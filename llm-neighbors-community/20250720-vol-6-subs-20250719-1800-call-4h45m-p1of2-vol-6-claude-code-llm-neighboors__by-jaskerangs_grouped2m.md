[00:00:00] Мини и вот вот этот БДСМ весь, короче. Да, ну, но он оказался весь невыгоден, да. Ну, мне так, знаешь, это показалось, как на маг ты пытаешься винду поставить. Э-э, но как бы пробовал ли ты без того, чтобы на маквинду поставить, а прямо код-код с опусом денёк другой посидеть или код? Ой, ну у меня у меня есть у меня есть спектн workflow для cloudкода. Угу. Всё, а не хочешь ли ты об этом рассказать? Да. А что, а что об этом рассказывать? Ну, там спектрай ээ точно такой же, как в Киру, только для cloudкода. Ну вот по шагам на самом деле, типа какая задача перед тобой, например, стояла, какая- ну там верхнеуровневая у тебя что там одна дока называется такая-то, в ней что-то там, потом ты итераций сколько делаешь, вот что-нибудь такое. Ну у меня не сильно сложные проекты, типа у меня, ну вообще такие очень поверхностные, что они могут выполниться при помощи Кира с одного запроса. То есть, ну, типа, вот Кира детально ему расписывают, что ты хочешь, и дальше всё, ты просто следишь за его выполнением, чисто корректируешь какие-то недоработки и всё. И вот оно работает. Вот я в Киро примерно так же вчера ��аботал. Вот мне очень мне понравился этот Кира прямо нам, ну, даже намного больше, чем код. То есть у меня эффект на Киру, этот эмоциональный такой всплеск был намного ээ ярче, чем с клоудкодом. А то я я просто этот как бы Кирой думаю, Кира, посмотрю через недельку, как время будет. Потом раз закрыли, теперь уже и не посмотреть. Кома рождают какое-то. Безос сидел, его кодил. Безос же его сделал или кто это? Я так, ну, трирую,

[00:02:00] имею в виду, что Amazon без там типа вот это или кто его забацал. Так, ну, ну, Amazon, да, Amazon. Там какой-то мануал ещё кидали надо ээ видео в каком-то чате, где типа там тридцатистраничная методичка Пакира. Хочется вот прямо кто типа, знаешь, как Саша Педин собаку ёна кодкоде, там агенты работают, будет его ночью доделать. Да не, я я что-то вообще в Куд это в Кира вообще такого ничего не вижу. Ты с ним только вот детально расписываешь всё в самом начале вот этот спек вот этот, и дальше просто запускаешь его. Всё. Ну то есть работает даже автономнее, чем cloudкод. Ну то есть, например, его не надо так упрашивать, там как-то что-то, ну прямо вот раскидывать всё по подзадачам. Вот он сразу, когда спек составляет, он всё это на субтаски раскидывает. И, в принципе, ты вот этот файл TASMD, который у тебя генерируется, в принципе, в чём проблема у тебя его запихнуть вообще в одну задачу, и просто у тебя будут куча, куча куча подзадач. И то есть ээ запустить вот эту одну основную задачу, он просто её будет беспрерывно выполнять. Ну, то е��ть можно и так сделать, в принципе. То есть вот. Угу. автономность зашкаливает. Плюс вообще, ну, типа, когда это полностью бесплатно, это прямо это так радуешься, улыбаешься, что оно работает всё бесплатно. Ладно, мой тогда вопрос, получается про Кира отвечен, считаю закрытым. Если у ребят может есть вопросы про Кира, думаете, ээ, потом накину формат, который придумал сейчас. Да. Привет. У меня вопрос. А что там кто-то разбирался про хуки? Там я глянул, что у них ��ам несколько страниц этих хуков. Можно навесить прямо на всё, что хочешь, но, честно говоря, времени не было посмотреть. А там, кстати, там, кстати, можно даже

[00:04:00] хук попросить его самостоятельно сгенерировать. Там, короче, есть такое это ээ менюшко для хуков, и ты, например, там можешь просто попросить его, ээ, навесить или там даже вообще самостоятельно написать хук на, э, например, ну, опять же, мониторинг там файлов. Ну, то есть вот так вот. То есть прямо не Ну, можно каких-нибудь примеров прикольных накидать, которые тебе очень прямо вот прикольных примеров на хуйки я не нашёл. Ну, то есть типа я просто себе уведомлялку ставлю, что типа там, ну, звуковую, что он там, например, подтверждение просит или что-нибудь такое, хотя там по дефолту оно есть. Вот. Но я чисто звук добавляю, вот и всё. Угу. Понятно. Спасибо. Я покажу сейчас скриптик свой, который у меня этот запускает чеки на этот самый, блин. Кстати, у меня вопрос. Вот тут я см��трю новый тренд заставить Laoud Decд работать как можно автономнее. А для чего вам это надо? Я просто, ну, интересуюсь, потому что у меня обычно такие, знаете, задачки, типа что-нибудь посмотреть, поковырять, потом отправить делать. Ну, типа, поэтому я не очень понимаю, в чём в чём прикол в том, что он там будет отдельно молотить. Ну, то есть зачем это надо? Ну, ну типа, неужели это такая линейная задача, что ты как бы запустил и он там молотик? Ну вот смотри, вот это вот сриптик вот, значит, ну смотреть, конечно, просто большого смысла нет, но короче это это shellsрипт, который а делает следующее. Он запускает, значит, ээ по а по всем файлам запускает линтеры. Вот, значит, собирает инфу и потом

[00:06:00] инфу, ну, собирает, что есть есть какие-то ошибки по линтером. Агу. И а что он слушает или что? Или как там? Как это он слушает? Что он слушает? Вот у у коннектор у курсора тоже был раньше, да, типа он там смотрел линтеры. Я просто как технически безграмотный такой задаю вопрос: "А что он слушает?" Это это просто, ну, как бы Линтер, это туза командной строки по Не, я в курсе, да. Ну, я имею в виду, ну, там еслин, да, но он это в каком виде как-то протокол идэшка это ловит как-то по какой-то штуке, а тут как это не ИДшка вообще ни при чём. То есть это просто, ну, баш файл и всё. То есть он линтер запускает просто и всё. Он запускает, он запускает Lнter. Он, короче, вот типа посмотрел файлы список их, да? Ну, типа, и дальше с логика идёт, да? Он дальше он, короче, то есть вот он вот он run allче. Это, короче, запускает цилиндры, да? Вот. А значит, и отправляет это всё э в этот самый, блин, да, отправляет так сейчас, да, вот в в этот самый в этот файл отправляет. Вот, значит, дальше он, а, анализирует, короче, этот файл с помощью кладкода. Так, где оно, [ __ ] где оно? А, бывает аутпут там, ну, и 600, и 800 Кб же у Линтера. Это сабагента запускаешь или как? Типа как борешься с тем, что неконтролируемый большой мусор? Да я просто просто отдаю его, короче, плод-коду и больше ничего. То есть код-код у меня его просто берёт и анализирует. Вот, значит, он его проанализировал. Типа команда код минус P это типа, да, я иззается или SDK или как? Да-да, да, здесь код минус P. Я покажу сейчас, что там что там наделано. Вот. Значит, и дальше, если если, короче, ну,

[00:08:00] собственно говоря, да, если если ошибки были, да, то, значит, отдаётся коду на анализ. Вот где он просто разбивает это всё на это самое на несколько категорий, вот по которым он потом, значит, идёт, э, запускает на каждую категорию вот эту вот. Вот, значит, где он просто, ну, то есть ему даются, вот если посмотреть вот здесь вот вот RНФix - это, ну, по сути, категория, да? Вот. И дальше чего, э чего и как фиксить. Вот и всё. И он идёт по этим файлам и исправляет их. Вот. Значит, ну как бы А сколько категорий у тебя штук? Там 5 10 15 Они типа все типичные ты, которые по дефолту линтеру, и ты их просто чуть-чуть посолил промтом или ты выдумал какие-то свои там абстракции комплекты? Не, это я как бы я ничего, конечно, не выдумывал. Значит, эта штука она, значит, вот, а, afterixable scripts, afterfixable code modifications requires manual intervation intervention. Ну, то есть, короче, просто он как-то там их разбил по этим категориям. Вот, значит, по сути получается вот такая штука. Mark Link fixes. Вот. Слушай, а ты проверял как-то, что он всё это делает? Потому что у меня поставлены Да, я не просто объясню сейчас ситуация. У меня поставлены эти линтеры на хук, на комитху, и когда он начинает комитить, он, короче, проверяется весь всё изменение этим линтером и там, ну, там можно всё, что угодно настроить. И, значит, всё, когда он там уходит там в пятый цикл, он говорит: "Что-то брат

[00:10:00] сложно". говорит: "Давай-ка мы это тамит руки пропустим, короче, давай без них". В общем, что-то сложно, долго, ну, верифай. Да-да, да, короче, потом, короче, будет тех долг, потом поправим. И у меня просто уже куча этой всей фигни скопилась. Он всё время начинает там после какой-то операции это всё стараться скипнуть. У тебя такое было или нет? И как у меня у меня, смотри, значит, он он здесь ничего не скипает. Вот, значит, ээ, короче, он вчера у меня возился где-то, наверное, часа два. Вот, то есть я поехал по магазинам, вот оставил, приехал домой, ��начит, он уже закончил. Вот. Ну и я же запустил, короче, этот ээ чек потом ещё раз, да? То есть у меня чек отдельный тут ээ есть файлик тоже нариённый. Вот запустил, он отрапортовал, ничего больше нету. Всё. Вот. А что он из себя представляет этот код? Гу. Так, где он, [ __ ] Вот он. То есть вот у меня, значит, есть такой, э, ба, ээ, баш стартапд MCP. Вот баг, Verb, print. И дальше, значит, то, что там пост добавляется стартап clклод MCP - это у нас Так, где он, [ __ ] Стартап код MCP. Вот, значит, ну, здесь он определяет этот самый директорию СРТА. Вот, значит, подцепляет System проomt вот специфический, ну, и просто запускает, собственно говоря, клод с этим

[00:12:00] системпромтом и остатками аргументов. Вот. А, а, а можно вопрос? А вот ты говоришь, что у тебя линт запускается по всем файлам проекта, да? Это уже какой-то, ну, как бы существующий проект. или это в процессе изменений, потому что если, ну, как бы делается изменения, то в принципе мо��но же линтер запускать ну для каждого файла. Ну, типа там сделал изменения файл, запустили линтер, посмотри тут же испрать, то есть доделай его до конца, чтобы потом всё не фикси. Ну, смотри, я я не хочу как бы в процессе в процессе работы, значит, ну, я хочу минимально минимально в этом участвовать, да. Вот. То есть я хочу заниматься руководством проектом, а не имплементацией проекта. Вот поэтому у меня максимально всё автоматизируется. Значит, если я буду м то есть, если я в коде буду в чате, значит, там периодически ему давать, как бы, давай там поисправляй что-нибудь, вот, ну, это нене не я не об этом. Ээ, естественно, всё должно работать автоматически, просто не для там всего изменения, э, которое касается там нескольких файлов, а для каждого файла отдельно. Ну, ну, по сути, не знаю, вот изменения пять файлов, да, там, да. Он первый сделал, вот начинает делать второй, но перед тем, как делать второй, он же он же может первый проверить тут же сразу линтером и сразу его исправить, чтобы потом не гонять отдельно линтер по проекту. Я вот об этом. А, ну, слушай, может быть, как бы, может быть, ты прав, да? А, ну хотелось бы тогда понимать, каким образом запускать его на изменение файла. То есть я могу

[00:14:00] посадить какой-то там хук на изменение файла, да? То есть файловой системе посадить. Вот. А, но тогда есть вероятность, что, короче, у меня двое клодов начнут одновременно изменять один файл, и может получиться очень нехорошо. А, ну тогда логика понятна. Всё, спасибо. Вот. Значит, есть ещё один вот стартап клод, в котором тут максимально, значит, ну вот такие вот вещи. То есть он подцепляет. А, кстати, вот он он, короче, у меня загружает из из моих директорий там определённым образом сконфигурированных. Он загружает, э, так надо идти register custom agents. Так, register custom agents. Вот, значит, он, аа, он регистрирует, короче, агентов, которые у меня там есть, да? Вот. Ну, это кастом агенты. Вот. Э значит регистрирует таких, ээ, которым сделаны вот такие вот. Потом есть агенты, которые зарегистрированы в виде промтов специализированных. Вот он их, ��ороче, регистрирует. И потом потом из получившегося, вернее, получившийся файл вот этот вот MCP Jon, да, он подцепляет воду. Вот он разрешает всё подряд. Вот и даёт системпромп дополнительный. Вот такая вот штука. А вот этот, э, bypass Permission, это из

[00:16:00] промтов кода или я не встречал? Или это башевская какая-то штука? Это кастомная. Ну, skip permission danger mode. Это вот её взял стандартно. Сейчас покажу. Я что-то не не так. Значит, а, вижу миion mode. Ага, понятно. А что она даёт? А, всё, я вспомнил эти пн. Вот это, вернее, я я всё время Danger запускаю, даже пн не прошёл. А байпасы что он даёт-то? Он просто пропускает все чеки и всё. Он просто херачит. А чем отличается от Dangerous мода? Зачем его мо? Я, честно говоря, пош, блин, просто меня заколебало спрашивать, вернее, что что он спрашивает меня, и поэтому я А я я понял. М я просто ем�� в сетин Jсоon [ __ ] чего разрешил. Он поэтому даже меня не спрашивает. А в Ders моде, наверное, если не даже это не разрешено, нужно нажать, а ты всё типа. Угу. Ну то есть два пути одного и тоже. Слушай, Саш, а интересно, типа, ну вот я помню, ты кидал вот этот ещё перед Телетоном, который мы вместе делали на воркшопе, ты кидал проект, я уже извиняюсь, могу запамятовать, там что-то был какой-то блокчеain storage или что-то, ну, что-то блокчейновое вы делали. Дама проект. Короче, это не перед телетоном, это после было. Вот. И это был не не блок не блокчейн, это блоксет. И, короче, ну пока пока он на это самое на заморозке лежит. Это просто смотри, значит, я участвую в одном стартаповском проекте. А, извини, OCR чексервер. Вот что было. Но я там просто заказчик был блокчейновый, я это уже связал. вместе. Я я к чему вопрос спрашиваю? Интересно, ну, просто понять, вот ты,

[00:18:00] например, ну, тогда его сделал, я так понимаю, это уже две разные вещи. Сколько прошло у нас? Шесть частей. Эпилогия Star Wars. Вот уже полтора-д месяца прошло, и как бы скилы растут, и, наверное, поменялся у тебя пол. Но в целом понять, вот ты сделал эту автоматизацию, типа тебе на входе заказчик говорит: "Блядь, хочу, короче, чтобы ОR работал заебись". И вот твои агенты, они вот это всё опрашивают, создают спейки, делают вот этот проект на там, допустим, на сколько? На 20-50.000 строк кода, и он работает. И это прямо крутится типа 10-20 часов. И вот такие уже кейсы получались. Или как у тебя вот это происходит? Не, у меня, смотри, у меня пока, ну, сильно сильно долго у меня не крутится, да. Вот. То есть у меня сейчас я я сконценрою на то, чтобы сделать инфраструктуру вот для это самое для своей этой херовины. Вот, кстати, название пош придумал такое замечательное. Эхав ахай рой пчёл или что такое? Да. Ну, то есть рой. Угу. Вот. Значит, прикольно. Да, спасибо. Кстати говоря, чат GPT. А антропик не подсказал? Да, я антропика об этом не спрашивал. Вот это, знаешь, это, короче, днём сидишь в это самое в антропике, ночью понимаешь, блин, э лежишь, короче, с чатом GPT, изменяешь с чатом GPT, да. Там какой-то, я даже не знал и не узнал бы никогда, сидел в коворкинге, там вдруг сказал: "В Инстаграме какой-то идёт хайв". Каких-то два каких-то больших топовых менеджера, вернее, нет, фаундер и топовый менеджер на концерте засветились. И об этом десятки миллионов людей сейчас, короче, стрим мейнстрим,

[00:20:00] типа, что, ну, это отоп. Угу. Короче, они долго не крутятся, но ты сфокусирован на автоматизации и отшлифовываешь отдельные куски, если вернуться. Дададада. Да. Вот. То есть вот то, что я вчера спрашивал там по поводу, ну, у вас сегодня было по поводу того, что, короче, что лучше использовать а в качестве там этого, ну, для C, для запуска C. Вот это вот, собственно говоря, по этому поводу. То есть у меня реально, короче, ну, то есть я запускаю интеграционные тесты, в которых участвует плот. Вот. Ну, и, соответственно, у меня там интеграционные тесты там для одного, а, для одного пэкаджа могут идти там 7 минут, ну, там 10 минут. Вот. И, ну, для это самое, для гитхаба это бн перебор. Вот. То есть я в гитхабе уже выходил, короче, за рамки вот разрешённые. Угу. Угу. Ну, Максим, я так понял, он может и сам расскажет или я могузать. Он говорил, да, своих воркеров. Я тоже как-то делал когда-то своих воркеров. Там давно ещё было до и кодинга, а потом для заказчика как будто действительно может быть под процессы дешевле выгоднее эти C. Смотря. Слушай, а Warркер - это ты можешь просто виртуалку какую-то сделать или как это вообще? Слушай, да. Просто на ВПК она тоже сколько там ресурсов требует же. Ты просто на впэске по мануалу Гитхаба заходишь там, ну, вн онлайнером запустил, установил и он как бы крутится. Не помню на чём он даже там написан у них, на Go там на но или на чём-то. И он как бы крутится, и он слушает события и такой берёт в работу. Просто он использует железо твоего сервака, и ты там условно их можешь э в конфигах задать, где какой воркер что

[00:22:00] запускает. Ну и, грубо говоря, если лимиты твои закончились, а у тебя без дела стоит сервак, ты напихать можешь там с 20 штук и не париться. Всё равно стоит, простаивает. Вот у меня простаивает сервак есть. У меня, блин, винда стоит до сих пор в кладовке. Я, блин, до сих пор её не могу достать оттуда. Надо как-то это сделать. Ну либо ещё можешь взять, есть всякие серверс системы, есть железо по заказу, но там надо смотреть, чтобы у тебя быстро вся эта инфра поднялась и накатилась, но зато не будет такого, что у тебя там А какие требования к этой машине вообще? Не, ну коперативы там желательно хотя бы там же вот как воркеры скриншот кидал Максим, наверное, как бы желательно не меньше. Там там, если не ошибаюсь, гиголов было. Можно этого там всё равно жёсткого-то лимита-то нету, как бы ты можешь и маленькую машину завести. Он не делает жёстких проверок. Он тебе, насколько я помню, даст и на маленькой машине всё завести. Просто тормозить будет. Угу. У меня, кстати, вопрос, он там несколько проектов параллельно сможет обрабатывать или как? Да. Да. Ты когда Workflow создаёшь, ты прямо в самом workflow указываешь, какой из э раннеров использовать. И по идее, да, он может там несколько их запускать. Ну проблема в том, что ты просто в железные ресурсы можешь упереться. Вот только в этом косяк. И а балансировку там как-то можно примануть причём или нет? Вот этот не знаю, не знаю, не скажу. Мне кажется, что там балансировка, точнее, как я не видел опций балансировки в настройке самого воркера, ой, в настройки ранера в GitHub Actions, вот в его панели управления. И кажется,

[00:24:00] кажется, так что не буду врать, не знаю. Но суть в том, что там как ты когда создаёшь свой раннер, он сам подключается к профитуре гитхаба, говорит: "Типа я доступен". Вот. Угу. То есть это у самого, получается, у самого Гитхаба есть информация, сколько сейчас раннеров доступно и в каком они статусе находятся. Ну, видимо, он на следующей свободной будет просто вот это распределять, но точно не скажу. Есть такое про, да? Ну, то есть тогда мы можем просто намасштабироваться за счёт подключения дополнительных, да? Они там сами будут получать, как Да, да, да. А, ну всё, тогда спасибо. А, а получается, что оркестрируют GitHub. И если утось в лимиты, то при наличии раннеров это всё равно будет работать. Или если лимиты, то и оркестрация перестанет работать. Лимиты как раз-таки за использование железа ранеров гитхаба, который он выдаёт бесплатно на 2.000 минут. Ну то есть если при этом подключить свой раннер пере он тебя не будет 2.000 минут юзать, а вот эти будет твои и как бы вроде, ну то есть он будет будет работать, да? У если свои подключить, то это получается постоянная работая система. Там там, судя по всему, нету такого фейловера. То есть, если у тебя закончились гитхабовские раннеры, чтобы он автоматом на твои переключился, потому что ты явным образом указываешь э название раннера в самом Workflow, в своём файле, который отвечает, собственно, за то, где у тебя э��о всё будет исполняться. То есть что-то я не уверен, что там есть такой механизм, что типа вот если китхабовские кончились, он переключится на твой костомный вариант. То есть можно тяжёлые раннеры, которые заведомо будут жрать ресурсы гитхаба, сразу запустить на своём железе и ужехаб использовать. Ну да. Вот вот это больше более такой жизнеспособный. Классно. Классно.

[00:26:00] А вот вот всегда используется связка GitHub Actions. А вот кроме кроме этого ещё что-то можно использовать какие-то другие вот такие вот оркестраторы. Ну, верн��е, кто-то пробовал, да? Знаю.Ла. Ты имеешь в виду, чтобы клод в этом участвовал или просто Да, да, да, да. Ну вот связка клод и и GUAB Actions. А вот можно и что-нибудь другое. Кто-то вот пробовал. Ну но ну но такому же принципу с куками. Ну получается, кстати, Максим, аа, ну, насколько я помню, э когда ты показывал GitHub Actions, ну, CД Actions, да, CД Copilot, пусть будет. А то мы говорили, что антропики взяли, задепоили одну конкретную штуку, и благодаря ней это работает. А эта штука, она не Open source. То есть, соответственно, нужно антропиков просить, чтобы они на какой-нибудь там Тим Сити, Тревис, Дженкинс бахнули свою, а, а это, по идее, они не делают пока. И ответ на этот вопрос пока типа недоступно, потому что этой штуки как таковой нет openсоourсной. Она dependent, он какой-то софт от антропиков, закачанный на GitHub, который переиспользуется. Макс, правильно я понимаю? Мм, что-то нет, по-моему, такого там не было. Вот у GitHub Капай-то, да, там вот есть такая штука, ты его не оторвёшь от инфраструктуры Гитхаба, а вот в случае с клодкодом вроде ничего такого нету. То есть, ну вот в Джен его можно посадить, поселить, судя по всему. Да. А, подожди, он open source. Вот. Да. Не, подожди, он не source. То есть, в смысле, сам сам агент, а, ну, в смысле сам CL-код, он не неource. Ну, хотя что,

[00:28:00] ты и так это знаешь. А вот GitHub Actions, а, кодкодовские, они прямо совсем open source. То есть ты можешь прямо готовый взять и, пожалуйста, использовать. Ты можешь его переписать под тот же самый Gitlab, если захочешь. Я думал, что там оно, да, типа требует всё-таки какой-то антропиковский ещё dependent модуль, который недоступен. Вроде нет. Что-то я не видел такого. Ну, мы не слышали. Ну, я, по крайней мере, не слышал. Андрей, тамха интеграция с Гитхабом - это был один из проектов примеров у клодкода, когда они выпустили клод-код SDК. SDK был - это общее решение. А интеграция с Гитхабом была как пример использования SDK для того, чтобы на Гитхабе всё взлетало. Вот как-то так это всё было, по-моему. Максим поправит. Денис, Денис, Денис, ты посмотрел там файлик этот? Файлик какой? Бумка. Нет, нет, нет. А ты посмотри, там кое-что интересное внутри лежит. Я тебя понял. Сейчас. А что же за пальк? Расскажите. Или ладно, если совершенно секретно. А ты в чём, Андрей, интересуешься? Для какого Дженкинсона, Team Сити? Нет, у нас мы используем bitтбакеet. Вот. И у нас своя система сборки. Вот там тоже на фуках всё построено. Поэтому я хочу понять, в каком месте можно в эту всю систему подключиться, чтобы, ну, работало вот похожим образом. Как демонстрировался. Получается как будто ковырять исходники

[00:30:00] GitHub, Actions и SDK. Ну вот не хочется ковырять, хочется всё-таки как Дадада. Ну, в общем, вот пока изучаем. Кстати, ребят, а вот такой вопрос, как тогда Redit, я сказал, а вот или не Redit, или GitHub Stars искать как-то, или какие-то другие инструменты. Кто как ищет? Что, что ищет? Ну вот, например, у Андрея задача найти bitтbcket код Code actions. Как вот искать какие самые эффективные? А, ну смотри, как я делаю. Я, короче, либо Ну у меня три источника, это GitHub, Rided и Discord. То есть, например, я могу зайти в тематические серверы в дискорде, либо там тред наредите тематически там на какую-то тему. Вот. и просто в поиске попробовать что-то уже банально поверхностно найти. А если хотя бы какую-то зацепочку нахожу, то я экспортирую там всю историю сообщений, например, от определённого пользователя или всего треда или сервера там какого-нибудь канала в себе, ну, в буфер обмена и дальше просто пихаю это всё в джеме. И он меня анализирует и что-то выдаёт. Ну, то есть я вот так делаю. Угу. такой руками сделанный агентский поиск. Да, почти. Ну, почти, да. Вот, кстати, я думаю, что ровно так будет работать поиск на агенте, который новый агент от Chat GPT, который гибрид оператора и псча. Вот он при этом, ну, пока что он что-то как-то так себе это выступает. То есть как-то не супер крутой по сравнению даже с тем же Манусом. Ну, агенты так мо вот то, как ты объясняешь делать, да, там зайти на редит, почитать, проанализировать. В

[00:32:00] принципе, агенты условно должны уметь так делать. А, кстати, вот кто-нибудь пробовал этого новог�� агента от OpenI? Он вышел там пару дней назад, я на паре задачек запустил, но мне очень понравился результат, то есть прям прямо очень понравил. А висит ээ ещё оставшаяся подписка в Грис периоде, как ни странно, но мне пока не раскатали. Он он раскатался и на про, и у нас есть одна вот эта вот 200 баксовая подписка там тоже, но прямо очень он он правда работает долго. Ну, собственно, это задача такая про раслся. У меня про вроде как, но Ага. Не раскатался ещё. ��идимо, не всем раскатали. Ты про кодекс говоришь? Наверное, в виду плюс. Нет, нет, не не кодекс. Это это агент Open. А Open же плюс за 20, а Pro за 200. А у этих Pro и Max унтропиков на Pro вроде бы за 200 доступен у всех. Не, Open уже вроде бы даже на плюс плю Openi плюс за 20 и Pro за 200. Вот на плюсе у меня пока агента нету, но обещали понедельник раскатать. Угу. Но сейчас не понедельник, поэтому [музыка] А ещё, кстати, вот она зависит от региона. Иногда в Америке раскатывает уже, ну, быстрее всего, как мне сказали, раскатывает Америку и Японию, а потом всё остальное. А это зависит от IP-адреса или от места, от того, где у них там датацентры и команды, которые это раскатывают. В Америке, в Японии большие команды, поэтому они у себя быстро раскатывают, а в Европе медленно, поэтому иногда можно просто регион ВПН поменять и всё будет.

[00:34:00] Что? А, ну у меня американский VPN, но нету как бы, к сожалению. Вот Александр рассказал сценарии, собственно, то, что таким образом работают, то есть днём ты решаешь какие-то задачи, агенты там работают. Вот. А потом, ээ, ну уже вечером у тебя смартфон, лежишь и приходит какая-то мысль, и хочется запустить агента. И вот сейчас то, что вот произошло в Open, по сути возможность запустить, но нет, он работает только на дескотной версии пока ещё. Ну, может, раскатают на смартфон. Тогда это будет вообще класс��о. Вот приходит какая-то идея, ты ему говоришь, он пошёл работать утром просыпаешься, смотришь прототип получившийся. Ну и дальше можно с этим что сделать. Он входит в подписку в вот которая 20 баксов, там 40 генераций. А та подписка, которая 200, там 400 генераций. Вот. Но генерация - это генерации. Ну вот, вот я ему сказал: "Вот у меня какая-то идея, сделай мне презентацию". Да. Вот вот он работал минут 20 и на выходе сделал мне презентацию достаточно качественную парпонте. Вот вторую задачу им давал, тоже была идея. Говорю: "Ну, сделай одностраничный сайтик вот на реакте и ээ ну вот реализуя эту идею". тоже работал минут 15 и выдаёт ээ отлично работающую вот эту идею в виде этого сайта разные пара я пока вижу такой сценарий использова слушай а он это самое он в в gpt чате то аген появляется или это отдельная у них априкупка он это ээ чат gpt который на сайте там появляется внизу а новый новый режим агент Вот он прямо так называется. Ты ээ ну, собственно, его активируешь и дальше

[00:36:00] просто читаешь тошь задание, но он теперь э рисует окошко прямо вот на экране вирталки вот этой вот, на которой э он работает, и прямо всё показывает, всё, что он делает, какие он поисковые запросы делает, какие команды выполняет, какие скрипты ээ работают. Причём там есть, вот с этим я ещё не разбирался, там есть возможность в это вмешаться. То есть, ну, ты прямо можешь туда из браузера зайти и остановить, скопировать что-то. И там есть какая-то ещё опция запустить, ээ, вернее, подключиться к браузеру. То есть ты прямо туда можешь зайти и, ээ, ну, допустим, если там креды какие-то нужно ввести, может быть, а, ну, то есть прямо всё как в Манусе. Да, да, да, да, да. Вот. Но это Open ну соответствующими, э, не знаю, или плюсами, или минусами, но у них ещё м к этому агенту, насколько я понял, подключаются все, не знаю, зы MCP, например. Вот так что можно, например, запускать э со своим MCP подключенный к своей собственной Вике, да, чтобы он использовал твою информацию для решения этой задачи. Вот это цен. Ну вот это уже хотя бы прикольно, что если типа агент работает даже в браузере, а не на твоём устройстве, так ещё и может использовать твои MSMP сервера. Ну вот вот вот это ещё не тестил как бы серверов с телефона работать. Ребят, а как сервера там какие-то можно? Я не видел такой возможности нигде на сайте чат пяти. У Клода можно, у этих вроде не было. Саша сейчас быстро сделает. Не, я что-то не хочу.

[00:38:00] Они, кстати, обещали, что они будут поддерживать MCP, но что-то, по-моему, пока нет. Я не видел у ОНАИ, кроме Кодекс Кли, по-моему, да? ни в одном продукте поддержки MCP. Ну вот я сказал про MCP. Может я действительно ошибаюсь, потому что сейчас всё-таки столько уже этих агентов может перепутать. Ну если вы подтверждение, напишите. Ну антропиков б��ло удобно, они сделали директорию. У них теперь есть и десктопные MCP в виде упакованных расширений, которые легко ставятся. И у них есть облачные MCP, которые называются интеграции, и они тоже довольно легко подрубаются, но у них список вот этих всех интеграций и расширений, он ведётся ими самостоятельно, и они его модерируют сами. То есть можно туда писать заявки, чтобы добавили твоё, но они сколько, как их обрабатывают и на по каким критериям проверяют д�� конца, неясно. Вот. Ну, какой-то пучок они проверили, он существует. Остальные можно руками подрубать. Ну, тут, видимо, остаётся только немножко подождать, потому что тут, например, у клода у них есть к фигме. Вот я обрадовался было, но выяснилось, что это как раз дестопная фигня. То есть нужно у себя её поставить как приложение, тогда он будет локально обращаться. Кстати, а по поводу Фигмы у нас планировалось в 19:00 подключиться Рима, е��ли А значит она она мне прислала, короче, сообщение. Значит, она сказала, что раньше э раньше десяти 945 тире де, короче, она не подсоединится.

[00:40:00] Блин, развлекательное шоу переносится. Это через поговорим о девах через час. А, да, ещё знаете что хотел поднять про источники, не хотел перебивать. Вот. Ну, понятно, Discord, Redit, GitHub, а вот Hacker News кто-то использует вообще или это больше продуктовый источник таких, э, новшеств или идей? Там же, вроде бы, многие люди публикуют какие-то свои новые э стартапы и проекты. У меня, например, есть, э, друг, который пишет агентскую систему типа конкурентофантропика, как он это говорит. А он прокачанный достаточно разработчик, но он сфокусирован именно, кстати, я его позову как-нибудь, он, говорю, через несколько недель придёт. Сфокусирован, знаете, такой как бы код хард work, deepwork, ну, типа там на алгоритмах и прочее. И он говорит, что вот этот oneграф, ну, это все говорят, что как бы так поиграться, а так лучше самому своять. Вот он хочет эффективный такой мм фреймворк агентский. Так вот, и он хочет публиковаться на Hкеer News, например, и общался с парой там э с из США ребят, которые тоже в долине, как и наш Саша Федин и Дима Филиппов. И скоро уже у нас будет долиновцев больше, чем не долиновцев, да, э-э, на звонке. И вот ему этот ангел говорил, что, например, оказывается, там есть такие хитропопые, э инструменты hidden бан hidden filter, если по по прямой ссылке переходят на твой проект и пытаются, ну, и типа вот ты там скинул в линтынь или друзьям, типа, а за лайкой, то это

[00:42:00] антипаттерн для них. Ну и, короче, по тезису, что вот хотят технори публиковаться там и что вроде бы тоже типа аляс считаются престижным. Я подумал, может быть, техническая тоже там новая появляется, но я не мониторю. А может кто-то мониторит и поделится опытом. Скажем так, Hacker News - это старая тусовка. Вот там все новости, если говорить про АИ, появляются с опозданием. И до сих пор там достаточно такая большая когорта скептиков присутствует. То есть если туда именно что-то прои пытается пиарить, ну такое. То есть это именно такая старая программерская, нердовская тусовка, которая с каким-то недоверием относится ко всяким новым штукам. О, его полезно читать, пожалуй, для этих, э, для общей дл�� общего ландшафта происходящего в этих технологиях, но не фронтир, увы. То есть, э, там что-то вот как-то для фронтира это уже не очень подходит. Но вот, например, интересно заходить в топики, которые там уже настоялись по каким-то вот новым технологиям. Типа вот вышел там какой-нибудь не знаю ну вот тот тот же самый клод-код когда вышел там очень интересные люди в комментах приходят вот прямо приятно читать там топики правда интересные вот но я говорю скептиков очень много и все эти новости там с достаточно таким сильным запозданием появляются то есть если говорить об источнике актуальных новостей то это скорее redдиit и Twitter вот для пиара собственных и проектов HER News кажется не самое хорошее место. Вот какой-нибудь продукт Hunter, где там сейчас вот, по-моему, модно. Вот мне кажется, там это с большей охотой воспринимают такие штуки. Кстати, про как продукт, как этот способ

[00:44:00] продвижения, мне кажется, очевиднее. У меня все знакомые, кто запускал какой-то стартапчик или про продукт, они там публиковались. Ну, особенно на западные аудиторы, конечно. Вот говорят годные годную отдачу. То есть если залайк, да, да, если там залайкает, это хороший буст там по установкам, по всему. Вот оно разлетит потом по интернету. Смотрю трафик Simul Web. Сейчас вот кину скриншоты. Например, Prodct Hun 3 млн, а, акеer News 12 почти. Интересно. Ну да, может быть такое. Hacker News новостной портал, всё-таки. Вот. И там как бы там PR проектов делают, но я говорю, вот надо учитывать вот эту специфику. ради интереса можно просто как там есть такая даже это категория не назовёшь то есть news он и хорош и плох тем, что это а как старый форум практически вот и как бы это чисто текстовый контент он такой приятный для тех кто к тексту привык с другой стороны какие-то новые штуки не выложишь там вот даже категорий каких-то нет этих постов и там вот есть как бы категория можно её назвать так категория там просто правила оформления постов шоу, а hн называется. Ну, типа шоу Hacker News. Вот можно поискать просто по определённому вот этому сочетанию слов и посмотреть, как принимались, э, точнее, как вот шоу Hacker News - это когда ты свою идею писываешь, даёшь ссылку на свой сайт и всё такое, типа я сделал то-то, то-то, покритикуйте, попереходите, всё такое. А, и вот можно посмотреть ради интереса, как люди оформляли вот такие посты в прошлом и как они воспринимались. а-а участниками коммьюнити. Вот проекты с ИИ обычно вот из того, что я вижу, не очень хорошо

[00:46:00] там воспринимаются, но это возможно я может не туда смотрел. В любом случае стоит какую-то какую-то вот такую разведку провести. Вот. Угу. Сейчас спрошу опуса тоже интересно. А мне, кстати, одному показалось, что, ну, в основном такие трухардкодеры, они не очень всей темой интересуются. Потому что такое ощущение, что вот те чувачки, которые довольно слабенькие, и они такие: "О, сейчас тут с агентом наваляем, меня забустят". Они такие как, ну, типа фронтир идут. А вот такие хардкорные программисты, у которых прокачан сильно свой налог, мне показалось, что они наоборот довольно скептически это всё дело воспринимают. Всё. Ну, интересно ваше мнение, потому что у меня вот такой батл сложился. Есть такое, да, я тоже замечаю. У меня вот даже есть несколько чуваков, кто, ну, прям хорошие, то есть они как бы алгоритмисты хорошие, и, в принципе, архитектуру хорошо понимают, и кот любит писать. А, и вот от некоторых из них я прямо слышу прямым текстом: "Я концептуально не использую и в работе". Для меня это такой шок, если честно, типа, ну я я как бы как сам программист, я могу их понять в том плане, что, ну, мне тоже нравится возиться в алгоритмах, в архитектуре, вот это вот всё. А и я могу понять то, что им нравится писать код. То есть это процесс создания чего-то руками, это выражение своих мыслей прямо вот в такой притягательной форме. Причём ты можешь проверить результат практически сразу. Но кажется, что это уже слишком устарело. Вот вот это агента, который пишет парень, вот как раз он как бы доверяет вообще даже там и я и только тесты писал, и у него там каждая функция не оптимальна. Вот это вот так, это так. Мы пытались с ним ээ 2 122 часа, короче,

[00:48:00] разъебать его там функцию, которая мультивложенная с разной иерархией, там универсальная, типа, знаешь, аля Google алгоритмы, но, э, опус, короче говорит, там во многом некомпетентен, но я тут вижу проблему контекст инжениринга по факту, потому что А я тут вижу проблему в том, что у чувака очень сложная функция, и как раз тесты должны показать, что это овер оверненниринг будет. должен быть, знаешь, этот склаломатик комплекси, короче, чтобы ты этот тестировалось уже там не как раз напишет ну типа сложность обозна убирает и прочее. Я там даже погрузился, ну типа, ну то есть он делает максимально оптимально, а Иайка там, ну лезет в рекурсию, где можно без неё обойтись ещё там типа вот такая история была. Потом мы, говорю, там вот представь это Google инженер, там давай критику. Каждый разборн там аргументы. Короче, после семи промтов, вот этих семи ревью я уже устал. Я говорю: "Да, тебе не поможет Я". Угу. Ну, а, кстати, ну, это же было исследование, что типа AI помогает, когда у тебя ��сть какая-то область, где ты не дотягиваешь, она тебя дотягивает, а зачастую, когда ты сам эксперт, то она наоборот будет тебе мешать. Ну, в том плане, что ты сразу сделаешь оптимальнее, чем он. Ну, типа, это уже, по-моему, года два назад, как было исследование, где где как бы есть сфера применения. Всё же эволюционирует каждый, буквально каждую неделю. Ну я лично в этом примере увидел то, что как бы когда я от него просил как бы на голос, мы сразу войскодили, он, короче, даёт там свой разъёб войс, а я его и записку кодил. Ну, типа, смотри, он скинул свою функцию или нет? Он сначала на скинул ТЗ, там промт, мы захерачили функцию, он говорит: "Ёб твою мать, вот это пять-7м, короче, вещей вообще просто, ну, днище". И начинает, я говорю: "Давай конкретно". И вот так вот он начинает всё это

[00:50:00] рассказывать. Я под микрофон, потом сам ещё даю свой этот Максим знает поромт разъёб. Не приходи, пока не доделаешь. Ну, я так с юмором, ну, чуть-чуть там поконкретнее и прочее. Он выдаёт вторую версию, тот говорит: "О, ну уже немного лучше". Вот это, да? Ну опять, блин, я же сказал вот это, говорю, а ты это сказал, вот это он ещё, короче, матерится минут. Ну не матерится, там вот это рассказывает по конкретике. Я как придирчивый критик вычленяю из него все вот что ему хочется, не нравится, почему и как. Мы ещё раз кидаем такую итерацию и каждая итерация по 10 минут. В итоге 60 минут. Я говорю: "Всё, харе, �� сам устал, короче. Ну, мы там полезли дип-дип". Короче, говорю: "Давай, что мы хотим?" Короче, я говорю, вот ты типа этот Google, кто там Сергей Брин? Ну мы, короче, сейчасделаем нормальный Google Review во двух твоей версии вот этого, и мы даём уже его отработанный код. Ты его код разъёбываешь, ну, типа, который мы пытались довести, и вот свою версию и, короче, там скорешь по оценкам. Ну, там добавляли слов. Я сейчас уже округляю, конечно, мысли. А-а это было где-то месяц назад. И потом он, короче, кидает, я кидаю аутпут, человек краснеет, короче, и у меня есть ещё аргументы. Короче, мы ещё раз, я закинули эту историю. Ну, типа, в целом его мнение по опусу неплохо, но, короче, а нахера мне всё это нужно, если он дотянул до 80% Дзена моего кода и ещё там три спорных момента, которые он уже устал объяснять. И как бы там, ну, типа, то есть вот этот опусче, если классно его тюнить и промтами и давать конкретикой, можно довести, но вопрос, что он не может этого так сделать. То есть это же другой тип получается мышления, когда тебе надо не ну как бы вот весь контекст подать со всеми нюансами и прочее. Там просто идея была

[00:52:00] проекта, что, например, в Яму, чтобы был такой мультиязычный, чтобы неважно было на каком уровне вложенности агенту ты даёшь сценарии, делать что-то для какого-то языка там, ну, для одних языков там одна логика, короче, типов действий, для других другая, чтобы люди, которые заполняли идея, что я мон ты заполняешь агента сложносоставного, там, не знаю, рой из там 200 делаешь агентов с трицатью типами операций, чтобы важность была неважна. Знаю, он там такую функцию писал, и как бы он вот эти все юзкейсы, с который надо бы снабдить иайку, весь контекст, её просто собирать и объяснять, ну, наверное, часа, не знаю, три, естественно, он не делает с учётом вот этих вот этих пограничных состояний. И получается, надо как-то учиться автоматизировать этот контекст инженеринг, потому что он безумно сложный и не всегда все могут даже так формулировать. Мой был урок из этого тяжёлого на, наверное, почти на полтора часа опыта. Я прямо вот как за день устал. Ну, типа за полтора часа, когда мы там пытались, можно я скажу в тему? Как раз Ага. с одним человеком тут беседовали на неделе и пришли к тому, что сейчас меняется парадигма разработки программного обеспечения и похоже, что спецификации становятся новым кодом. То есть вот то, как ты описываешь это всё дело, то, как ты формулируешь, то, как ты это всё раскладываешь, как группируешь, вот это всё важно. А дальше как это потом э всё превратить в некие технические решения, по каким модулям это всё разбить, как реализовать, на каком техническом стеке и прочее. Это всё будет всё быстрее и быстрее делаться неросетями. И вполне возможно, что ты наговорил

[00:54:00] такой вот мануал, что типа хоть как видеть, спецификацию т��кую определил, и фактически нейросеть тебе будет довольно шустро генерировать код, работающий уже там с тестами, со всеми пирогами вот на твоё ТЗ. И вот то, что ты говоришь, почему как бы опус не справился, да? Так, опусу водные не поставили в полном объёме, а как раз вот формулировка этих всех водных, она и реально нужна для того, чтобы это всё классно работало. И вот это будет самое ценное в то есть ТЗ и постановка задачи будет самое ценное. Вот. Ну, то есть спейки, с��ейки. Ну, спейки, да. Вот мы там, блин, обсуждали, как правильно эти спеки писать, что типа надо ли писать, как это делать. Э, ну, то есть ты спеками пишут, что ты делаешь, да? Это само собой, вроде с этим никто пока не спорит. Но надо ли писать, как это делать? Или пусть, блин, нейросеть предложит, а вроде тебе и хотелось бы по поведению там какие-то вводные дать. Ну, короче, там такая дискуссия была мощная. Десь, мне кажется, извини, я полностью согласен, Денис. Вот контекст инжениринг, я и вкладывал понятие, где ты, ну, снабжаешь необходимыми спеками, объяснениями, юзкейсами, ну, вот вот эту всю агрегацию со всех сторон получается. Только даже не только спеки, а вот прямо, ну, бизнеспеки получается, пояснения какие-то. Вот не знаю, какие ещё документы могут быть, которые какие-то разбира вот Кира вышел там вот Михаил скинул файлик в чат. Это, я так понял, системпромты из скиры тоже там не бе не безынтересно пролистать. И у них там свой подход к спекам. Они там

[00:56:00] разбивают на спеки, собственно, и на стиринг файлы. Стиринг файлы - это, а, инструкции для модели по поводу того, как делать. То есть, типа, в спеках давайте опишите, что вы делаете, а в тиринг-файлах вы описываете, как вы это делаете, в деталях. И стиринг для агента, чтобы он там всё консистентно реализовывал. А спеки они в целом задают, что за продукт, какие компоненты, как взаимодействуют, архитектурное решение, вот это всё. Тут тут, мне кажется, короче, самая большая проблема, типа в том, что а ну в том, что типа к твоему подходу, к ревью этого кода финального, типа одно дело вот ты писал в спике там и типа как-то хочешь это делать, потом он сгенерировал код, его всё равно надо посмотреть. Ты не можешь ему доверять, даже если он тесты написал, ты не можешь ему просто типа там, не знаю, архитектуру он тебе сделал, пропустил там типа 10 крайних случаев, которые ты сам бы не забыл. Если ты, естественно, не превьюешь там, то очень жаль. Програ. Я вот просто ровно на этой неделе экспериментировал как раз обработкой спекров агентом. Писал workflow для клод-кода. И у меня там есть агент, который делает ревью автоматом. И я тут, ну, коллеги в курсе, я рассказывал, что у меня построено всё на папочке, в которой агенты пишут свои файлы. Ну, у клодкода там обмениваться с контекстом можно по минимуму, да, и контекст не надо заму замусоривать. И у меня агенты настроены на то, что они при старте задачи, в ходе задачи, ну, и финально пишут в некую папочку отчётики, там, файлики. И вот у меня агент, который сгенерил техническое решение, потом был агент ревью. И как он его

[00:58:00] разносил это техническое решение, хотя это тот же самый сонет. И как бы он вообще так нормально разнёс. То есть если дать ему вводные, чтобы он критиковал принципы там всякие архитектурные. Нене, да, это точно нужно. В смысле без этого ещё хуже б��дет? Это к тому, что просто в любом случае в любом случае тебе всё равно надо ребть. Мой мой поинт был скорее типа про то, что то, что вот обсуждали, что там типа чуваки не используют нейронки. Кому-то так просто проще, потому что если типа у тебя уже, то есть типа не знаю, в основном люди, которые там сейчас нейронки эти пишут, они либо просто пытаются экономить время там, типа, я знаю, как это сделать, но нейромка просто быстрее напишет, меньше моего внимания нужно будет. Либо там, например, типа я не знаю, как это сделать, типа она знает и она напишет. Вот там, не знаю, я не знаю, как как там, типа, я не знаю, на тайпскрипте писать код. Вот она напишет код на таймск, потому что я там типа долго больше на это времени потрачу. Но при этом типа если чувак вот алгоритмист заранее знает, что написать, то, естественно, он скорее всего потратит суммарно меньше времени и меньше багов. Проблема в том, что типа ему будет понятно, другим нет. Во-первых, но это не всегда важно. Слушай, ну вот то есть, например, ну условно там мне, например, типа, да, алгоритмическую задачку, я быстрее её сам напишу, чем типа попрошу там Клод её реализовать. При этом, если чувак типа проходит интервью и его там просит лидкод решить, то, скорее всего, а он не умеет, то типа скорее всего ему сона просто типа пройдёт интервью, а он сам не пройдёт. А можно вот на минуту назад вернуться? Там пример был о том, что один агент пишет код, а потом другой а��ент делает ревью и его разносит, да? А вот на практике сколько сколько таких итераций проходит для того, чтобы ээ ну был, чтобы ревью прошло? Слушай, я делаю одну, потому что у меня агент пишет код минут 15, потом ревью делается минут 7-10, потом он ещё минут

[01:00:00] 7-10 вносит изменения. И если А ты ещё ты ещё раз делаешь ревью? Второй ревью делаешь? Можно, наверное, но я говорю, я вот на неделе настроил экспериментально посмотреть, что будет. И как бы он после, а, на этом деле прощёлкал примерно штук шесть фич, да, вот, ээ, и каждую фичу он что-то находил, что-то делал по-другому. И я читал потом вот эти все отчёты. Вот. И я просто не решился, чтобы зациклить это до и метрики какие-то поставить. Наверное, это правильный будет подход. А, но пока не решился, потому что тупо это реально долго всё происходит. У меня времени не хватило, но, наверное, надо. Как ты это организовал? Через хуки или как? Папа Нет, всё просто. У меня промт. У меня есть некий процесс. Я сделал три несколько workflлоow. Первое workflлоow - это подшаманить э-э спеки, сами фичи эпики, да, чтобы привести их к некому стандарту. То есть он у меня запускает агента, читает эти все спеки, а делает небольшой депрессёч по коду, что там реализовано, делает небольшой депрессёч по докам, что там задокументировано, и задаёт вопрос, уточняющие, э, детализирует нужным образом спеки. После этого спеки приходят в нормативный вид. с��едующий workflow, который готовит техническая рефрения, он делает deпревью кода, то есть собирает, что сейчас в коде имеется. Он собирает под оком всё, что надо реализовать, то есть какая фича, какой эпик, что мы делаем. Он сопоставляет текущий код с тем, что

[01:02:00] надо сделать, и придумывает некое архитектурное решение, его фиксирует. Это второй этап. Третий этап - это ревью вот этого архитектурного решения. Вот. Ещё один агент заходит, всё это дело опять повторяет, смотрит и разносит это решение на предмет, что здесь оверинжениринг, там не учтено вот это, здесь вот это сделано ненадёжно, здесь это сделано лишним образом и так далее. Я его напромл, чтобы он сохранял, э, вносил изменения только, которые реально оправданы. Ну, то есть я контрил особенности нейронок усложнять всё, быть многословными, усложнять. И мне это не нравится. Я напромл его, чтобы он за этим следил. Вот. И он как бы там говорит: "Нахера вот это сделали, вот э��о, это не нужно, это не даст того результата, который тут пишут". Там же нейронки тоже, они же все оптимисты. мы там получим на 95% более лучшее решение и прочая вся [ __ ] вот эта. И по результатам вот этой критики есть ещё один прогон вырабатывается некое финальное решение. Вот примерно такой пайплайн. Подозреваю, что можно рейтинги зафигачить. Типа напиши там по какой-то системе критериев, там расставь числовые значения, там насколько всё соответствует. Нет, может быть, на них ориентироваться, сколько итераций таких делать. То есть, ну, как-то так. А если вот представить, допустим, у тебя есть какая-то система по подпискам, ты такой, а, да, даёшь ему типа какой размер задачи, пусть это будет эпика pay as go модель добавить. И это у тебя как это у тебя три промта, три код кода, которые в Dangerous mode запущены или это как-то они дёргают друг друга с код минус п по хукам или как это происходит

[01:04:00] вот эти три? Ну сейчас в��ё запускаю я. То есть я запускаю некий процесс проработки спецификации, потому что в этом процессе нейронка мне начинает задавать уточняющие вопросы. То есть она прочитала IC и говорит: "Ага, а вот здесь ты неправильно расписалке". То есть он не полный, а вот здесь у тебя USй не покрывает все те фичи, которые там Epic перечисляет и прочее. Ага. Вот здесь вот ты спецификацию на компоненты пользовательские не сделал. Мы типа описали, что он есть компонент, но ты не написал, какие есть требования к его поведению, потому что там в юскейсе упоминается, что он как-то там себя должен вести. И вот эти все его уточняющие вопросы задаёт, я ему там что-то отвечаю. И вот он приводит это всё дело в более-менее божеский вид. Потому что я подумал, что если мусор на входе, то мусор на выходе будет. То есть неправильно описал, что хочешь, он, соответственно, всякую херню понадел. Ну или не пол, наверно, пишешь, тогда додумает своё и Да, то есть, а как бы терпение это всё прописать по бюрократии, как надо, а у меня не хватает лично. Я как бы знаком с этим всем. В своё время читал лет там садь назад. Ну вот сейчас, кстати, ренессанс вот этой всей технологической бюрократии наступает, что если раньше все отказывались от этой всей чухни, потому что её никто не использовал, ни Ватерфол, ни проектирование, ни паттерны по классике, да, вот все об этом знали, но в на практике углы были все скруглены, то сейчас как бы нашлись, наконец, блин, благодатные слушатели этих всех паттернов. Это не Расети. И как бы и реально улучшается всё из-за использования. То есть первый режим он условно говоря там планмод или как-то более ручной.

[01:06:00] У меня есть workкflow, который называется разработка. Это проработка эпика или фи. Вот банально. Следующий режим на основании проработанного эпика и фича, там это другой workflow запускается, это говорит: "Разработай план реализации, implementation план". И вот он там пыхтит, что-то там разрабатывает. Я ему поставил вот такую такой workкфлоу, чтобы он в три этапа сделал. То есть разработал план, потом его отревьюил, потом внёс изменения на базе. И я читаю уже отревюные, потому что по моей практике, когда нейросеть даёт некий ответ, а следующим сообщением ты делаешь рефлексию, типа подумай и скажи ещё раз, то она, как правило, ещё раз что-то дельное доскажет. Вот. Ну, по этой же логике хотя бы один раз ревью сделать. Я вот замл её. В принципе, какой-то эффект даёт. Я говорю, я шесть фич прогнал по этому workркфлоу. Каждой фичи вот то, что я читал, она там что-то, ну, не совсем бредовое, что-то там докрутило. Вот. Ну и, соответственно, потом она просто согласованный план реализации берёт и по нему начинает фигачить. Как бы это уже все видели, как оно там полтора-д часа работает, как бы фигачит. Здесь, я думаю, никого не удивлю. Угу. Угу. Прикольно. Ну ты не это самое ты не запускаешь эти клод клод с минуспи? Не, это у меня следующий этап. Я, короче, решил следующим образом. Я сейчас вот натренируюсь на наработки Фик. И вот, ээ, следующим я хочу туда докрутить

[01:08:00] Gitфow, чтобы она, э, результаты нормально делала. Ну, то есть оно уже в фиче ветке делается, да? А, ну, чтобы оно его нормально потом пиар к нему делало и потом нормально мержило. Вот. И вот когда этот весь процесс замкнётся, тогда можно попробовать одновременно делать несколько таких процессов, потому что я, допустим, докручиваю туда фичи, чтобы я придумывал фичи. Агенты в это время их там более-менее с годным качеством реализовывали. Вот я бы только смотрел на результат. А когда я смотрю на результат, я бы фиксировал баги, и оно бы по ещё одному процессу в своим ветке для ��икса бага это всё дело исправляло бы, и это всё вливалось, вливалось, я бы итоговый результат смотрел. Вот такой у меня план. Угу. Мне сейчас голову пришла интересная. А можно я спрошу? Пока тема не ушла. Нис, а вот можно как-то, то есть, я так понимаю, ты хочешь сделать вот тоже типа через GitHub Hook как rev или или я не совсем на тебя понял? Ну, это уже вопрос реализации, можно будет сделать через GitHub, потому что Максим нас сагировал, я согласен, интерфейс GitHub, потому Да, тогда можно, получается, ты как бы одним агентом пишешь, второй параллельно ревьют и а вот у меня вопрос: а как ты себе представляешь потом отревью с другого процесса перебросить обратный контекст? Вот ревю написано, надо поправить и типа у тебя как это тоже через хук вернётся или что? Нет, всё банально. Там просто файлик в папочку будет записан. И у меня, короче, есть агент-ркестратор, который экономит свой контекст. Я вообще с ч��го началось тут субагенты в чате. Я подумал, что

[01:10:00] клодкод шизеет при компакте памяти. Он очень часто компатифицирует память и забывает половину того, что делал, что надо делать и так далее. Мне это не нравилось. Я стал думать, как это всё победить. И оказалось, что если делегировать из основного процесса клодкода всю работу на субагентов промтами, тогда реально происходит экономия контекста. Тогда он довольно много работы в рамках своего изначального ко��текста может сделать, то есть заоркестрировать это много работы и не шизеет. Но так как между этапами работы надо передавать информацию, а у него из средств коммуникации между субагентом это начальный промт, это он закидывает субагента задачу, и субагент ему потом делает ответ. А так как улоткода системный промт говорит о том, чтобы он был очень краткий, то ответ у него довольно лаконичный. И чтобы победить эту лаконичность, у меня все агенты пишут и запромчены, что у него есть некая папка задачи. Это выбора на место. Там создаётся для каждой запущенной задачи некая папка. И в промте всех субагентов говорится: "Вы должны писать отчёты в эту папку". Они туда пишут, и они, э, от этапа к этапу дают ссылки на файлы в этой папке, и их следующий агент читает. То есть, допустим, ревюер записал своё ревью, а тот агент, который исправляет по этому ревью, он прочитал файл, потому что оркестратор на самом деле очень кратко его, э, понукает, то есть там доволь��о лаконичный промто получается. То есть я их просил записывать тот промт, который они получили на вход. Они иногда слушаются и пишут. Ну и там как бы без

[01:12:00] особых деталей. А вот если агенту сказать: "И ещё ты должен прочитать вот этот файл отчёта", тогда он отчёт предыдущего агента засасывает к себе в контекст. И, в принципе, ему информации тогда хватает, чтобы качественно сделать свою работу. Это вообще классная идея. Ты описывал её в чате, но вот я понял, что под каждый под каждую задачу создаётся файлик. А сейчас вот, ну, я понял, что не файлик, а это папочка. И в папочке уже не один, а результаты работы ээ разных стейджий агентов. А вот есть какая-то мм эти структура этой папочки, что там должно быть, какие именно файлики или это зависит от конкретного флола и конкретных агент? Слушай, я вообще запромтил следующим образом. У меня каждый агент на старте своей задачи должен записать начальное задание, которое он получил в некий файлик, называется задание. Потом он делает свою работу. По результатам своей работы он пишет отчёт о своей работе. И вот я сейчас гляжу на папку, у меня реализация эпика. Сколько здесь у меня получилось файлов? А-а, ну, блин, как посчитать-то не понимаю. Ну, штук 40 файлов получилось. Вот, аэ, агенты вот пишут, э, ну, по по сути дела на каждого агента два файла получается. Начальное задание и конечный результат. Вот. И они Да, вот так. Так понятно. По цепочке. А как они А как эта цепочка? они нумеруются и как это ощущается, где каким агентам файлик, чтобы они чужого не почитали, лишнего не перегрузились. Я а запромптил, чтобы а значит

[01:14:00] каждому агенту при старте его задачи агент-ркестратор присваивает некий идентификатор его задачи. Вот он там случайным образом выбирает. Они там в разных задачах по-разному организовывают вот эту идентификацию. где-то пишут там агент ноль, агент оди. То есть имена файлов содержат такие вот идентификаторы. И написано, чтобы он имя файла префикс использовал идентификатор своей задачи. Угу. Понятно. Как-то так. Ну и его надо там реально сильно промть, чтобы он читал предыдущего оратора, что называется. Вот. Ну, как бы, у меня идея появилась, на самом деле, по поводу, знаешь, это автоматизация для бедных называется, да, можно сделать ээ этот опять же набор этих самых э баш файлов, вот, которые будут запускать, ээ, значит, кло��ы с промтами. Вот, значит, и, допустим, маркестрация двух агентов, работающих в паре над одной задачей, да, вот, э, то есть он это в баше нетрудно как бы организовать, а, и обмен их как бы ответами, вот, и запромтить их таким образом, что, в общем-то, как бы всегда результаты находятся в файловой системе. Вот. И чтобы они просто, э, смотрели тамдив, чтобы понять, ээ, что, значит, что изменилось. Вот. И, ну, то есть в плане результатов всё изменилось. И они будут работать просто как этот по процессу там программин, да? Вот. Ну, вы же заметили, коллеги, что мы опять изобретаем изобретённый лет 40. Это же Unixway классический. только на

[01:16:00] новом этапе развития. Раньше консольные утилиты туда-сюда стыковали друг с другом этими пайпами, да? А сейчас мы стыкуем агентов вопросамиответами. Вот. Ну и вот эти все записать во временный файл, да, передать хнл процесса, передать хдл файла или имя файла, да? Ну это же 100 лет придуманные паттерны, да? Ну а что бы не заюзать? Да ну так да. Так это же придумали не просто так, а потому что такие же были проблемы и также их решали. Ну да, да. Я к тому, что зачем изобретать велосипед, когда можно ракетный двигатель современного этапа прикрутить к тому же велосипеду? Да. Угу. И скажи, пожалуйста, а ещё вопрос. А ты в итоге ревью в мастерагенте как-то делаешь или у тебя, ну, я так понимаю, вот у тебя, не знаю, там задача, да, а что-то там один агент, не знаю, одно ушёл делать, второй, второе, а ты потом как это мржишь? Или это агент сам мрджит или ты это руками делаешь? Агент сам У меня, смотри, у меня есть Workflow. За, э, протекание workкфлоу отвечает агент оркестратор. То есть это его пром Ну, это я понял, да? Да. То есть изначально вот у агента оркестратора прот ты выполняешь вот этот процесс. В этом процессе есть такие стадии 1 2три, да? То есть ты там разрабатываешь техническое решение, ты ревьюешь техническое решение, ты вносишь изменения. Но каждый из этих этапов ты делегируешь субагенту. Кто бы делегировать субагенту, ты делаешь вот на этом этапе ему такие вводные даёшь, так его инструктируешь. И у меня есть в другом месте описанный процесс, как правильно звать субагента, что ему говорить. Вот. А значит, на ревью ты его вот так зовёшь, такие задачи ему ставишь. И на доделку ты его так-то зовёшь, такие задачи ему ставишь. Всё. Вот это задача

[01:18:00] оркестратора. Он только запускает субагентов. То есть у него фактически за время его работы вызов субагента на то, чтобы реализовать план, разработать первоначальный план, потом вызвать ревюера и потом вызвать агента, который это делает, несёт исправление. Всё. А вот ещё такой вопрос, э не знаю, может вы раньше задавали, но, по крайней мере, не видел ответа. А вот эти промты, они на каком языке пишут? пишется. Вот я видел Александр, когда-то был семинар, он на английском писал, но есть ли кто кто на русском пишет? Слушай, я пишу на русском и могу сказать, почему ещё в прошлом году я, ну, все же знают, что протненниринг надо всё на английском писать, вот всё такое. А я всегда использовал фронтирные модели для аи разработки. И я в прошлом году мерил качество. У меня был классный тест, короче, была система, мне нужно было к ней сделать, э, пучок юнит-тестов. И, ну, то есть вот есть некий кусок функциональности, это в Гите комит определённый. В��т и задача нейросети была разработать систему тестов. Я перевёл прот на английском, я сделал прот на русском и мерил качество выполнения этой задачи. Ээ, измерить его очень просто. Ты запускаешь набор тестов, что проходит. И разница в качестве между промтом на английском и русском языке для всех топовых нейросетей, которые я тестировал, а это Грок, Чат GPT, там каких-то актуальных моделей лод, актуальных моделей Гемени, вот эта разница отсутствовала, в принципе. То есть никакого плюса перевод на английский язык промтал.

[01:20:00] Вот если она ноке же побольше юзается. Ну, господи, в рамках того, что там контекст проекта, а, 50.000 токенов, да, экономия на промте двадцати токенов, она, мне кажется, это экономии на спичках. Ну вот я я, кстати, обращал внимание, что агенты и cloud код, и openагенты, ты когда на русский по-русски его просишь сделать, он внутри себя переходит на английский. Он как бы дальше начинает работать по-английски, но результат всё равно выдаёт на русском языке. Поэтому, похоже, он это делает как раз и для экономии только на Ну, тоже и для понятному ещё не его просто обучили. Его просто больше на английском языке обучали, поэтому он на английский и использует. Возно. Он просто у него внутренний промптинг на английском. То есть он сво к своим тулам для передачи там задач внутри себя. Он они просто внутренний промто на английском написали. Соответственно, естественно, он внутри по-английски будет общаться. Я просто ещё одну такую вещь добавлю. Используйте тот язык, на котором вы более полно можете выразить свои мысли. Вот это вот, пожалуй, будет вернее, потому что различие между тем, как они воспринимают языки, но оно по сути уже действительно чедо. Поэтому выбирайте тот язык, на котором вы эффективно сможете передать информацию. А, коллеги, вот ещё был важный момент. Я тестил на openсорсе, который у меня локально инференциался. На тот момент это квен был какой-то и что-то ещё, что же ещё-то тогда было? А, то ли, ну, короче, вот вы сами знаете, какие локальные модельки там в размерности 14Б запускались. И вот локальные sourceные модели очень чувствительны к языку. То есть квен-русски, ну, как бы хуже работает прямо сильно.

[01:22:00] Вот. И все небольшие модельки. Чем меньше модель, тем сильнее она чувствительна к языкам обучения. Но все фронтиные модели вообще нечувствительны. То есть после какого-то размера они всё превращают, они же ��ектора превращают всё в смыслы, и им хватает обучающей выборки, чтобы любой язык превратить в нормальные смыслы. Поэтому Максим совершенно правильно отметил, что качество промта зависит прежде всего от того содержания, которое ты сумел туда вложить. Вот если твоё содержание правильное, тогда результат эффективный. Если неправильно, тогда будет плохо. Это факт. Ну я я с этим согласен. Собственно, задавая вопрос. Да, я просто подтвердил свою своё видение этого. Спасибо большое. Но вот небольшое уточнение. Всё-таки вот мы говорим про начальный промт. Да, действительно, начальный промт, он ээ должен максимально э правильно описать идею. А вот мы же про агентную систему говорим, и у агентной системы внутри есть какие-то уже правила, да? И вот эти правила, они тоже могут быть на русском. Значит, я вот пишу и правила тоже на русском, и в принципе работает. Или вот правила лучше всё-таки оставить на английском? Слушай, ну я пишу на русском. Я думаю, что если я буду в продакшн что-то вводить, наверное, можно перевести это качественно на английский, постараться, там ещё смысл посмотреть, все дела, но я на русском пишу всё равно получше, чем на английском. Мой родной язык всё-таки, поэтому мне проще для скорости на русском, как бы на качестве. Не знаю, как это влияет. Может, коллеги тестили, но я разницы в качестве особенно не замечал. А вот разница, если пром писать правильно или неправильно - это факт, она есть. То есть, если я невнятно сформулировал или есть какая-то неконсистентность в

[01:24:00] инструкциях, вот в чём засада работы с агентами? У меня агент грузит пачку файлов. Он у меня мемори бан грузит там и тот, и другой файл подтягивает. Это дофига текста. обеспечить консистентный вот эти все инструкции, чтобы они все были непротиворечивые, чтобы использовали похожие термины, чтобы форматирование было ей понятным и прочие всякие нюансики. Вот это всё сложно. Ну, как бы, мне кажется, это большее значение имеет, чем язык. А, а вот ты это описывал, по-моему, на этой неделе или на прошлой, не помню точно. тоже взял это на вооружение. Я периодически сейчас запускаю вот есть вте правила, посмотри на них, найди противоречия и исправь. А вот кто ещё это делает? Это вообще нужно делать? Это wayй - это то, что у тебя работает. И же нету каких-то правильных ответов. Нет. Ну, может быть, может быть, ээ, м, есть какой-то другой путь, который позволяет, ээ, приходить к тому, что правила изначально непротиворечивые и правильные, да, и не нужно их периодически исправлять и вот этот мусор убирать, который в проекте накапливается. Ну, это, в принципе, основа любой системы, управляющей знаниями. То есть при поступлении новой информации надо бы проверить, не дублирует ли она существующую, не противоречит ли она существующей. и меняет ли она какую-то существующую информацию. Так что, да, по сути, любая входящая информация должна таким образом обрабатываться, если есть возможность. Я не реже, чем раз в пару дней провожу ревизию Мемори банка. И каждый божий раз

[01:26:00] там находится что-то, что туда нейросети понапихали дублирующее, что раздуто, что противоречит каким-то вводным. То есть, допустим, сказано в папке гайды или в папке архитектура не пихать -э то, что не является архитектурой. То есть туда пихать только что мы делаем, а как мы это делаем, пихать в другое место, в гайды, там, в архитектуре только что мы делаем. И вот они регулярно это нарушают. Мне кажется, это всё технически абсолютно обусловлено. Потому что у нейросетей при выполнении сложной работы, которые их агенты грузят, а агенты грузят их по полной, контексты там большие, а много очень вопросов ставятся, и они просто не всю не за всем успевают следить. И поэтому у меня есть такой класс агентов и такой класс скриптов, которые отрабатывают над мемори банком. Я их называю enorсеer политик. То есть у меня есть набор правил, и у меня агенты пробегаются по этим правилам выделено, фокусно. То есть, например, у меня marкдаун файлы все имеют фнтмета форматирования. Периодически модели забывают туда дописывать фронтмета. У меня есть агент, который за этим следит и исправляет. Далее у меня есть между некоторыми файлами кросссылки. Например, Epic содержит в себе ссылки на файлы фич. В Фиче есть ссылка на эпики, а по коду есть ссылки на фичи. То есть в комментах в файле кода указано, в рамках какой фичит код разработан. И есть некий агент, который пробегает по всем файлам кода, по всем по всему Мериб

[01:28:00] банку. И вот эти все ссылки взаимные перепроверяет �� поставляет. И вот куча таких вот политик, там, допустим, стиль кода, да, чтобы все файлы кода содержали по определённым правилам оформленные JS доки с описанием того, что делает функция, что она на входе, на выходе, там какие особенности поведения, какие у неё внешние зависимости. Вот эта вся хрень. Я считаю, что это помогает моделям, когда они читают код, чуть-чуть лучше его писать. Вот такое у меня есть заблуждение. Вот. Ну и вот ещё, а вот ещё ты описывал, извини, а эти метки должны иметь префикс, ээ, по-моему, ай, что это именно ээ агент ээ э поставил эту метку. Это ты м к этому пришёл, потому что так лучше или просто ну порядка? Нет, это была э мысль в чате под капотом. Там Ринат есть админ, вот он эти фишки использует. Вот. Ну, в принципе, мне кажется, тоже годный способ. Почему нет? Если я через обмен файлами между агентами они там что-то делают, то комменты в коде нейросети и так ставят. Может быть, их использовать таким образом даже и годная идея. Я просто ещё сам реально не внедрил, но считаю, что не бесполезная идея, потому что Гемени, например, через раз проставляет комменты в коде туду там сделать тосё пятые, десятое, что-то они там не доделывают и прочее. Не при корабо. А ты я из студии отошёл или или продолжаешь использовать? Слушай, я продолжаю, но я всё хочу теперь, так как м это работа

[01:30:00] механистическая, да, то есть запаковать весь проект, кинуть в Гемени, спросить там это всё, я подумал, что это тоже тогда можно автоматизировать агентами. И вот сейчас я делаю такой процесс получе, то есть, грубо говоря, у меня пока гипотеза, может ли агентским способом модель собрать контекст себе под задачу? То есть я ленюсь, чтобы собрать руками контекст, и поэтому кидаю весь проект Гемени, чтобы если ты кинул всё, то ты не можешь упустить что-то нужное, да, там будет всё. Из минусов в Гемене приходится получить на вход кучу ненужной ей информации для данного конкретного вопроса. Но руками это всё перебирать реально хлопотно, потому что если в проекте там сотни файлов, да, то как бы собрать под каждый запрос все файлы, не забыть ни документацию, ни архитектурные паттерны, ни тесты, ни файлы конфигурации, которые ей нужны, да, но это реально как бы хлопотно. Я подумал, что это можно автоматизировать. У меня была очень давно, ну как очень д��вно, полгода назад написана для автоматизации сборки контекста с помощью модели. То есть ты, она задавала модели вопросы, модель что-то там отвечала, и я бы это дело паковал. Вот делался конфликт для Репомикса вот под это дело. Сейчас я подумал, что то же самое могут делать агенты. Теперь, если руками под каждый вопрос собрать контекст, тогда, ну, точнее, не руками, если агент его соберёт по неким правилам, тогда будет, наверное, качественный. Вот эта гипотеза, что это будет тоже

[01:32:00] качественно, нуждается в проверке, но тогда проектировать. Я тут, кстати, подкинул такую штуку, собственно, столкнулся. Ну, как столкнулся. Просто в очередной раз обозначилась проблема того, что в клодкоде нет собственного индексатор кода, а, и вообще индексатора проекта нету. И это всё-таки вливается иногда в проблемы с тем, что он там что-то недонаходит, вот лентся запускать субагенты, него все места проекта пролезает в процессе. и встретился с таким мнением, что а чувак, ну, который в принципе неплохие обзоры, модели делает там и вообще, в принципе, инструментов для работы с кодом, аа сравнил реализацию индекса кода в рудено вмен. И, как он сказал, типа работает сравнимо по качеству. Амен индексация очень хорошая. То есть это вот у него индекс проекта, а где-то на сервере строится, он не на вашей машине находится, и он очень эффективно контекст предоставляет агенту своему. То есть буквально агент в свободной форме задаёт вопросы этому контекстнну, а contex engine возвращает, а релевантные куски кода довольно-таки эффективно. То есть я его там тестировал на проектах с нескольким миллионом токенов, и он практически моментально возвращал релевантные куски для того, чтобы начать работать над задачей. Так вот, собственно, вкод тоже появилась где-то вот не так давно, короче, появилась реализация индексра для кода, то есть тоже такой своеобразный контекст engine. Она надран основана, и я вот думаю вырвать её оттуда, а обернуть в MCP и присобачить к вод-коду. А эта задача такая, скорее всего, не

[01:34:00] совсем тривиальная, да, и довольно-таки это много времени может занять, но просто я к тому, что если кому-то интересно в том направлении попробовать поисследовать что-то там вместе, может быть, пообсуждать, можно вот просто туда пообсуждать, посмотреть, как бы это можно было бы сделать. Ну, можно даже на эту тему сделать такой как бы brainшторм ��вонок. Угу. Кому интересно, да, было бы было бы здорово. И линк кинь в чате, да? О'кей, Максим, кидай. Я тоже как, ну, как бы ничего не обещаю, но я точно посмотрю, потому что мне кажется, это перспективная идея. Кстати, по поводу у меня ещё на эту тему есть соображение насчёт того, что я больше в агентский поиск верю, но его надо точно чем-то усилить, потому что он реально сейчас медленно идёт. Ну да. Кстати, по поводу Дран. Вот я несколько раз, когда изучал, какие векторный есть, всегда он считался лучшим. И мы ещё обсуждали на том звонкемра. И вот они тоже РН юзают. Как будто это лучшее решение по мбедингам выходит. Есть ещё турбопу. Нет, просто расти написано. Но он собака дорогой. Вот. А кто? Кто? турбопуфер. А его этот с, господи, курсор его использует, но он такой, это cloud сервис тоже вот для охранения бедингов. И они там действительно тоже так неплохо работают. Но на самом деле, короче, если говорить прямо уж заморачиваться по контекстнже, но я находил прямо хорошую подборку статей, которые фронтир исследований в этом плане представляют, и они там, а, каждый из исследователей, каждый из групп исследователей строит контек engine, они там knowledge граф используют, э, там сбоку где-то ещё какой-нибудь рак припелен и вот это вот всё. То есть там довольно-таки много интересных технологий, но это пока не выливается в готовый реализации. То есть они, конечно, их сравнивают там с реализацией

[01:36:00] в аугумента, в курсоре и всё такое, но, скажем, из набора этих научных статей, судя по тому, что они не так уж много кода тебе дают, не получится сделать самому contex engine. Вот единственная реализация, которая более-менее готовая, которую вот я нашёл вот знсурсных, это вот в рукоде. Вот поэтому можно попробовать с неё начать. Вот. Короче, курсор конструктор Cloud турбобуфер подкл��чил N8N и и поехали. Типа того, да, пиантропика. А треси кто-то использовал в итоге? Просто я, насколько понимаю, это максимально тупое, простое и эффективное решение. Если проект, конечно, не там миллион строк кода. Какое? Эй, по-моему, его используют хитерни. Я и говорю, что там очень хорошо работала эта вся тема, если честно, и она очень простая. То есть он просто генерит по сути файлик. А с классами. Ну, то есть он делает такое угощённое дерево, и по нему агент уже очень хорошо навигируется, потому что там нету как бы контекста самых самой реализации, но какие классы есть и какие у них контракты, там всё довольно легко делается. Это да, честно думал взять свою Я, если честно, думал взять свою приблуду. У меня был индексатор проектов на триситере. Как раз он что делал? Он писал то, что моделям сложно было расковыривать. То есть он писал карту кода такой скелет делал из файла. В этом файле были все комменты, потому что я в JSDOG храню много информации, да, там были сигнатуры функций и всех сущностей верхнего уровня, особенно которые экспортируются. И там были не назвать это колграфом, но для каждой

[01:38:00] функции перечислено, какие внешние зависимости она использует, то есть что внутри в теле функции самой э вызывается. То есть, допустим, там какие-то внешние функции, какие-то переменные, может быть, глобальные и так далее, которые она использует. Для того, чтобы модель это всё прочитала, ей надо полностью загрузить файлы и проанализировать весь код. Это медленно. А я делал ей такую карту, чтобы она при решении каких-то своих вопросов на неё опиралась и определялась, нужно ли ей читать этот файл вообще в принципе или нет. И у меня была опция, что это всё можно было с той или иной степенью детальности делать. То есть, допустим, либо просто получить список сигнатур этого этого модуля, что там объявлено, либо вместе с комментами получить, да, потому что JSDC предлагает очень большую информацию. Там всё описано: и параметры, возвращаемые значения, и типы, и описано, нахрена они нужны, и дополнительная информация там есть. То есть как бы мощный такой контекст формируется. И вот эти все внешние зависимости, чтобы она понимала, что от чего может быть зав��сеть поведение функции там даже не смотря исходные код функции. Круто работает. Ты не пробовал использовать ты не пробовал использовать этот диаграммы диаграммы для этого? По идее на базе вот этого парсинга, на базе, который выдаёт триситр, можно делать любые диаграммы там. такие пятый, десятый в любой нотации, но не пробовал использовать. Просто есть тулы, которые делают эти диаграммы, я так понимаю, из кода, но я использовал банальный трисет. Нет, смотри, этот, ээ, ну, практически любая модель сейчас,

[01:40:00] да, вот она умеет генерить ээмей, допустим, диаграммы, вот, и, ну, как бы на основе кода или или просто там ты просишь дизайн что-то, она может генерить. Вот. И, ну, диаграммы вот, ну, по моему опыту, они ещё более компактное представление, э, чем чем пострипанный код. Можно с точки зрения компактности, да, это классная идея, надо вот в этом направлении подумать, потому что у меня было весь смысл, чтобы не грузить полностью код, а грузить что-то, то меньше, чем этот код, но которые даёт тоже достаточно информации, какой-то компромисс найти. Первая моя итерация была, я думал грузить нейросеткой, делать доку, э, файлу, да. Вот. Но как бы это не очень работает, потому что ей не всё, ну, не хватает ей полностью на базе доки. Ну, хотя тоже работает неплохо. Она всё равно чуток компактнее, чем код получается. Но всё-таки это же какой-то аксмарон, когда ты вместо кода грузишь документацию, которая по объёму очень похожа на этот код. Как-то, на мой взгляд, неправильно. Денис, а ты в виде тулы это не пробовал ей давать какой-нибудь, чтобы она могла, когда не были так популярны. Вот сейчас, наверное, это с 99типроцентной вероятностью стоит обернуть в тул в виде MCP сервера хотя бы локального. Это просто. И как бы дать модели? Нет, не пробовал. На тот момент не пробовал. Это был консоль. Я всё понял. Что вы поняли, пришл, когда копипест с веб-чатами был в тренде? Я пришёл к тому, что, короче,

[01:42:00] документация у меня занимает ну где-то, наверное, раз в 20 меньше места, чем чем код. Вот. Но я я инфорсую так, чтобы у меня, короче, в документации предпочитало диаграммы тексту. Ну, диаграмма, да. Александр, а ты к этому пришёл ээ как были какие-то тесты, по которым ты понял, что лучше модель обрабатывать именно диаграммой, чем, ну, какое-то там, не знаю, логическое описание. Ну, а да, я тестировал это дело уже, наверное, года три, как тестирую. Там, короче, есть такое процесс описан. Сейчас я скажу, там есть, короче, ну, вы все знаете, я проник концепции Мемоory банка, да, как структурированное структурированное хранилище спецификации по твоём проекте. И эта концепция изначально появилась в Клайне. Ну, вру, наверное, она ушла. Вот. И нашлись, естественно, азиаты, которые зафорсили эту концепцию на максималке. Есть, я бросал в чат ссылку на гитхабе, там на курсоре, э, люди делают меморибан, и они его оптимизировали там по-всякому. Там э весь этот GitHub очень интересен логикой того, как они оптимизировали весь процесс. То есть они говорят: "Мы вот использовали Memory Bank. Вот первая трасса, с чем мы столкнулись, такие такие проблемы, как мы их решали? Мы сделали вот это, вот это, вот это, потому что это вот это сработало, это не сработало. Вот и там таких куча итераций

[01:44:00] оптимизации их мемори банка, как они эволюционировали его. И одной из оптимизаций было типа мы процесс объясняли на словах, оказалось, что нейросети прекрасно понимают диаграммы мермейдовские, и они их понимают лучше, чем текст. То есть для миросети объяснить диаграммой последовательность действий гораздо проще, чем описать эту последова действий словами, потому что слова многосложные и могут быть неправильно поняты, а диаграмма она понимает довольно однозначно. В этом смысле, ещё раз подтверждение слова, что это не только компактнее, но ещё и содержательнее. Да, слушайте, а вы сами как код читаете? Вы же, наверное, идёте, смотрите диаграмму, а потом уже компоненты идёте смотреть. Или как вы сперва методы тыкаете, а потом смотрите, как оно собирается в проект. Ну, обычно сверху вниз идут люди. Нет, даже люди так делают. Ну, в смысле, это логично. Ну, не всегда логично. На vision способности модели раньше особой ставки никто не делал. Просто здесь оно так. А в чём вин-то? У тебя просто текстом объяснена взаимодействие компонентов. Тут же нету вина вообще как такового. Хотел сказать, что это обманчиво, это не vision, это не диаграммай, это не vision, это совокупность текста. И там вот эти коннекторы, которые текстом прописаны, они для моделей, ну, весьма понятны. И, в принципе, этот формат весьма понятен. В этом смысле получилось здорово, да? Ну, это как формальный язык какой-то получился, да? То есть он вполне следует определённым правилам, закономерностям, поэтому, да, его нейронки так неплохо понимают. Там какие-нибудь меня наруже понимают неплохо. Там Алекс кидал триситер какой-то уже готовый MCP. Его кто-то смотрел в итоге

[01:46:00] или оно так и лежит, ждёт своего героя? Ну, я не смотрел. Ну я я их поставил даже себе несколько штук, но тестов с ними я ещё толком не проводил. Понятно. Алекс - это который я или которы��? Который ты. Да, я уже, видишь, сам и забыл, какой именно у меня в звёздах стоит, но неделя была жаркой. А в рейл ты имеешь в виду? Да без разницы какой. Просто интересно, насколько хорошо сделали, если кто-то потестировал посмотреть. Я-то делаю, ну, как бы я тоже, как Денис, использую самописный тылуй, но, честно говоря, ну, то есть нормально работает, если я прямо поршу, типа, заюзай тулу, сделай вот так. А если бы это был какой-то, ну, то есть хочется, грубо го��оря, абстрагироваться, чтобы она сама понимала, когда ей надо заюзать хочет более автономный вариант. Я знаю, хотел, знаете, чуть-чуть вернуться. Получается, у нас источниками новшеств являются ээ Рукотй и Аидер, да? Хотя Идер, я не знаю, может уже как бы побираться пошёл бедный крутой чувак. Ну, у Айдера было много концепций прикольных в том плане, что они он один из первых вообще стал агентов юзать и довольно много задачек у него было, причём и ранних, когда эти модельки были совсем чахлые и очень много этих костылей в итоге, ну, до сих пор переиспользуется, но сейчас бы я не смотрел это как источник каких-то крутых инноваций. Ну вот, получается продолжает keep идти, например, вот memory bomранг концепт. Вот Максим сейчас подсветил икс base. Кстати, они тоже первый сделали. Кого? Модель стиринг. А стиринг. Стир как ру как руль управляется. То есть они там в процессе чата с моделью периодически ей изнача��ьные инструкции скидывают, чтобы

[01:48:00] она не забывала, в каком направлении мы движемся. Я вообще с этим даже не сильно знаком. Я слышал это слово Денис сейчас использовал для Киры или кто? Семантически чуть-чуть другое получается. В случае с Кира оно чуть-чуть по-другому работает, но в принципе, да, это тоже это дополнительное понукание модели двигаться в определённом направлении. А может на интересно оно работает? Вот э там есть у стиринг файла, почему он называется ещё стиринг и специально не просто спецификация, а именно какой-то, как переводится с английского. Стиринг - это рулевое управление, это вождение, по-моему, или кручение рулём. Угу. Руление, то есть, если, наверное, ближе всего по-русски правильно перевести. Короче, смысл такой, что это некий файлы с инструкциями, причём практического толка, как использовать некие фичи, связанные с тем или иным э доменом, с концепцией. Допустим, база данных, там, не знаю, файловая система. тест или ещё что-то. И у Кира есть возможность указать в фронтмета этого мар файла, каким вопросом вязать этот файл автоматом. То есть там просто выбирается, допустим, что если ты а файлы базы данных с ними работаешь, тогда нужно потянуть вот этот стиринг-файл, и он тебе там покажет, как правильно этим всем пользоваться. То есть у тебя есть, допустим, некий код в системе, у него есть некая апи, и ты, чтобы объяснить модели, как этим апи пользоваться, нап��сал срингфайл и поставил, что если ты вот этот файл с ним работаешь, тогда вот этот стиринг-файл в контекст падает. Ну, довольно оригинально. Я такого вроде больше нигде не видел.

[01:50:00] По-моему, это похоже на курсор Rформат MDC, когда ты задаёшь маски типов файлов и в том числе пути. И какие исследовать RС они обязаны из Ну да, ну да. Это вот на эту тему же, да. У них там какие-то ещё были. Ну, короче, в любом случае, э- все, кто работают с агентами, в той или иной степени решают проблему контекстов. Они знают, что модели забывают всё и не всё знают. Им в контекст надо релевантное что-то полезное положить. И они тем или иным способом пробуют этот пазл собрать. Ну, этот, в принципе, годный способ. А интересно, к чему я ещё пошёл? а-а этот мм рукот иклай. Вот я сейчас в чатике тоже задал такой вопрос, поднял. Я, насколько помню, последний раз, когда я кого-то спрашивал на эту тему месяцев 3-5 назад, было то, что а рукод они стали те, кто типа агент сам себя, короче, как автономно, как сейчас-код действует. Из-за этого они разногласия разошлись. Я только не знаю, кто там. Китайцы, американцы, русские, нигерийцы, что сомнительно, а-а, или кто ещё там. И вот они сейчас идут полностью разными путями, повторяя друг друга фичи или связываются где-то. Я вот полистал их релизы, вижу contribбution примерно похожие. В Stars в два раза, по-моему, разница. Ну, квайн исходный больше, но вроде бы по фичам рукот дальше и по девелоперам ощущение, что на 30% чуть-чуть у них этот ёмкость. А кто вот как изучал? Просто любопытно, как будто для истории. Раз уж это инструмент номер один новшеств, полезно, наверное, знать

[01:52:00] то, что знает на эту тему. Ну, я периодически просматривал доку у Клайна, чтобы, ну, что-то такое вдруг у них вычитать. У них вполне нормальный блог. Они там более-менее адекватно пишут что-то новое и интересное. Вот можно почитывать. Discord очень активный. Я вот как какой самый активный дискоord топ пть. Я много в них не сижу. Я обычно в целевых Discord комьюнити так иногда что-нибудь посматриваю. Типа Эйдер тот же самый. А вот рукот, а госукодер есть такой чувак. Он обзоры моделей и инструментов на Ютубе делает неплохие. Но я не активный участник сообщества. Я чисто туда за новостями прихожу. Иногда что-нибудь посмотреть по нацио��альностям. Интересно, кто впереди планеты всей намешано? Как обычно китайцы, американцы, русскоязычные люди. Вот, как ни странн��, китайцев там почти нету. То есть там в основном именно западный сегмент представлен. Ты имеешь в виду в дискорде? Ну, по крайней мере, в тех сообществах, в которых я состою. Да, в дискорде. Угу. У них можно забанить какие-то свои типа инструменты. У них и GitHub же свой, если я не ошибаюсь. Там GTI есть у них Alibaba, Model Scope, ещё что-то я слышал. А это Model Scope, это Hugin Face. Кстати, вернусь немножко к теме источников. А получается, когда Яйку спрос��л, подсказал мне, что вот Хагин Face смотри. Хотя непонятно, что смотреть. Мы хантеры за инструментами для кодинга, да? Аген - это, ну, модельки новые

[01:54:00] появляются, пары, архив тоже самое. Вряд ли есть огромная комьюнитищиков и всех там, если честно, и в дискорде, и там, и они в чате. Ну это по моделям получается, не по инструментам для кодинга, да. Но разве что модель для кодинга не было нормальной вроде Open не по моделям. И у Хагинфейса есть свои агенты. Ну там больше, да, там более такие хардкорные мельщики, но инструменты у них тоже обсуждаются. Ну как, кстати, курс агентов, кажется ты, Сергей, проходил Face? А, ну я я начал, да, но у них свой такой, блин, кстати, у них прикольная идея. У них вот именно то, к чему сейчас курсор пришёл. Они эту идею давно слушали, что а давайте мы как бы сделаем такого агента инструмента, который более там разумный агент может вызвать и что-нибудь от него запросить. В целом очень прикольная концепция, и они одни из первых её кушали. Ну а так, ну в смысле обычный курс проагентов что выдающегося. Кстати, я вот прямо думаю, что к лод-коду привязать агента для второго мнения, ну, вообще не безынтересная идея. То есть какой-нибудь Gemini 2,5 Pro, чтобы MCшка вызвала и спросила мнение. Это, ну, мне кажется, может улучшить это как быстрое ревью такое, и там реально качество повысится. Думаю, что да. Да, идея прикольно. Ну, даже, по-моему, по сути самая умная моделька - это GO3 Pro, да, по рассуждениям, по всему, по архитектуре. Ну да, О3 здорово отвечает. У неё контекст небольшой. Вот единственный недостаток, что 128К, по-моему, в АПИ у неё. Ну, сейчас ценник на неё упал. Можно, можно, наверное, её звать. Да, я, конечно, так. Ну это это получается как пор программированию, только с двумя

[01:56:00] агентами там или с двумя яичками. Ну и можно гемени, наверное, присобачить через клиента. Кстати, вот как вариант, чтобы курсор т��м, ой, cloudди код вызывала там это и через неё, наверное, можно это сделать вообще автоматически полностью. Вообще GI 2 с по когда-то мне очень зашёл своим контекстом. Я вот всё ждал в мае в концепкинг, даже купил ультраподписку, но они кинули и до сих пор собаки уже 2 месяца не дают её. Никто не слышал апдейтов, знаете, на 2 млн токенов и чтобы был как О1 Pro или O3 Pro, типа по 3-5 минут думала. По-моему, в АПЕ только есть йлист. Не, она в она в чате так делает, а в этом вапе не знаю. Разве в чате уже 2 млн токенов? Не, я имею в виду в чате есть deep thinking. А сколько там контекста в чате, я не в курсе. Алло. Я в чате не видел, если честно. Я анонсов тоже не слышал. Я слышал, что все ругались, что обозначенная фича, она немножко отложилась и её не выкатывают. Угу. Ну, там заявлял их этот, что 10 млн токенов вообще они тоже тестировали. Какой-то парень, кстати, русскоязычный, который участвовал вот в этом отделе. Где-то я пост такой читал, кажется, у селошный, но такие вкусные вещи не выкладывают в контекст. Ну, мы поднимали, кстати, вопрос по поводу ТПУ. Кажется, на одном из звонков такой был тезис. что если open все начинают у гугла просить тпушки, чтобы чтобы чтобы, наверное, вот и только их тпушки могут делать большой контекст, а вот эти GPU от Nvidia все

[01:58:00] застряли на 200к токенов, типа. Ну я вот вообще не представляю, я обзоров не читал вменяемых. Кто бы объяснил, как для архитектуры современных невертей ограничения карточек они влияют? То есть может быть действительно, что Nvidia она у неё очень быстрая память, но она же очень дорогая, её не так много. Может быть, это ошибка была системная, что надо было памяти побольше делать, было бы покруче, пусть помедленнее бы работало, зато модели были бы поумнее. Угу. А тут, кстати, дипсик и китайцев большая надежда. Если Дипсик произвёл такой шум в начале года и вроде Компартия выделила там какие-то хулирды денег на поддержку отрасли, то, может быть, раз китайцы сейчас э делают следующее поколение своих чипов, и у них вроде в двадцать шестом году должно всё получаться, может быть, они запроектируют всё правильнее, у них будут нормальные размеры памяти и у них будут нормальные линки сделаны. Там же ещё не только в памяти размер, там раз вопрос, там размер, как ноды друг с другом взаимодействуют, насколько быструю между ними надо делать взаимодействие. И для архитектуры нейросети, как распределять вычисление по вот этой вот вычислительному кластеру тоже значение имеет. И может быть китайцы сделают вообще классно. Они же на вычисление всяких биткоинов сделали, асики и быстрые, правда, такие довольно здорово работают. Почему здесь не смогут сделать, тоже непонятно. Я каждый раз, когда слышу китайский реч, у меня что-то страх начинается, паника.

[02:00:00] Они справедливости действительно умеют делать типа некоторые вещи просто потому что их много. Но я просто работал в Huawei я знаю, как там разработка ведётся в 99% случаев, поэтому мне страшно. Но этот 1% скорее всего может, да, плохо. Ну как типа, а примеры, да? Ну это просто плохой код, типа, там чуваки не шарят. Типа, они работают 24х7, но они не шарят то. Ту работу, которую ты сделаешь за 8 часов, они сделают за 24 часа, будут спать в офисе на раскладушка свой, выгорят 10 раз, но их никуда не отпустят. И вот так вот там всё типа ведётся на компарте достижения. Но опять же, это типа по большей части, там есть действительно умные ребята, и вот их может быть кидают на проекты, что они, конечно, могут или лбом пробить стену. А, но всё-таки я смотрю на победителей матлимпиад и те, кто папиры пишет сейчас азиатских фамилий там, наверное, ну, блин, ну, процентов 90. Вот это нет, если если говорить про математику, они прямо очень сильны. Типа в этом, ну, то есть, что азиат, математика - это стереотип такой известный. Вот. А если говорить именно вот там, не знаю, про разработку, то, ну, так уж, ну, deep пси-ты реально сделал кучу оптимизаций таких, которые, в общем-то, может быть, они известны были, но они точно были не публичны, и они сделали это на уровне ядер, там, худопроцессоров. Они архитектурно в свою сетку, допустим, мультиток. Это вообще, в принципе, кто, не знаю, разбирался кто-нибудь в этом деле, она довольно прикольная штука сделана вот и довольно новаторская. У них ещё там были всякие внимание, архитектура НСА тоже обещает большие контексты. Ну,

[02:02:00] придумок-то много приду. Не, они они в этом плане могут дать. Это тот же самое, если даже смотреть этот ээ 5G сети, которые Huawei сделал, то что же они придумали, типа сделали там 6G они или какие 10 они уже делают, типа просто, э, тут проблема в том, что это делает реально там типа если даже не один, а 0,1% типа китайцев. И одно дело, когда они это вну, то есть типа одно дело, когда они это внутри у себя там ис��ользуют, другое дело, если этим все начнут пользоваться, там вообще может что-то страшно начаться. Ну псик-то лавка, когда она взлетела, в ней работало, по-моему, человек 200. И американцы что-то хотели все, потому что это страшно, когда там мета с неограниченными бюджетами, там тысячи исследователей, у Гугла там бюджеты бешеные, Open AI, там тысячи людей работают. И тут их всех уделывает Deep ПСК, в котором 200 китайцев. Ну, конечно, как бы, ну, эти эти китайцы ещё нет, что что американцы ещё бесятся, потому что эти китайцы, скорее всего, ещё с американским образованием каким-нибудь. Типа они обучились в США, потому что, ну, и в Китае я не уверен, если честно, что именно прямо образование норм. Кажется, они все в Америку пытаются веехать, кто кто может. А потом они возвращаются, типа, и вот делают типа на вред США. Поэтому они типа США не любят, когда они, например, там то же самое сейчас типа если ты там на студенческую ты русский, ты на студенческую визуйдёшься. Они ещё 10 раз подумают, типа, вдруг ты вернёшься там к Путину. Секреты расскажешь американского образования? Ну, сложно играть с горы. Вот такая игра видимся она с запрограммированным проигрышем. Просто вопрос во времени, когда и очередная империя падёт. Но из

[02:04:00] интересного, что псик-то хоть и обещали к маю выпустить, они же выпустили фактически новый чекпоинт только. А модельку новую R2 они не выпустили. И, как бы сказать, в принципе, не��огично было дать к маю R2, потому что ни у одной американской лабы, топовой, даже гугла, даже Меты, даже Open AI, большие модели чаще раза в год или около того, они не выходили. Даже антропиги свой четвёртый опус выпустили через год после третьего. Вот. А это лабы, ну, реально топовые, с наработками, со всеми пирогами. Иди псик ещё, ну, ждём поздней осенью. Вот. И в чём фишка-то? Сейчас К2, да, была на хайпе. Все отметили, что это обычная вроде нейросетка, у которой очень запредельные ��енчмарки для такой нейросетки без рининга. И если сверху этой модели поставить рининг, ну, непонятно, как показатели стрельнут. Вот у Гугла стрельнуло очень сильно. Помните, чекпоинты 2.0 были у Прошки, а 126, по-моему, какой-то такой был долгое время. Вот. А потом они сверху этого прикрутилинг и показать. И получился прошка 2 с по иточеский рост показателей был. Она сразу стала умнее там на какой-то бешеный процент. Вот у Гугла вроде так получилось. У антропиков рост был не такой, но у них клод и сам по себе умный был. У дипсиков получился неплохой рост. И если Кими сверху прикрутит рининг, тогда, ну, что получится там, тоже очень

[02:06:00] интересно посмотреть. Вот. Но они уделают, по-моему. У меня какое-то такое ощущение складывается. А какой сейчас, кстати, стейт вообще у реинформен лернинга при обучении? Ты что имеешь в виду? Ну, типа, они вроде тут, я так понял, у них закончились данные типа интернета, и они типа начинают там типасенты расширять. Вот тоже, кстати, непонятный для меня загиб. Вы помните, что в начале года все топовые американские лабы закрыли цепочки размышлений для того, чтобы коварные китайцы не украли все американские секреты, которые выбалтывают в мыслях модели. Антропик же вроде типа он даже подписывает их. Нет, ну он их подписывает, но они заменяются все на суморизацию теперь у всех. Антропики тоже разве? Да. Да. Раньше вроде бы возвращал. Ну о'кей. Вот. И короче, а потом оказалось, когда ПСИК выпустил свои техпейперы, что для обучения моделей вот эти трейсы особенно не нужны. Ну и как бы китайцы уже всё своровали, и им, в принципе, хватит. Там только чуть-чуть подтюнить на формат выдачи. А основное обучение они reinforce learningнингом делают. А для reinforce learningнинга не нужны никакие трейсы. Там нужно функцию в обучении правильно воткнуть, которая ревар будет давать. И как ��аз с этим были вот эти все новации дипсика и связаны там при обучении, вот эта вся хрень. Вот. И как раз сейчас вот буквально всялошне же обсуждалось результаты у коп, что они там на маталимпиаде какие-то новую модель внутреннюю тестировали, как всё круто там было.

[02:08:00] Ну и говорили, что это благодаря новациям в механизмель обучения. И вот сейчас вот это опять, да, на топе. Короче, у нас, кстати, подходит уже середина нашего звонка и запланированная кульминация, точнее, не кульминация, а следующая часть и этап. Предлагаю поприветствовать нашего спикера. Рима, привет. А, привет всем. Ну, мне на самом деле сегодня нечего показывать, потому что а я сегодня 2 часа уже пыталась застатапить. Я просто вчера подключа подключила MCP сервер как раз Hagen Face и HTML to design. И хотела как раз показать, как можно делать resarch и потом, собственно говоря, из КД всё это импортировать аа дизайны в фиг. И у меня сегодня всё полетело. И, в общем, теперь ничего не работает. В итоге я 2 часа тут это всё пыталась починить, а потом пошла на deep псик, и он мне сказал, что я вообще всё делаю неправильно, что мне нужно срочно удалять токен, что я его exposed и, короче, вообще всё удалять, потому что я что-то тут нарушила правите какой-то. И в общем, я сейчас си��у немножко в стрессе, как бы мне очень хотелось вам показать, но у меня ничего не вышло. Так, ну включай камеру. Сейчас будем смотреть чего на тебя. Я шучу наживание. Вот и экран будем чинить. Собралось столько программистов. Видел одну фотографию?

[02:10:00] А сейчас, пацаны, давайте Team viwевр подключаем. Сейчас сделаем. Сейчас всё сделаем. Так, я, короче, смотрел на твою аватарку и, в общем, ничего этот не понял. Можно тебе вопрос? Токен, короче, заспариуса или тебя антропик сказали, что забанили? Нет, что я его полз, что я нарушила прависи, когда пыталась создать код, чтобы подключить этот хагин. Это страшно. Страшно, это не страшно. Это он просто предупреждает, говорит, что типа не надо вообще мне присылать твои эти нас потом хакнут, и тебя тоже хакнут. Дима, ты же в соседнем подъезде, иди почини экран. А я уже всё поудаляла. Не, это он просто говорит, что типа, ну, нельзя, типа он считает, что он небезопасен и ему не стоит присылать свои токены, потому что Да, он просто предупреждает, потому что типа Но на самом деле ничего страшного. Так что мы тогда можем сейчас Рим всё. Ты, кстати, у тебя, Саш, сраное представление об Эре. Мне, я думаю, полтора часа ехать. Да. А нет, да я А не, я я понял. Я так Да, чтобы юмор поддержать. Ну у вас не как в Лос-Анджелесе там, вот в Лос-Анджелесе - это пробки. А так у вас У нас тоже пробки. Что мы хуже ЛосА? У нас ещё и толлы, прикинь. Ну да, платные платные дороги. А, угу. Баксов за прайс в Сан-Франциско. У меня есть, ну, с Истб. А так и Ну, можно в объезд, можно в объезд, будет дешевле.

[02:12:00] Ну, в объезд бесплатно, да. Можно Uber включить или нас довезёт твой пассажир, оплатит дороги. У меня есть такой друг лайфхаком пользуется. А, кстати, да, да, да. И мож��о поставить, что ты везёшь там троих человек и тоже ездить бесплатно. Вот такое, да, я слышала. Такая долина непростая. Я недавно узнал, кстати, ну, это в топ пока там что готовьтесь шарте. И для меня было сюрпризом. Я узнал, что Uber забирает 70% поездки себе. Типа всего 30% водителю остаётся. Это как-то вообще неправильно. Ну я слышал, там у вас этот робот такси же запустили и там пикеты их поджигают, переворачивают. Нет, было на роботокси. Ну ты прикинь, ти��а ты типа поездка дорогая, а ты всего 30% получаешь. Это жесть. Типа за что там Убера 70 забирает? Яндекс я не знаю сколько забирает меньше марнация машины твоей новой Тес будет там на тебе вопрос за что он неверный правильный вопрос а типа почему вы хотите так много денег да я я кстати не знаю ктото кто-то знает сколько Яндекс забирает признавайтесь 50 по-моему 50 вот 50 на50 у них вроде бы. ��лин, ну это тоже грабёж вообще. На самом деле, если давайте митинги, если сделать пиртупир альтернативу Уберу, вот которая там пиртупир, децентрализованные такси, да? Потом как с этим потом как с этим сигналом там будет, типа этого Джейди Венса с Трампом в чат добавили и всё слили.

[02:14:00] Дадада. Тра, Трамп будет это самое по по пиртупир этот машину заказывать. Да ну, Теслер. Угу. Он же любит Теслер. Ладно, что-то мы это Давайте, да? А, Рим, так, то есть у тебя что там было в код-коде? У тебя токен сейчас не подсасывается или что? Ну да, у меня получается в клоде не подключается MCP сервер на Хагинфейсе, на HTML design. И я не могу это никак решить. То есть в итоге я уже удалила токен, а, и вообще всю конфигурацию с кодом, ну, которую я подключала, потому что псих сказал: "Всё, срочно удаляй". В общем, всё это exposed. Я тут перепугалась немножко. Надо было Игоря спросить, прежде чем удалять. Ну куда его спросить? Сегодня же утро суботы. Китайцы, ребят. Ну это, если я правильно понял, это токен просто для который генерируется в Hagen Face на подключение к нему. А, да, это его в чат лмке прислал, типа, и она такая она говорит: "Я за себя не отвечаю, как бы сожги всё до прочтения". Да. Вот забавно, кстати. Джиминай так не ругается. Она такая: "Ну ладно, поехали, давай засунут. Всё, я о'кей. Просто то американские, они все знают, что НСА всё и так уже перехватила, отследила. А это китайцы, которых третируют за то, что они компартии всё сообщают. Они на всякий случай оговариваются лишний раз. Не, я к тому, что там МCшка-то подключается, это локальная или она удалённая должна быть? Она на комп, на

[02:16:00] компе должна работать прямо с десктопной фигмой. Да, да, да, десктопной. Да. Если ты готова на этот, как сказать, на прожарку, можешь зарить экран. Что это значит? Сейчас всё почини. Ты ты сейчас Нет, ну я могу поширить поширить экран. Могу, конечно. Да. Ну, поехали. Сейчас починим. Либо мы программисты, либо нет. Да, можем. Да, это же уже практический челлендж, да. Как бы как вот столько людей переходит в шоу. Окей, погодите. Укода вроде бы встроенный теперь фигма же какой-то коннектор. Может его просто настроить и проверить. Нам-то просто флоу посмотреть. Салон-то никто же не просит. У него Ну да, давайте по шагам. А, да, я в принципе за любую инициативу. В консоли нужно А вопрос, ты в код-коде или в коддесктопе делала этот MCP FO свой? В код-коде же, да? Декто app desktop. Вот он у меня здесь установлен, да? То есть не ве он мне сразу сказал на Угу. А а знаешь ли про файлик декто? Сейчас её ну или в принципе тут он у неё он у неё открыт. Он как раз этот Да, он открыт. И давайте выделим говорит. Я вот предлагаю всё-таки синхронизацию сделать. Да, давайте по 3 минутки каждый риме поможет. Начну с себя. Этот Арима можешь зазумить экран? Ничего не видно. Или это у меня? А, ничего не видно. Да, интересно.

[02:18:00] А, стой, я же могу зазумить. Такая же функция есть у меня. Всё. А вот этот файлик у тебя у тебя слева должен, если смотреть коды десктоп, у тебя hingн face с этим вопросиком, да? А на что он ругается? Давай посмотрим правее. А, но оно здесь всё некликабельное, если частное. А ещё вот сам код десктоп, как будто не на весь экран нам виден. Ребят, у вас тоже обрезан кусок десктопа не полностью видно. Давайте лук, может, посмотрим. А вот так лучше видно, да? Угу. Log, может, посмотрим? Кого? Логи. Вон видишь? Open logs folder. Да, можно логи посмотреть. Давайте, кстати, там реально типа в клод десктопе же уже есть коннектор Фигмаде десктопный, поэтому, возможно, и не надо никакие ключи там настраивать. Сейчас надо сгуглить и дать ссылку, чтобы упростить. Фигма Д. Нене, прямо то, типа в код десктопе нажимаешь, типа tools, брауз, ээ, эти самые connectors. И вон там есть, да. А давай попробуем, кстати, да, вот здесь конекторs, не, ну да, десктоп, типа, потом там типа тулзы выбираешь снизу. Нене, прямо new чаat нажми. Вот. Ага. Типа вот. И вот там вот тулзы вот эти вот рядом с плюсиком, которые шестерёнки. Да. Так, он здесь. Да. Да. Вот там manage connectors снизу. Угу. Ээ так вниз, вниз. Вот browse connecteds и вот так. Desktop extension сверху. А верхний tab web и десктоп. Да, да, да, нашла.

[02:20:00] Да. И вот вот фигма тут должна быть, да? Вот фиг. Да. Вот. Ну вот типа он говорит, что там типа десктоп должно быть пущено там. А там можно посмотреть сразу список. Да, запусти, запусти фигму сначала. Фигма у меня работает. Вот как раз я здесь пыталась. Иди туда и не знаю куда. Install. Да. Вот. Ил. Всё, закрываем. Спокойно. Козлодое сядем. Все. Вот можно, наверное, этот генфей забэкапить этот кусочек конфига и и удалить его потом нахер. Там было. Я думаю, что у неё просто поэтому проблема. Когда он, кстати, такие ошибки фигачит, он вообще не работает или это конкретны МCшки у н��го типа не будут работать? Конкретно не работает, да? MCP не работает. Так он работает? Да. Ну, в принципе, в принципе логично. Конфигу там есть что-то. Да. Да. Теперь давайте настройки смотреть. Фигма. Вот там как раз может ключи надо сейчас. Не, нет, сверху там была кнопочка configure. Да, кстати. Угу. Так, Мишины по максимуму. Давай без без этих без спрашивания. Ну, по максимуму, да. Угу. Исто не это не получае��ся. Всё нормально. Да. Не, ребята, какой там ключ ей нужен? Она же будет работать с инструментами, с компом. Ей нужен. логически осуждаю его не нужен. Да. А попробуй, попробуй счать в клоде. Попробуй. Иди, иди в клод сейчас

[02:22:00] в этот в чат. Ну, может, вначале квит а подожди, я попробую просто чат иди. Угу. Сейчас мы один эксперимент сделаем. А опус выбирай или насколько подпис. Не, нет, напиши, напиши. Знаешь что? Напишин инструмент включите, пожалуйста. Он должен быть включен. Проверьте, что он включен. Шестерёнку обратно. Где плюсик? Рядом с плюсиком шестерёнка. Нет, плюсик, да. Вот это вот это extended sinking на всякий случай добавить, наверное, надо. А вот смотри, Figma def mode. Воткни вот в эту фигню. Ну вон всё пишет, есть, да? Всё хорошо. Угу. Давай попробуем ээ этот самый значит вот в чатике. У вас подключился MCP-сервер Фигмы. Да. Давай попробуем одну вещь. Напиши в чатике, а askigмагма WhatsApp to list to list tools. Что? To list tools tools. Угу. Всё. Да он же русский знает. Вон он. А вот это да. Так, а может закрыть? Открыть надо или слушай, ну MCP работает. Это это отвечает MCP. А, то есть можно пробовать. Давай попробуем. Он рестарт, он говорит. А, ну закрой, открой. Ну хорошо, сейчас яста. Окей.

[02:24:00] Всё время мне выдают эти ошибки. Это это пофиг. Это для ББ. Угу. Ну, можно что-нибудь просить. Ну, там он писал, что ему требуется какой-то фигма дев мода что-то перестартовать или какие-то такие вещи он просил сделать. А в предыдущей переписке зайди, который был сообщение, там написано же было два. Посмотрим. А пишет первое, подождите, дектоп. Второе, Figma File. Третье, in open the Figma menu under preference select enable mode server. То есть в figma меню, в апке посмотри фигмы. Preference enable de mode. Есть где тут эти preference? [музыка] Да. И так. Надо самого. Давай, давай посмотрим другие меню, может быть, файл или что-нибудь. Вот быват файл ещё бывает преферен. А вот всё вижу. Ага. Не видно тут плагин. А вот там в конце мен Ну а менедж плагин, а здесь не добавляется. Может, может у вас фигма не последня, ребята, зайдите обратно в код десктоп, он дал ссылку, а там скриншоты. Код

[02:26:00] А, о'кей. Так, куда заходи? Ссылку внизу. Внизу дал ссылку там скриншоты. Угу. Вот ниже пролистать. Тут он где-то скриншот добавил. Ты как фигма. Вот. Вот как это винда enable death mod mp сервера. Но это, но это преференсы, кстати, не самой фигмы, это какого-то уже это таба преференс. Нет, да нет, это это в Фигме. Нене, я имею в виду, что это не в самом приложении. Это вот он кликает типа на какую-то табу. Давай, давай ещё один маленький эксперимента в рабочий, да, вот сюда. Ага. Давай это самое с кводом маленький экспериментик ещё один проведём. Не давайте мыва доделаем. Вот. Всё. Угу. Так, а там что было написано? Что-то не повёто только что-то я не вижу. Это где он такие? Ну вот невоз. Может, надочек for update сделать на фильме? Давайте последняя веси. Да. А когда двадцать второго? Нет, Фигма по дизайну вижу сразу. Так, там надо опять сверху фигма и было чек for updates типа на самом приложении. Вот фиг и яблочко есть у тебя яблочко вверху. Вот с яблочком рядом на фиг на са фигма рядом с яблоком фигма. Ага. Second from the top.

[02:28:00] Ну или двадцать пятого. А давай, давай, в в код пойдём и кое-что у него попросим. Давай. Значит, вклодно, да? А значит, скрольни выше, где там было у нас этот, э, где мы просили MCP что-то сделать, полистить, да? Вот смотри, вот здесь. Стой, стой, стой, стой, стой. Вверх покрути. Я хочу просто этот посмотреть там. Ещё выше. А те выше нету. Нет, это Сигма Tools overview. Вот это вот чайник. Вот, значит, смотри. А GET connect Map. А прямо напиши getд connect Map. Вот прямо вот эту фигню напиши. Вот скопируй её оттуда просто. Просто я что хочу попробовать, чтобы он, короче, просто позвал этот MCP и фиг ему что-нибудь вернула. Да, да, где-то надо там. Угу. севера. О'кей.

[02:30:00] Тут нет такого. Так. Угугу, угу. Давай в этот в меню просто пойдём тогда. А вот подожди. Ну да, в меню. Так, тоже нету такого. Давай по всему меню потихонечку пост воще. М. Да, да, смотри, вот здесь должно быть где-то отключаться мод. Я точно знаю. Так, а может быть, потому что у меня бесплатная версия. Может быть такое? Да. Ну, может быть, конечно. А, попробуй рестартуй фильму. Что будет? На форуме написано, чтобы включить MCP сервер, вы должны быть на dev или full seat на professional плане. Вот я о чём говорю. А у меня обычный, поэтому я не могу подключиться. То есть мне нужно апгрейд сделать, мне нужно заплатить деньги. В принципе, можно это сделать сейчас. Да, ну да, я тоже уже всё поставил. У меня та же история, да, не видно. Ну, получается, да, надо заплатить, поэтому и нету этого деф-мод, потому он вообще здесь должен быть сейчас только дизайн и прототайпe, а ещё должен быть defд. Он получается только на платной версии. Угу. Угу. Я в чат сла на форум, там всё написано,

[02:32:00] как это включается. Но там однозначно написано на платном тарифе. Угу. О'кей. Значит, тогда тогда я уже это сделаю потом. Оке. Угу. Там, кстати, довольно ограниченный ��писок того, что она может через коннектор это делать. Может, это смысла нет. Ну ладно. А сейчас я сейчас покажу, кстати, то, что написал этот дипсик. Это интересно, но мне прямо страшно стало. А вот он мне написал. То есть я ему кинула код и спросила, чтобы он проверил его, потому что мне никак ничего не подключалось. И вот он говорит: "Вощем, ты в безопасности? [смех] Я уже всё, меня тут хакнули. Я туда полезла. Я, короче, наклейку видел на машине. Это это вообще абзац, короче, этот типа поедем скоро. Kids kids not on board. Дали мою посылку, знаешь куда? На улицу, [ __ ] положили просто на улицу, [ __ ] Как тебе? Заебись. Пойду сейчас собирать. А можно мнетить людей? Да, да, я сделал. Ага. Там так. Ну, короче, Дима не приедет. Рим, извини. Я надеюсь, он не с динамиками. Я надеюсь, он не с динамиками.

[02:34:00] Так, ну что, я предлагаю тогда э поговорить о хуках, не о боксёрских, а о кодкодовских. А-а кто их активно сейчас использует? У меня в планах. Я вот [музыка] попробовал Инди Деден, знаете, такой YouTube канал есть, где он скинул свой репозиторий Observability, который показывает претус. Ну и, короче, типа, что там агенты творят прямо и сабагенты. Но у меня, короче, всё нахер поломалось. Вот вылетает. Ну, в плане не то, что там не тот ответ мэтчит��я и слетает. Ну, короче, я пока что забил. Но идея с обзервабили, если запускать какое-то количество платсессии в параллель, это, конечно, было бы очень удобно, потому что отсмотреть, какие ПТУ юзали, потому что вот эти мультики, когда он скролит бешеной скоростью своих сабагентов, конечно, ну, у меня вот последние 3 дня я ему давал верхнеуровневые задачи, и когда он на час уходит в свой этот сабагентный путь, Ну, типа, хочется, конечно, отсматривать. Ну, отчёт как у Дениса, это хорошо, типа, Таска и что сделал? Ну, типа думал, может, вот кто больше уделил времени, кто-то хуки пока юзал в итоге или нет. А я, кстати, думал про хуки, но я не придумал, как мне достать оттуда что-то содержательное. То есть можно запустить по хуку какую-то утилиту. Эта утилита может быть тоже инстансом клодкода, и она может взять

[02:36:00] отчёт и его как-то красиво трансформировать. Может быть, так. Ну, там, по идее, если требовать в промте Jon output, я так понимаю, то тогда можно их больше более сложные пайплайн цепочки формировать. Я знаешь что предложу? Смотри, у меня у меня идея такая есть интересная. Значит, ты можешь, например, хуки на запись или апдейт файла, да? Вот. А ты можешь подключить ээ клод в этом месте и попросить его ревьюить эти изменения. Угу. Если, короче, они не нравятся, то отказывать и ризн говорить. Ну, это вот отчасти, что Денис хочет. тебе тебе нужен там именно тебе нужен клод или просто лалэмка там да ладно это одно и то же, наверное, на пример. Типа, короче, тут просто ещё интересное такое. То есть, например, ээ, я не знаю, вообще это проблема или нет, но ты вот, например, когда типа автоматически что-то ревьюешь, ты, наверное, хочешь ему меньше прав давать ещё, типа, чтобы он, типа, не поехал сам там код дальше менять, чтобы он такой вот ревью, давайте-ка мы ещё и сами поправим. Типа нет, такого у меня никогда не было. Он, как правило, остаётся в рамках задания. У четвёртой версии есть некоторая склонность к как же это по-английски overгер, а по-русски это overреact. Ну он слишком деятельный, то есть он делает больше, чем поручено. Вот такая беда есть у последнего Джемини, у Клода, потому что когда его их перефорсили на агентские возможности, у них вот эта инициативность избыточная, она выросла. Иногда они начинают делать вообще не то, что попросишь, то есть сверху что-то,

[02:38:00] что считает нужным. И вот у того же Айдер есть на эту тему специальный промтинг. И я в свои пром добавляю, что ты должен сделать только задачу, только то, что поручено. То, что типа не поручено, не делай. Хватает. Извините, ещё раз можете напомнить слово руление, как называется на английском? Стиринг. Стиринг. Стиринг. Стиринг. Да, языками не води, извините. Вот хочу стилинг MCP. Ну, короче, у нас получается по надо пробовать, да, у нас из таких тем, получается для изучения это вышлифовывать аа spec driven development, steing, а, провести брейнсторм на как Максим поднял использование руку от квадранта в Подключение к код-коду. Три сиitр MCP из домашки. Да, я, кстати, это сейчас это сейчас домашнее задание, типа это дада. Берёт то, что берёт. Я Я, кстати, ещё один экспериментик сделал с кодом. Вот я попросил его проанализировать логи вот и оценить по, короче, ценам кда, типа, сколько у меня, значит, стоило бы это. хозяйство. Ну, если бы я платил за API. Вот. Угу. Сейчас я открою этот экранчик. Интересная цифры. Какая-нибудь Клаудия, наверное, также и

[02:40:00] делает, да? А, не знаю. Короче, вот такая штука. Cost analisis. Видно, да? Угу. Там ялка очень. Четыре сейчас. Я думал ты на полмиллиарда долларов потратил. Это токенов. Ага. Нет, не слава яйцам. Нет. Вот это, короче, это по вот этой документации, собственно говоря, анализ был. Вот. То есть вот вот эти вот меня интересные очень цифры вот эти вот. Да. Вот. То есть это работа с кэшем, оказывается. Он, короче, работает с кэшем. Вот что позволяет очень сильно удешевить, на самом деле. Вот. Ээ так, [ __ ] куда пошло? А это А ты уверен, что он правильно посчитал вообще это всё? Ну я смотрел лог сам. О'кей. А там в логе пишется типа что что он взял из кша, а что нет. Да. Дададада. Да. пишет это в отдельными полями. Сколько у него запись в кэш и сколько чтений кэшit кэшми? О'кей. Да, посмотри. Попадание в кэш. Это чисто из-за документации? В смысле? Да нет, это в целом просто для кода вообще не вс такой высокий процент попаданий кэшхитов. Это из-за документации или это типа А я, смотри, я, короче, вот это вот хозяйство, это я просто генерил, зн��чит, ну, для инвесторов всякую документацию разную. Угу. Ну и вот да, я ещё напущу это на код, посмотрю, что там было. У меня когда вот у меня сейчас статистика, я смотрю, у меня а 65.000 входных токенов, а 2,5 млн выходных токенов. А запись в кэш 75 млн токенов и чтение с

[02:42:00] кэша а 1 млрд 70 млн токенов. Угу. То есть больше 90%. Это в основном код. Поэтому просто клод-код так работает, что он сначала себе в контекст подтягивает всё, что должен знать. И каждый вызов э модели сопровождается отсылкой этого контекста. Так как контекст был сформирован ранее, он его в кэш записал, и он его мутызгает постоянно при вызове. То есть он, допустим, tools решил сделать, там прочитать файлики какие-то или вызвать команду какую-то, да, тул отработал, и вот результат вызова этих тулов - это новый запрос к модели. И вот этот весь запрос делается. Вот у меня если было 120 к контекста, то все 120 к они все улетают в этом запросе вместе с результатами тулуюза. То есть там из нового Да, если сказать просто, что это прикольно, типа, что они молодцы, экономят сами себе деньги. Так, они экономят сами себе вынужденно, потому что если бы они не экономили, у них бы сервера нахер расплавились, потому что каждый раз пересчитывать это всё дело ну как бы и курсор бы их положил бы за первую неделю. И Google, Google же тоже они же сейчас, сейчас, погоди, погоди. А при чём тут курсор? Это типа это фишка клодкода или это типа фишка чего-то другого? фишка апи антропиков, но у них мануальный нужно, короче, курсор тоже это реализовал, и у них нужно руками вроде писать в кэш, да? А у мени оно сейчас автоматом пишется, что тоже всегда мне было удивительно. Не, чес, погоди, я не совсем понял. Типа то, что кэш-то понятно у них есть, это понятно фишка антропика, а типа то, как

[02:44:00] типа строится промт запрос, это же уже клод-код ответственный за то, чтобы там типа сделать так, чтобы больше кэшритов было и кэшхитов. Ну там надо в запросе пометить, что вот это положить, ну, типа закшировать. Там не сложно это делать, но нужно это сделать явно. То есть, если бы курсор не включил поддержку, то как бы ничего бы не получилось. Для меня это всегда было дикостью, потому что уж провайдер, он абсолютно точно видит, что на вход модели поступает. И он абсолютно точно может понять, что запрос последующий содержит в себе там 90% данных из предыдущего запроса. Никакой сложности автоматом этот крш вести нету абсолютно. Но там же ещё важно, типа, где оно находится. Нет, типа, если оно типа, ну, оно должно там же по префиксу гашируется, нет? Ну да, правильно. Там, понимаешь, там каждый вызов модели, по сути дела идёт массив сообщений. Угу. Вот. И вот эта вот история. Этот весь массив сообщений, он практически одинаковый каждый запрос. Ну, естественно, когда тебе пришёл запрос повторный с этим же массивом, отследить див с предыдущим запросом крайне просто, потому что захишировать это всё дело, ну, как бы как два пальца об асфальт. Ну, с предыдущим, да, наверное, просто искать уже. Ну да. То есть у тебя же был обработан предыдущий запрос, он же весь посчитан уже там вдоль поперёк, и так, и сяк, и пятым, и десятым образом. И как бы новый ты всё равно будешь считать. Ну как бы, ну посчитай его, сравни заранее, там хэш просто посчитай, это быстро. И вот Google это делает автоматом, а антропики так всё-таки жлобятся, потому что у них запись в кэш - это платная операция, там наценка за такие

[02:46:00] токены идёт. Вот. А у Гугла это бесплатно и автоматически, что в общем немножко э репутацию Гугла в моих глазах поднимает. В Google просто алгоритмисты более мощные тут, да, написали алг��ритмы сравнение строк, короче. Окси, ну как бы это примерно как в Гугле тоже закончили второй класс, да, там, ну, типа типа того, да, да. То есть как бы это же это голимое жлобство. Вот просто простите, это тропики жлобы. Вот они как всегда. Не, нет, ты там, знаешь, ещё причём в чём? Они они ведь четыре брепоинта тебе дают. То есть у них вот на на весь массив входящих вот это вот входящего промта ты можешь проставить только четыре брепоинта, в которых кэш бу��ет происходить. И этим брепоинтом, блин, опять-таки руками нужно управлять. Это вот они скинули на пользователя не только плату за за кэш дополнительную, они ещё, блин, вот это вот контекстменеджмент с четырмя брейнпоинтами на пользователя скинули. Блин, ну это вот настолько неудобно. Я не стал это говорить, и так люди запутали со слов это всё слушать. Я к тому, что это, на мой взгляд, голимое жлобство, потому что это всё переусложнено. Нахрена так сделано, неясно. И почему это не сделает автоматом, тоже не прямо примерно такая же загадка, как если вы помните, у Chat GPT долгое время на модели О1 не было возможности файлы из проектов подтягивать. Вот для меня тоже было загадкой, как бы, как файл из проекта - это просто текст, который отправляется с каждым сообщением. То есть они настолько экономили, что не прикручивали эту возможность. И, по-моему, её несколько месяцев назад прикрутили. До этого полгода не было такой возможности. Ну, бст в чистом лидер.

[02:48:00] Укла денег много, атропика мало. Угу. Ну я с другой стороны я чётко понимаю, что для нас это кажется злобством, а для них это оплата серверов. И для них это очень даже заметные бабки. Ну да, особенно в масштабах ча, например. То есть им каждый день, когда они не прикрутили такую возможность, означает, что пользователи не будут отправлять весь свой склад из файлов проекта к модели, и они обработают там на миллиарды токенов меньше за этот день. GP обогнал Twitter, Instagram, Facebook, YouTube, Google остались. Ужас. Ну я потому что там реально сотни миллионов пользователей в день получается, видимо. Нет, там 4,8 млрд. Ну вот, да. То есть, ну, как бы охренительный трафик. 5,4. 5,4 для них любой. Это всего это ман. Наверное, надо дау считать. Ну я тому, что там масштабы такие взрослые, поэтому и для них любая экономия, наверное, отливается. Жопе 5% лишь. Антропик я тоже понимаю, потому что у них по жизни с серверами было всё не очень весело. Всё время отлетало. Вот сколько с ними работал там год, наверное, с лишним. Так сейчас же им всё Amazon это даёт. Так кого там дают? Онито вроде тоже акционеры, но что они там дали, я не до конца понимаю. У них так они так в условиях сделки н�� 8 млрд долларов у них было переход с чипов

[02:50:00] Nvidia на чипы Amazon. Да. Ну и нам как бы как пользователям, наверное, только был бы плюс. Беда в другом, что А, ну, кстати, вот они же на днях прислали письмо, читали, вам пришло, если кто-то пользуют, что типа мы переходим на инфраструктуру дата-центров, что у нас будут уже, я так понимаю, дата-центры, которые максимально приближены к географическому региону пользователя. Мы распределим нагрузку всю. И если вы не согласны, там напишите нам. А так мы вас переведём вот в глобальную инфраструктуру. Я так понимаю, это глобальная инфраструктура, судя потому что она реально глобальная, много каких-то там локации, то эта инфраструктура похожа на Amazon. Может, и Google, кстати, почему бы и нет. А может Oracle вообще? То есть там не пойм на Oracle не похоже. Oraacмериканский скорее. А вот Google или Amazon могут быть в плане, а не International, но точно не Яндекс облако. А вот как уж не был, как как этот называется Яндекс не был. У Яндекса есть набиус. Небиус. Вот. Да, Небиус, да. Но я думаю, что они не они не могут, скорее всего, ничего российского использовать, потому что там тогда же данные надо что-то хранить в России туда-сюда. Не, ну не обязательно в России они будут хостить. Просто это будет хоститься где-то в той же Европе, по-моему, сервера Небиус, они как раз-таки все за пределами России, по идее. А кто же мешает? Это центр был первый точный. Они ещё так это же уже два разных яндекса же, конечно. Да, да. Ну, на самом деле, кстати, Найобиус он вполне годные условия для инференс моделей. Даже деньги бесплатные давал. Там 5 баксов, по-моему, приветственных на АПИ. Deep seк хостил с приличной скоростью. Угу. Ну, как бы, да, в любом случае сейчас

[02:52:00] вот эти провайдеры, точнее, вендеры моделей будут использовать все доступные железные ресурсы, которые во�� только можно. Ну, потому что спрос на тот же Anтропик прямо очень большой. И вот то, что сейчас последнее время начали народ замечать, то, что там то контекст урезают, то количество токенов в рамках сессии начали подрезать. Это вот как раз первые ласочки того, что динамическая балансировка будет происходить какого-то рода. И хорошо то, что они сейчас расширяют своё присутствие по по многим датцентрам. Возможно, мы этот момент динамической балансировки отсрочим, потому что уж очень комфортно работать в клод-коде, практически не думая о лимитах. Вот. А кто Open Router номер два? Никто. Ты имеешь в виду Openроoutур? Использует кто? Не, второй компетитор его. Кто? Или он самый мощный? А, что-то вот из тех, что на слуху, по-моему, да, это он самый мощный. Ну или хотя бы второй. Просто любопытно. Просто прикольно посмотреть там статистику, какие апки у него жрут трафик. Вот это типа получается продукты такие, агрегаторы среднего масштаба. Ну, в основном получается open source популярные, можно смотреть список через это выходит. Угу. Я я вот ещё скинул S Web AI, короче, на ара это типа получается такой авторитетный селоисточник. Там правда типа оказывается deep птик идёт за Open AI, представляете, он обгоняет Gemini и обгоняет, обгоняет код. домен, по крайней мере, вот сейчас клад по Ну, китайцев много

[02:54:00] бустану. Ну, сейчас очень хороший промоушн китайцы получили с выходом 2. Он реально популярный и реально неплохой, вроде бы, по всем отзывам. Я сам не сильно юзал, так в чате поспрашивал. Ну, отвечает. Вот. Но это же удивительно то, что это незанер, это обычная модель, типа как типсик V3. А 4 он же там был очень классный, эмоциональный, типа так вникал в твою ситуацию. Я, кстати, его и тестил. Неплохо было, да? И его вообще убрали, дебрикейт сделали. Не, его из Апе убр��ли, а чат GPT он всё ещё доступен. А в итоге ризингом разобрались, там была статейка, что типа по факту ризининг ничего не даёт и вообще это всё придумано, чтобы больше токенов тратить. А в итоге были какие-то опровержения или повторные тесты. В итоге вообще что как там? А, а там что-то кто-то говорил, что это капитан очевидности Apple включил, типа ничего, они своей статьёй только как кайпанули. Ну так как бы я готол по факту ничего как бы вообще не нужно. Ну может контакт расширит за счёт генерации дополнительных токенов. А так ну вот точно не так, потому что когда сверху модели делают рининг, тогда растут все в бенчмарки заметно. Вот там было немножко не то написано же, вроде бы, как я понял, там было написано, что новых оригинальных идей ризнинг не способствует выработке, как бы. Ну и схренали бы он способствовал, потому что он наоборот идеи замораживает, потому что чем дольше модель, тем больше токенов получают свой контекст, который фиксируют тот или иной путь размышлений, да, тем сильнее она на этом пути остаётся. И в этом смысле модель без

[02:56:00] рассуждений, она может двинуться в любом направлении, да? А модель сразмышлениями она по рельсам рассуждений, конечно, будет делать, но первичный вот этот выбор токенов, который её направят на тот или иной путь, он же по сути дела, что у ризанера, что у обычной модели абсолютно одинаково идёт. Вот. И как бы вся разница между ними только в то��, что ризанеры до обучены ч��ть-чуть больше больше. Тут вот, кстати, вопрос. Вот эти токены текстовые, вытащены из латентного пространства и запихнутые в контекст, они обязательны для того, чтобы модель через них размышляла? Или же мы можем остаться в рамках латентного пространства? Это вот как раз я встречал статьи именно того, что а то, что в ризинных цепочках-то пишется, то, что наружу модель выдаёт, оно как бы не всегда согласуется с её финальными выводами. То есть возможно, что процент размышлений процесс размышлений где-то в латентном пространстве всё-таки происходит, и он чуть-чуть отличается от тех текстовых токенов, которые модель наружу выдала тебе как пользователю. Вот это вот интересно. И кажется, что исследования в этом направлении тоже должны же двигаться, по-моему, к тому, чтобы замкнуть это всё на на то, чтобы это внутри модели происходило, а не видят цепочки. Ровно то, что ты говоришь, ровно то, что ты говоришь, делала мета полгода назад бы��а папирно этот счёт исследования они пихали вектор, который сформировался. Они его не дискретизировали в токен, а сразу наверх модели пихали вектором. и говорили, что за счёт этого рассуждения становится интереснее, потому что этот вектор содержал в себе все нюансы. То есть, когда он вался этот вектор,

[02:58:00] фактически происходило загрубление, потому что все нюансы терялись тонкие. Вот. А они его подали сразу в нетакинизированном виде, вот в этом св��ём исходном виде. Они его продавали сразу наверх модели. И вот это говорили, что, ну, якобы улучшает размышление, что они как более комплексные становятся. То есть такое исследование было, так можно делать. Я не вижу вообще технически никаких причин, почему так не делать. Ну да, собственно, потому что единственное, что, наверное, цепочку не увидим, хотя тоже же не мешает фактически пихать токен, да? А для интерфейса там вот этот вектор наружу подавать и его такинизировать, чтобы оно где-то там в другом потоке писало. Просто контекст модели. Ну да, это да, это скорее размышление. То есть пусть она там себе внутри думает. Просто нам наружу ещё отдавай процесс размышления и всё это. Ну визуализация чисто, что там что-то мелька был в чате. Вот. Ну да. Вот. И мне кажется, это вообще отличный путь. Я не вижу причин, что не сделать. По слухам, Google в этом направлении эксперименты проводил. Мы же не видели ни одного чекпоинта третий Гемени. Может быть, они там сюрприз нам сделают и выкатят его. Может, там будут такие вот штуки. Они вроде должны были сильно прокачать по бенчмаркам третью версию, потому что они ржали над опнаи, что типа о молодцы, ребята, вы там поспешили с анонсом своей невыпущенной модели, там молодцы, спасибо. И с таким намёком, что типа ну хайпуйте, хайпуйте, пока можете. Вот я что-то в этом увидел намёк на то, что Gini 3 скоро зарелизт и все прикурят.

[03:00:00] Ну, посмотрим, да. Но в любом случае кажется, что вот этот вот процесс размышлений наружу, он действительно избыточен. И скорее модель не должна так думать. То есть ей ей бы думать внутри. То есть можно было бы предположить, что в какой-то момент было эффективно к примеру, вот всякие Chain of Sours, вот эти вот старые Chain of аа техники промтинга модели, они в основном-то в чём заключались? в том, чтобы из латентного пространства модели вытащить на божий свет нечто, поместить в контекст и чтобы она уже за счёт этого контекста тебе лучше решение выдавала. А тут так получается, что нам вообще не нужно это всё вытаскивать из модели. Можно же всё в ней всё это провести, а и как раз-таки это будет и эффективнее, и быстрее, и действительно и интересней. Там, знаешь, ещё какая была из последних архитектурных придумок идея? была идея, что надо взять входные токены, распределить их по важности и важные токены пропускать через модель несколько раз. Вот. То есть не все токены вот так вот по кругу запускать, а только важные. Если пропустить важный токен несколько раз, качество типа вырастет. То есть там в промкте есть какие-то, ну, основные такие, которые несут ключевые мысли, токены. Их можно узнать на берегу. И вот если он оказался важным, тогда его запустить одидтри раза, вот пока он типа не обогатится там максимально. И пропускать не все токены для оптимизации, а вот только некоторые. Вот такая ещё была идея. Ну, в принципе, тоже норм, но тут сам механизм важности главное проработать.

[03:02:00] Ну, говорят, что есть способы узнать вот этот токен. Угу. Интересно. Ну, по крайней мере, идею о том, что пропустить токен несколько раз, я до этого особенно не слышал. из за последнее время. Там, кто с этим глубже знаком, говорят, что это классическая идея. Ещё там вот эти вот зацикленные трансформеры обсуждали довольно давно, но в последнее время они не использовались. А типа зря, оптимизация очевидна. Угу. Если что, я беру домашку. этот ситер MCP поднять и потестить. А предлагают действительно, может быть, по итогу этого звонка, так сейчас на словах пообщаемся и возьмут энтузиасты нас как минимум, мне кажется, человека четыре-5ть какой-то скоуп и как бы потестят, покрутят и сделать такое хотя бы пятнадцатиминутное с экранчиком презентацию. Ну, это прогр��мма минимум, а максимум до часа, да, ээ, было бы совместное обогащение, а то не хватает же времени у всех всё тыкать. Например, там тымук сессии, я видел, ребята перекидывают из одной в другую, типа там что-то на серваке с с помощью прехуков и, ну, не прехуков, а хуков кодкодовских и Jon аутпутов. Ну, вот мы там затрагивали. Просто типа прикольно в голове остаётся слепок, когда кто-то прямо показал с экранчиком, обсудили, у нас как-то нейронные связи в голове скрестились и как-то как будто, ну, лично меня мотивирует и как-то эксайтинг, вот типа лучше усваиваться коллективно. Что

[03:04:00] думаете над такой идеей? Хорошая идея. Я, может быть, чем-нибудь позанимался бы на неделе, так потыкать. Можно даже делать формат, если у нас хватит. Это я пока вот есть сомнения там типа вот поболтать, например, в субботу, а в воскресенье ещё и что-то вот можно только более лимитированно до 2 часов. Типа такое ручками поделать, типа что-что ручками поделать, потыкать, типа. Не, ну вот смотри, я сейчас что делаю? Я вот что-то мне триситра, я его тогда в Аидоре не докрутил, но у меня он очень был мне нужен. Э там тогда ещё как-то что-то откодить. Я подумал: "Блин, прикольно, кодкод же такой умный и агентный". И вот эта идея, где триситтер построит карту основных там классов, методов, функций, каких-то ключевых частей там на основе своего алгоритма. И это повысит эффективность awareness CД base прикольно. Я бы потыкал. Я беру себе сейчас, что делаю. Открыл в User Home директоре, скачал репу, говорю: "Давай мне, короче, подучи её. Вот что-то сейчас початись, какие вопросы есть тем же кд-кодом. Потом скажу: "Добавь мне в такие-то проекты, в конфиге его этот MCP, добавь там в код десктоп". Потом пооткрываю эти проекты и попробую поделать какие-то типа задачки и посмотрю, насколько у него этот Awarness неплохой. Ну, типа, я просто уделю на вот тесты и с каким-то своим вот сгенерированным в голове флоу, ну, там типа часа два-три, да, и могу эту вещь пересказать людям, как бы, что у меня подсветилось там за минут 15, что я понял. Я могу что-то не доглядеть, но это вот как бы я мультиплицировал, как бы, ну, типа вот мы как распределили, и мне полезно и донести другим как бы типа

[03:06:00] мне полезно, потому что интересно, да. отзывается, а кто-то другой тоже взял какой-то другой кусочек потыкать, потому что вот Сергей сказал, что Алекс скидывал, я ��осмотрел по истории, это Денис скидывал. Я тоже, а я даже в звёзды не добавил. Что-то у меня была какая-то загрузка и забылась вот неделя и, знаете, канула в лету, как бы интересная тема. Cдbas как бы этого. Я вот в силу в себя, как Максим не чувствую квадрант прикрутить к код коду. И решил как бы триситер. Вот. И с бэклога можно реально кому-то отзывается, может хуки там поделать или Ну вот понятна теперь идея. Можно репок вот реально понабрать и вот так вот сделать. Джон Сноу. Правильно. Вотчель. Мичель. Я не знаю, почему Джон, почему у меня Джон? А это Майко, который Кира. Да. Да. Ну это мульти. Это походу Кира тебя переименовала, да? Может быть, сейчас что-нибудь на практике потыкаем, ну, в плане, например, может быть, Кира потыкаем, либо попробуем, может быть, что-нибудь с N8N потыкать всё-таки сделать так, чтобы он какие-то схемки генерировал. Workflow. Майкл Шаркран, поехали. Только единственное у меня ещё один вопросик вот возникает, но чисто из практик, из-за маленького опыта. Мы его ещё сейчас сейчас экранчик заширим. Так, лимитируемся, допустим, чтобы вдруг это там типа видно, да, допустим, получать. Ага. А я буду могу куратором быть типа в плане там, может быть, вопросы задавать, что Ага. Ну вот у меня тут сейчас это Кира работает. Я абсолютно вслепую ээ решил

[03:08:00] ему бросить бэкэнд, чтобы он его делал. И я вот столкнулся сейчас, например, с такой вот проблемой, что всё-таки как правильно стыковать бэкнд с фронтэндом. То есть вот как ему предоставить возможности для стыковки. Ну то есть типа вот у меня раньше была общая папка, то есть я его запускал просто в общей папке проекта, то есть там, где отдельно папка бэкэнда и отдельно, где папка фронтэнда у меня была. Э вот. А теперь, а теперь я решил попробовать всё-таки отдельно папку бэкэнда взять его. Вот сейчас он у меня работает в папки бэкэнда. Почему я решил так сделать? Потому что когда он у меня был в общей папке, он постоянно совершал какие-то ошибки, постоянно забывал, в какой папке он находится, э-э, где он вообще, что он делает. Это это просто он 15 минут не понимал, что он находится не в той директории. Вот. Но как правильно вот именно состыковать, дать ему, предоставить ему возможности интегрировать именно вот фронт с бэкэндом? Вот я не понимаю, как ему это Слушай, а у меня первый вопрос, это Statel Кира, я просто ей не пользовался. Она как-код Statel не индексирует базу твою? Ну я думаю, что индексирует. Во-первых, я смотрел системный промт. Э-э, там, ну, это просто как упоминание. Он берёт в учёт активные открытые файлы, то есть типа мои открытые файлы и упомянутые файлы или как там что там было. Там какие-то ещё файлы были, по-моему. Ну вот. Но индексация, мне кажется, у него всё-таки есть, потому что по уровню кодинга, мне кажется, всё-таки, ну, ну, так как он релевантно как-то ему вытаскивает ээ файлики, ну, эти фрагменты кода, мне кажется, индексация есть. Вот. А

[03:10:00] я тебе, Миш, могу ответить, если вот нет вопросов каких-то дополнительных? Ну, у меня вот вопрос именно про вот эту вот стыковку. Всё просто. Смотри, стыковка у тебя по классике должна происходить. А это опять же надо написать правильные спецификации. То есть ты должен на свой стыковать надо, а, наверное, писать спецификацию на backend, и frontend будет пользоваться этой спецификацией. Спецификация на бэкэнд пишется, ну, я не знаю, в каком-нибудь swager тире Openпе спецификации. Вот, э, можно в произвольном виде написать. То есть он должен тебе составить некую документацию, которая опишетпоинты все твоего бэкэнда и напишет, ну, то есть файлы доку��ентации, да? Да. То есть в каком формате мкэнд - до какие у него есть роуты, в каком формате они ждут параметры на эти роуты и в каком формате эти роуты генерируют ээ данные. То есть это всё, что содержится в Open апе спецификации. Если он сможет составить Open App спецификацию, ну о'кей. Если нет, я просто юзаю, я юзаю просто сразу этот фреймворк фастпи. У него есть генерация и этот, как его, open спецификация автоматов должна г��нерироваться. Да, да, да. И вот вот тут это мо и вот эту спецификацию надо совать на вход для фронтенда, говорить, что сервер по этой спецификации работает. В принципе, этого хватит для синхронизации довольно очевидный, нормальный. Угу. Ну вот как фронтенд делал Киру вчера, мне прямо очень понравилось. Там очень прикольно он сделал. А давай интерфейсик вот, например, с кткодом ещё действительно полистаем,

[03:12:00] что тут прикольного. Ну типа это ты в консоли это. А это Кира - это десктоп электроннаплекуха, типа аля, как Да, как тот этот. Я её просто очень зани, ну, короче, минимализм у меня по полной. А что от неё с код-кодом общее? Или это всё-таки курсор один? Я не м Ну нет, он как полностью автономный работает. Ну то есть смотри, тут есть файлик tasks, а который он выполняет. Это ну как спек, то есть он генерируется во время этого составления спеков, самого спек, точнее. Вот. Эты как открыл и сказал: "Бля, сделай зашибись". Он начал делать спеку или как это было? Он тебя интри? Ну смотри, как это работает. Вот ты открываешь, у тебя сразу здесь либо режим, либо спек. А в спеке ты ему пишешь о том, что ты, а что ты хочешь построить там именно приложение? То есть тут это прямо масштабная какая-то фича. Не фича, а именно он, пока не успокоится, да? Нет, нет, нет. Он генерирует всего три файла. Это сначала он генерирует, по-моему, requirements. Вот такой файлик здесь. описывается именно логика, то есть функционал. Вот смотри, например, он описывает acceptance критерия. То есть теперь когда пользователь открывает страницу авторизации, тогда система должна отобразить Telegram login widget. То есть вот э подобный файл requirement он составляет, затем он тебя у тебя уточняет, ээ, достаточно ли хорош requirements. MD. И ты там дополняешь, либо жмёшь кнопку "Приступить к decision". Decision - это просто у нас идёт дизайн, планирование всего дизайна продукта. То есть вот он даже, кстати, РМИ графики составляет у меня, э, по работе приложеник. Э описывает здесь

[03:14:00] стек технологический. Ну и напявот в режим просмотра файлы. Там есть сверху, можно его смотреть красиво. Ну, в плане его изменений или ты про что? Нет, в плане, что когда ты MD осматриваешь, там есть возможность просматривать его в режиме не редактирования, а просмотра. И тогда он А не мне так неудобно. Просто я когда сам редактирую, просто тупо открываю файлик, чтобы сразу что-то подредачить. Ну, я так смотрю, всё равно всё равно схемка мне тут и так в принципе понятна. Я понимаю, как мермоид график. ээ работает. Я его вручную составлял, так даже. Вот. Аэ, и в принципе я просматриваю в другом просто редакторе, если мне прямо это нужно. Вот. Что ещё? Что ещё? Затем, после того, как дизайн файлик сформирован, опять же, он у тебя там до бесконечности может уточнять, доволен ли ты этим дизайном, э, он приступает к созданию файла Tasks. И вот тут вот он создаёт вот такой вот огромный огромный список задач с подзадачами. И ты просто жмякаешь вот сейчас где тут, вот, например, вот старт Task. Ты жмякаешь на эту кнопочку и у тебя запускается девятая таска. То есть, ээ, ну, либо ты можешь вообще все под все девятые таски запустить, либо ты можешь какую-то отдельную подтаску запустить. Ну и, в принципе, всё. И как я понял, ээ можно, в принципе, всё запихать в одну таску. То есть все таски запихать в виде сабтасок в одну таску. И получится, что у тебя будет полностью автономный агент, ээ, который вообще не будет запрашивать, ээ, у пользователя каких-либо там запросов, вопросов. Вот. Ну то есть вот так оно работает. Очень, в принципе, минималистично. Вообще ничего лишнего. Ну мне нравится пока что. Вот скажи, пожалуйста,

[03:16:00] вот эти собака, они параллельно будут делаться или он будет их последовательно все всё равно? Не, он последовательно их делает. Даже если несколько объединить и за Ну как вот у тебя сейчас, например, кручится он. Ну ты в принципе можешь сделать, чтобы у тебя один агент, например, ваял, другой фронend ваял. То есть типа так можно сделать. Ну вот, ну вот в пределах одного Task MD файла, ну я не знаю, как это можно, хотя в принципе можно попробовать ещё один инстанс запустить. Вот я я не знаю, правда, будут ли они конфликтовать. Ну должны, по идее, если вообще файлы будут. Ну ну и вообще разрешит ли такое Кира провернуть? Вот. Ну можно, кстати, попробовать сделать. Так, где быс надо запустить? Так, тактак. А он, по-моему, всё-таки в одной папке. Подожди, а так он не запустится, если так. Вот запустилось. Open, open, open. Как там? Project Project или как открыть папку проекта? Open. Вот. О, вот Openфolder. Так, Open folder. Ээ, GitHub. GitHub. Так, а давайте, а, то есть мы сейчас ответи на А как сделать, короч��, интеграцию фронта и бка. Денис тебе, получается, пояснил, что стандартными путями через Swager Open да и ты там это делаешь. Мы посмотрели интерфейсрывается, поняли, что эта история между курсор и код-кодом. Только более продуманный мой вывод из этого подход к спекам. Полностью автономный, да, чтобы автономность была выше, usability тоже было выше, чем удкода. Вот тут есть хуки ещё этот hook UI, где

[03:18:00] он открывается. Он вот здесь открывается, вроде бы, да? Вот. То есть получается, вот как раз-таки у него, мм, можно попросить вот здесь написать, э-э, расписать hook. Вот, например, вот сразу есть пресетка Optimize my code. То есть там, например, когда файл изменяются, он будет, ээ, ну, срабатывать ХК на оптимизацию хода, ой, кода. Ну или там, например. Ну, то есть типа он сам вы это пишете. Вот по функционалу вообще, кстати, всё. То есть больше тут вообще ничего нету. Даже в настройках, если покопаться, а-э, сейчас, сейчас, сейчас, то тут вообще типа минимализм Kiro. Вот всего восемь настроек. Это Trusted Commands, Notification, моделька. А вот, кстати, что такое supervised agent autonomy? Я вообще не понял. Пока что не переключался на него. как раз сколько он спрашивает вопросов тебе задаёт или полностью автономно все правки делает или будет каждый раз тебя спрашивать: "Ты удовлетворён вот этими изменениями в файл? Принимаешь их?" Это типа если супервай или или когда это? Если супервайз, да? �� вот у тебя автопилот, это автоматически принимать все правки, которые он сделал. Угу. Вот единственное, что ещё с чем я не разобрался здесь, как MSMP подрубается. То есть вот мне написано model context проко. Хотя у меня вот здесь settings в настройках прописан Memory B sequential con то есть, а он их не видит. Я не знаю, почему это. И здесь написано только здесь фиксируется только глобальным MSMP сервер. Вот. Не знаю, почему не работает. Ну, типа я прямо пишу, например, там MSMP, то есть

[03:20:00] OpenWS MSMP config. Ну вот он у меня открывает этот файл. Я не знаю, почему мсмпишки не подгружаются, либо они подгружаются, но это как-то криво работает, потому что ещё бетто. Ну, как-то так. Вот. А ты говорил, вот это что-то там сбросил токен и, короче, лимиты сбросились. Как это сделал? Можешь показать? Так, ну я я это вчера тыкался. Ээ почему у меня вот этот лимит встал? Ну рейдлимит, короче, на запросы. В��т вообще не понял, как он работает. Он у меня длился больше часа. Ну и вот сейчас он уже закончился. Я удалил просто файлик. Был там где-то файлик RM.Vs s, вот этот Kirouft token. Вот этот файлик и просто зашёл заново с со своего же Google аккаунта, с той же почты. Кстати, удивлён, почему он почту даже не ну типа не чакнул, не сравнил, потому что почта одинаковая. Интересно, а то есть у тебя это А что этот на Линксе? Да, у тебя это не не этот не маг. То есть, если вот я в я сейчас эту херню не поставлю, это только если кто-то скачал DMG, он мне кинет, я установлю и может быть AOS тоже прокатит, типа, что у них криво сделано. Ну вот эти авторизации никто не качал. Так, не, а в принципе у всех электрон приложений, ну, по крайней мере, VS-код. Он на базе, ну, так как на базе Вис, у него путь тоже 100% такой есть в системе. На Маквейсе он, наверное, такой же будет, а на винде он может быть чуть-чуть. Я я уже не с этим имею в виду. Я имею в виду, что я вот забил на эту кирус, сейчас посмотрел, хотел бы поставить. Ну, получается, надо ждать, пока мне йтлист одобрят уже. Типа, если

[03:22:00] файлика инсталлятора нету, то я пока не могу их поставить. Слушай, а у тебя какой компьютер? Э, тош на м- серии процессоров, да? Ну, лови давай. Сейчас мы тут попробуем. Так, сейчас пять. И и ещё, может быть, попробуем сейчас что-нибудь с NN потыкать, тогда какие-нибудь валидные конфигурации погенерировать. Тут получается би все в N8N или есть кто шарит? А какая разница? Там, если мы сделаем нормальный генератор, то А какая цель? Что ты имеешь в виду? Можешь ещё? Ну, какие-то создание сложных каких-нибудь workflow в N8M. Просто типа это мо затянуться надолго, если ты не знаешь, что ты хочешь. Не, не, не. Ну нет, в смысле, типа, не знаю. Ну вот вы же пробовали уже что-то делать, ну типа в плане, я помню, вы говорили про Nemm, что он у вас генерирует какие-то, ну сломанный невалидный workкflow, где у вас не соединены нужен человека, который это говорил. Я не в чатике, в чатике же было. В чатике было. В чатике. Покажи пальцем на толпу в чатике, кто это говорил. Я не тол толпа в чатике. Толпа в чатике. Вот вот этот человек говорил и вот этот человек говорил. Ну я знаю вот Леви, он что-то пропал совсем. А только приходится вопрос задаст опять выйдёт. Когда-то он пару звонков посетил, а Влада тут, по-моему, нет тоже на звонке. Он тоже Ну жалко, жалко. К два приходил. Я знаю. Знаешь что? Я могу тебе скинуть репу. Я сегодня её кидал. Или напиши в поиске отцы в группе. Это типа, да? ACI

[03:24:00] это тебе не какой-нибудь N8N. Вот. Да, нажимай. Ты его сам и кидал? Да. Да. Ну я до тебя ещё знал. Вот вот этот давай лучше попробуем. Это какой-то аля уже-код для N8N, по-моему, был. Сейчас ещё посмотрю в переписках. Т��па вот такую штуку состави. Это это идэшечка, что ли? Или или это Ops. Это, короче, N8N, который ещё пизди. Сейчас я, э, сейчас ещё есть. Это, короче, мм, как сказать, это N8. N8 там - это малой, а - это подросток, а у нас ещё есть дедушка всех этих вещей. Ещё более хайповая. Кинк п. А ну-ка попробуй. Цинк 5 или что? А, хотя, да. X5 X подожди. X I I N NG F. А теперь, да, бери этот ворд, GitHub и не просто пятёрочка. Берикирд и в Gitхабе пиши. Ну, в Гугле. Вот, короче, вот эти два инструмента позиn ребята говорит. А туту так сейчас. А, а, всё, короче, это Active Pieces. Вот сейчас я дам ссылочку. Нет, это Синк - это другие. Вот я бы вот эти два хайповых инструмента почекал. Вот я скину в группу. Вот отцы и вот устанавливаем, потому что N8N - это дедушкины методы, а это вот по совре, кстати, ещё один

[03:26:00] инструмент для AFOW FL называется штука. Вот у нас у нас ребята ��го пользуют очень как бы очень интересно. То есть там прямо можно построить агента. Это как будто всё N8N. А как бы отцы и этот как будто они чуть-чуть вот хайповее такие, как вот фронтенда был killillлер. А вот а там есть такая возможность, вот флой можно построить агента, запустить Flow, а потом к нему уже к этому агенту обращаться через апи. Вот прямо целиком. То есть как бы он всё флоу запускает в одном АПИ вызове. Да, я этот на закрытых этих встречах мацнов увидел эти два инструмента. А я их не тыкал, но ребята этот вроде неплохие неплохо шарят в этих N8нах. И в то же время Так что так что нынче хайповий А и за FLI не скажу, я его ещё давно знал вместе с N8N. А вот сейчас я скажу, кто активней Active PES или за F сложно сказать. Ну, если бы я ещё, конечно, во всём этом был. М, как сказать? Ну, а за Active PES сейчас, сейчас, се��час скажу, какой из них самый последний. Мы в личке переписывались, короче. Active Pieces - это они, короче, дают не только сценарий, но IMCP инструмент, который как бы любую ноду делает. Хотя, может быть, с тех

[03:28:00] пор, как мы переписывались, 1 мая уже это всё поменялось. А-а, то есть они прямо давали больше коннекторов. А вот инструмент отцы. Ну, короче, вот как будто эксплорить такие инструментики прикольно в режиме воркшопа. Но, конечно, наживую читать, то есть вот отцы, да, вот у них как будто написано прямо [ __ ] всегоди есть. Он, короче, всё коннектит совсем. Да, через уауф. Прикольно. То есть хотя я не пробовал NMN ты по MCPХе подключаешь, он тебе тоже всё делает, но как будто эти ребята ещё более делают. Ну тут вот интересно, что тут интеграция, например, даже вот через ООАУ это получается что ли self-клиент или что это типа авторизация через ОАУ в Discord. Что что это значит? Типа интере Ну это они, наверное, обёртку вот сделали какую-то плюс-минус универсальную. А вот написано, да, реально Discord real Discord usеer, это значит self боты получается прикольно. Ты Фигма. Вот. Ну да. А слушай, а ты можешь или это если не интимно? Покажи, как ты Discord to тут to чаat делаешь? Discord toчаat. Сейчас сейчас это ну кривожёп выглядит немножко в плане того, что я просто поиск открываю, получается, жму Ctrl A, то есть, ну, максимально зум отдаляю, жму Ctrl I и просто вставляю в Джемини. Но я при помощи Киро вчера начинал писать эту утилитку DSMD.

[03:30:00] DSMD вот это вот э она получается должна решить эту проблему, но суть в том, что у меня вот как разтаки лимиты вчера закончились, то есть она вот сейчас вообще не работает. Ну то есть в перспективе в перспективе если она прямо реально нужна, то можно дописать. С другой стороны можно уже подрубить какому Джеми Николай. Вот какое контекстное окно в Джемила. Ну, такой же, как и этот 1м, да, но там 2,5 Pro, а, ну там какие-то эти рейлимиты или что-то. Этот Денис больше всего у нас эксперт, наверное, по G. Тут же получается можно подрубить какой-нибудь аля Discord MSMP Discord self бот ээ MSMP, что-нибудь такое найти. Вот. и просто тупо, ну вот реально юзать, если качественный MSNP какой-нибудь. Так, Discord token your bot to Token. Ну вот, в принципе, я уже нашёл lists, get servers, info, get channels, lists. Э, вот иногда мне не нравится, что вот в этих вот MSMP вообще никак не продумывают рейд-лимиты и соблюдение термовс. там, например, Дискорда или Телеграма. Вот я видел хороший MSMP для Телеграма. Прямо там полностью вообще весь функционал Телеграма был реализован. Но суть в том, что там абсолютно никак не соблюдены рейд-лимиты и очень высокий риск, что просто аккаунт забанят. Вот вот этот в��т MSMP сервачок прикольный. Тут прямо ну слишком много, я бы даже сказал, всего. Тут вот просто абсолютно все функции сейчас. А в чём проблема с рейдлимитом? Ты прикрути его сверху. А ты же Что такое MCP- сеервер?

[03:32:00] Это же ты сам его вызываешь. Ты полностью можешь контролировать ээ скорость, которой он Ну в плане в плане, как это делается. Ну как MCP сервера работают? Ты вот через что работаешь с MCP серверами? Ну, я работал через cloud код, через и через cloud desktop. А, ну, в принципе, да, если это агент не твой, то есть я-то из своего кода в этом проблемы не вижу. Когда свой код, тогда ты вызываешь через rateit. Вот. Ну, а здесь, да, наверное, никак без вмешательства в код тыйлимит не сделаешь. Не, ну просто это очень странно, что там, вот, например, там есть этот мм getме message, да, тут суть в том, что ты даже, я не думаю - что-то это даже как-то вот при помощи ручного вызова или, мм, или вызова модель. Ну, хотя нет, можно как-то ограничить. Короче, с��ть в том, что функцию send message, э-э, там сейчас получается где-то здесь вот get messages, по-моему, суть в том, что ты тут можешь вроде бы указать больше 100 сообщений или тут pageч сайза. Ну, короче, в Телеграме ээ нельзя там больше, чем один запрос в секунду делать. Если ты делаешь больше, то твой аккаунт может попасть в серзону, а потом вообще откинут. И тут, короче, суть в том, что вообще никакой защиты. И у меня вот на телеграмом SMP отлетело два real user selfбот аккаунта. Пытался что-то сделать. Ээ хотел сделать агента, который ведёт свой канал полностью в Телеграме, э-э, прямо вообще от аватарки до постов, до модерирования контента. Там кто в комментариях что-то пишет до пиара, то

[03:34:00] есть прямо вообще автономного агента запускается в Telegram, да? А вот кто парноботов запускает в Telegram. Понятно, да? Нет, да нет. Ну, конечно, ну, конечно, там ботик может подумать, что это актуальная очень такая темка, которая многих заинтересует, но я не думаю, что он будет юзать. Как к Джеми не подрубить MSNP сервера? Так, так,так. Как быстро подрубить? Где файл settings Jon? Вот Gemini, да? Gemini settings на уровне проекта у него файл туда вставляется. Из документации лучше скопируй все конфиги. И там вот я у меня документация. Вот се. Тактакта тактак. Ну давай попробуем какой-нибудь этот добавить discскордом Smp. Нет, не так. M SP сервер. Так, что-то что-то не то, по-моему. Так, а нам надо, наверное, чуть-чуть более цельно обозначать, какую цель и результат. Мы сейчас что хотим? А мы я затронул не просто просто ты затронул сему с дискордом. Вот я решил решил порыть своим S&amp;P сервера дискорда. И вот поэтому вот я решил сейчас потыкать. Понял. Да дует. Я хотел в студию вопрос задать Андрею. А расскажи, пожалуйста, о Flow WI, вот про агентность, которую ты говорил. Что там, как её можно завяз��ть? Интересно. Вот. Мне мне коллега показывал, он активно используется Flow для построения агентов. Он ээ ну накликивает Flowй

[03:36:00] агента мм э ну там цитирует, проверяет, он начинает у него работать, а затем там прямо в Flow не помню команды, ну, можете посмотреть там просто можно получить ум для обращения к этому агенту. То есть то есть можно дальше программно использовать всю эту цепочку как один выжит. А, а какой кейс жизненный? Типа он написал бота д��я недвижимости на миллион руб. [музыка] Ну, какие задачи? Ну, если это нет, сейчас, сейчас я пытаюсь вспомнить. Э, ну, например, э-э, приходит от клиента, э-э, э, задание проработать ТЗ, э, да, э, или, мм, что-то такое вот. Ну, у клиента есть какая-то специфика, э, он, соответственно, раскладывает это на цепочку, на части делает мм э различные ветки, которые каждую свою часть прорабатывают, используя MCP, какие-то внешние источники. Вот, потом всё это собирает, проверяет и делает в конечном итоге лендинг, э, который, ээ, ну, ну, потом отдаётся клиенту. То есть, условно говоря, клиент, ээ, отправляет ТЗ, через какое-то небольшое количество времени получает кликабельный лендинг, который, э, хорошо прорабатывает его ТЗ с учётом там, ну, всех всех факторов. Вот. И, соответственно, вот эту всю эпидерсию он накликивает в лой. Вот. И она начинает работать. И дальше, соответственно, он просто программно вызывает, то есть пришёл новый запрос, отправляет и получает такой результат. Но это работает пока, что называется, на коленке, да? Ээ то есть это ещё не

[03:38:00] запущено в какой-то там продакшн или из этого не сделан какой-то продукт. Но вот сама идея того, что ты можешь э как бы распараллелить эту часть, то есть, допустим, ну вот тоже это вопрос, потом, может быть, на него ответ кто-нибудь даст. Вот когда мы сегодня общаемся, почти всегда все говорят: "Я я сделал, я ч��о-то сделал". А вот здесь ситуация, когда команда работает, идёливание, он, э, соответственно, м готовит вот этот вот сценарий, и дальше другие люди им пользуются. Они уже э ну как бы прорабатывают качество работы этой модели и возвращают. Или ещё кто-то, кто проработает отдельные ветки, сценарии, там пром прописывает, потом ээ всё это собирает. То есть такая командная работа. Поэтому для этого и нужен нужна возможность запуска этого агента программы целиком всей ветки получается. Насколько я понял, это вот помимо вот этой визуализации хорошие, удобные инструменты и ноукод, и коннекторы и дающие как бы гибко настраиваемые с агентскими вызовами. Да, да, да. Ээ, причём, вроде бы как из этого всего можно получить Python код, который всё это делает. Вот. И опять-таки, ну, как вы понимаете, если это, ну, какой-то конструктор, визуализатор, он же описывается конфигами. А если конфигами, они выгружаются, загружаются, значит, их можно сгенерить. Поэтому у меня тоже было домашнее задание такое для себя. -э, попробовать. Э-э, вот я слышал, что делали эксперимент для N8N, сгенерить сценарий. Вот сгенерить для Flow, потому что, ну, штука такая интересная, а, у неё очень активная комьюнити. Они немножко разные по целям с NM, но ээ интересная задача, например, такие как я. А чем они разные?

[03:40:00] А, ну вот, ээ, я толком, мм, не понял, насколько я, ээ, понимаю, FLI ��н как раз для для создания агентов, да? А NMN для уже конечных каких-то м приложений. Я так для себя это понимаю, может, ошибаюсь. Угу. Ну, я так понял, он появился просто после, а, N8N, взял философию нот, но фокус всё клепать из агентов и айтулов, типа того. Ну или даже вот агентов, где нода - это больше агент скорее с коннектором, чем просто какая-то нода, которая лol. А у N8N уже потом добавляться начали. Это может быть коннектором. Я вот сейчас листаю GitHub скинул. Хотел посмотреть, насколько они популярны по Openроутеру, но они своё там вроде юзают. Но это типа тоже open source выходит, как NN. Бери и пробуй. Я ещё помню такой был Lengow, по-моему, один из самых первых. Не знаю, насколько он развился по звёздам. А сейчас сколько звёзд? 90.000. Блин, хайпажёры. Но я имею в виду, что как авто появились первыми и всё с такое количество звёзд. Ну вот я могу в качестве домашки взять, но опять-таки ничего не гарантирую. Если, ну что-то будет интересное и получится, я тогда расскажу с удовольствием. Отлично будет. Круто. Ну давайте тогда действительно на следующую субботу выдумаем такую себе челленджик и я промодерирую там, условно говоря, если у

[03:42:00] нас будет строительство каких-нибудь, да, пайплайнов, что-нибудь workflow каким-нибудь. Может быть, быть. Я вот изучила или или преза, или демо. Ну, типа, ну, грубо говоря, там эфир на 15 минут, максимум 30, чтобы если мы хотим там четыре человека. Ну, дема поинтереснее, конечно же, будет. Ну да, ну, может быть, не все инструменты, если как бы дема нет, то покороче, да. Я вот сейчас зашёл на авто GPT, у них 177.000 звёзд вообще. Кто уж сейчас этим пользуется-то? Ну просто старая штука-то. Ну да, слушай, а Last Week что не обновляли? А, GitHub work обновляли, MD добавили. Вот, вот этот, э, друг, который агентов делает, вот он их там срчил, типа, и говорит: "М, ну, не так их много этих, 10 там фреймворков. Самый какой-то заметный - это Нграф. Вот есть Мастра, которую Денис щупал и там может ещё кто-то, а остальные вот такие какие-то не поймиче. Только как бы самый перспективный. Вот он граф Мастро, я не знаю, кто ещё. А эти, ну, что-то делают вроде вот как будто у них сайт есть что-то. Это, я так и не понял. А есть, кстати, ещё один такой метод GPT. Я его увидел по ссылкам Александра его. Хаби, может, он что-то знает. Скажи про него. Я не тыкал. Тут, кстати, интересно в этих workflow. Нет, нет, у другого Александра. Вот у меня что ли у Алекса? Дадада. Я не помню, что что ты видел? Скажи. Meta GPT M agent Framework. Саш, к вам в звёзды залез один

[03:44:00] репозиторий неизвестный. Да. А, ну я я просто это самое см��трел, когда всё это делал, я там как бы набирал себе посмотреть всё это дело. Ну я я сейчас уже не помню. Я последний раз, наверное, трогал два назад. Там, насколько я помню, из такой специфики, там можно было поименовать агентов, дать им роли, вот описать флоу. Ну, я Pth использую на Pйthне всё это хорошо, что было можно сделать. Вот. Но сам не пробовал, только только почитал. Думал, как раз может кто-то скажет. Доста. Ну вот из из того, что я, короче, вид��л, блин, да, вот ээ ну опять же это было пару лет назад. Вот. То есть после этого я, в общем, как бы своё что-то пилил. Вот в основном. А из того, что я видел, что, короче, было интересным, это был, значит, во-первых, я сейчас не вспомню название, короче, GPT, который, а, типа контекст с контекстом работал, как будто это виртуальная память. Вот. То есть он подгружал, как надо, там всё такое. Вот он был неплохой, но у него было очень жёстко зашито. С чем он работает? Он работал, а, с ��итоном, чтобы с чем-то другим, например, заставить его работать. Это была проблема большая. Вот. А потом, да, и, ну, короче, у них у всех была для меня как бы вот, ну, для моего случая была проблема в том, что они, а, либо там через очереди какие-то общались, либо просто непосредственно вызов делали какой-то. Вот. И была очень жёсткая структура агентов, которые они поддерживали. Ну, выглядит как если быстрый бизнес что-то там делать, клепать вот извас и прочее, оно норм, но по факту это всё по сравнению с Кирой и код-код, это не до штуки по идее в

[03:46:00] теории. Ещё сложно. Это всё маломальски сложнее, чем элементарный флоу, да, из пунктов. Всё это превращается в довольно навороченную такую систему, слабоуправляемую. То есть тебе нужно иметь реально алгоритмический стиль мышления и, в принципе, склонность к программированию, чтобы это нормально всё обустроить. Те, кто шарит в программировании, они на этих штуках более-менее нормально всё делают, потому что они делают под программы, они модульность соблюдают, они процесс какой-то там прописывают. А если народ не очень шарит, у них такая [ __ ] получается, там такой макаронный монстр, что просто ужас. Понять, что происходит, довольно сложно. Вот. Ну и, на мой взгляд, э вот эти все конструкторы отличаются тем, что на них что-то сложное скрутить, э, порой сложнее, чем код написать, если умеешь. И м как бы м когда линейная линейный алгоритм, да, когда-то 1 2 3 4 5, да, из кубиков его собрать просто. Там самый ад начинается, когда у тебя алгоритм начинает быть условным. То есть тебе там надо какие-то условия, какую-то обработку данных сделать. Вот эта вся [ __ ] Вот она на такие конструкторы ложится тяжело. Не дай бог циклы или сложные циклы, там вложенную какую-то логику. То есть когда у тебя из линейного алгоритма превращается в нормальную программу, тогда это всё абсолютно неуправляемое, на мой взгляд. Вот поэтому каждому инструменту, наверное, своё поле деятельности. Вот это для простых таких алгоритмов. Угу.

[03:48:00] Потому что получается в разрезе этих штук о них общаться типа их инструментарий - это как типа фиг мне. А вот тот есть инструмент. Надо, получается, или тогда вот такую прикольную штуку, типа я из неё сделал, где может слышали, есть такой алмаз там парень потишал чат, он там типа на таком видосике своём такой раз показывает, ну вот этот бизнес-процесс или resarch я так делаю, это так, и он показывает вот эти как бы наброски, он в код-код наруби кодит, а вот для бизнеса, ну такой он смесь предпринимателя и засучил рукава, вспомнил кодерство и показывал какие-то он реальные боли задачи решает. Вот деф и прочик с коннекшеном там к редитам, дискордом и прочим. Он вот на N8 B делает. Ну там может потому что привы Не, оно, смотри, оно здорово работает, когда у тебя абсолютно ясный линейный алгоритм. То есть ты втянул данные, что-то куда-то там передал, по цепочке оно прошло, вышло. Но если тебе нужен сложный алгоритм обработки этих данных какой-то нелинейный, там циклом условный или ещё что-то, то здесь вот эти все блоки, они не очень выразительны, они плохо позволяют это дело делать. Там данные трансформировать. Если у тебя получены данные в одном формате, тебе надо их дальше чуть-чуть трансформировать, передать в другом формате. То есть, если в коде элементарно делается, то в этих всех конструкторах там какие-то ставятся блоки трансформации. Вот это всё. Так не очевидно. Угу. Вот ну вот в этом сложность некоторая, что а программирование оно не заменяется, оно как бы здесь трансформируется и начинает делаться неудобными способами. Вот. Вот когда до этого доходит, это значит инструмент исчерпал свой потенциал. Надо менять инструмент. А у парня, наверное, просто, ну, нет таких кейсов и всё прекрасно

[03:50:00] работает. Ну, как бы здорово. Угу. Кстати, ещё вспомнил вот такое, но это уже, э, кто-то использует такие какие-то бойлерплейты Нест или всегда пишете с нуля или Пайthна API какие-то, которых много звёзд. Я вот использую там один Prзма. Ты ты про что? Ты про что? Ну, на гитхаберпо ты хочешь начать какой-то проектик, например? Ну, многие вещи, а типа шаблоны, что ли? Брок. Брокоorders, например, есть для несса такой попул��рной. Ну, я не знаю, кто на несе делает. Или или всегда вот с нуля все сами архитектуру делаете. Ну, слушай, я пробовал бы так и так. Вот фронт, который я не очень люблю и не очень понимаю. Я брал boйлерплейты на нексте. Как бы, но в чём плюс? Когда ты buлерпate берёшь, то у тебя уже приложение похожее на настоящее, красивое, проработанное с фишками. Но для того, чтобы въехать в этот бойлерпateт, нужно прямо реально потом потратить силы и время. Сейчас, слава богу, нейронки есть, они могут объяснить, что где там и от чего. А так приходилось туда нырять и разбираться. И это не всегда очевидно всё сделано. То есть иногда там даже врплейтах, даже в популярных всё как бы некоторые вещи из говна и палок скручены или как-то не очень оптимальным образом добавлены или а так как он популярный и развивается, то там начинают какую-то фичу делать и она там в полуготовом состоянии где-то что-то прикручено, но не докручено и код такой неоптимальный. И, короче, для того, чтобы потом

[03:52:00] какие-то фишки убрать оттуда, надо тоже сильно постараться. То есть просто так всё отключить не так просто бывает. И получается, что ты себе в проект напихал кучу кода, который не твой, в котором ты же слабо понимаешь и как с этим работать не очень сечёшь, разбойлерпate использовал. И это вот некий создаёт риск. Вот если твой проект очень похож на тот бойлерплейт, который тебе нужен, ну круто, как бы ты сэкономишь время на создание. А если тебе из этого бойлерплейта нужно чуть-чуть, тогда проще этот бойлерплейт скачать, нейронку расспросить, как это всё реализовано конкретно, вот этот кусочек, и в своё приложение самому руками добавить, чтобы всё было ровно и правильно. Вот такое моё мнение. Может, кто поправит? Ну, я в целом согласен, да. То есть действительно что-то такое незнакомое, наверное, поверх известной нейронкам технологии. То есть нейронки вот о том, что наверчено поверх известной технологии, типа поверх того же Next JS, а в конкретном бойлерплейте, они могут и не знать, и тебе каждый раз придётся вот заново этот путь с ней проходить или документировать это всё на старте проекта. Ну, короче, не очень интересно. Я пришёл к тому, что я беру, а как можно более стабильные версии а вот этих вот фреймворков, типа того же Nextса, и сопровождаю это всё своим архитектурным видением. То есть уже вот после того, как несколько таких проектов сделаешь, примерно понимаешь, какая архитектура конкретно для тебя приемлема. Ну, то есть там, не знаю, какие архитектурные паттерны использовать, по каким слоям систему разделять, как базу данных проектировать. Я просто вот это вот

[03:54:00] выделил в качестве не некого набора инструкций. И в каждый новый проект я с этим набором инструкций прихожу. А, и фактически это у меня болер Plate. Он не в виде кода. Это мой собственный бойрплей, получается, но он не в виде кода, а он �� виде а спеков, подходов, концепций. Вот. Да, приходится чуть больше, может быть, времени нейронки тратить, чуть больше токенов на то, чтобы в конкретном проекте это всё нагенерить заново. Вот. Но с другой стороны, стабильность такого решения и управляемость, она как-то повыше, чем бороться, например, с боле с бойлерплейтом, который я получил от кого-то. Как-то так. А знаешь, Максим, напомнила дискуссию, которая у меня на неделе была человеком. Как раз примерно об этом. Мы, я уже упоминал, обсуждали, что спеки - это новый код. И там как раз обсуждали, что порой, наверное, сейчас, э, рефакторинг и заботка, она может и устареть. По какой причине? Жайлом мы пользовались когда был работающий код и надо было новую фичу реализовать, да, она прикручивалась куда-то туда и как-то интегрировалась, да, там делались интеграционные тесты, делались там всякие разные тесты, чтобы мы старое не сломали, а новое бы заработало. А сейчас фактически можно как делать? Ты вносишь в спеки новую функциональность, говоришь: "Хочу, чтобы вот это работало". И нейронка в состоянии выработать общее техническое решение, которое включает и новую функциональность. И порой может показаться, что так уже правильнее делать. То есть проще, чем интегрировать новую функциональность, существующую систему, проще всю систему перегенерировать,

[03:56:00] чтобы включить и новую функциональность, в том числе. Тогда не нужно будет ни рефакторинг делать, ни а какое-то инкрементальное вот это вот развитие. А просто у тебя каждый раз новая система, она то есть это будет нормально, потому что остальные-то спеки никуда не делись, и она им соответствует. Вот такой интересная мысль. Ну пока как бы я живьём такое не пробовал делать. То есть, грубо говоря, у тебя есть система, ты туда дописываешь какой-то эпик. Ну, я понимаю, да, о чёмрует вот весь всю систему перегенерирует. Я вот пока, ну, ну, мне прямо стало любопытно, что мысль-то не без оснований, и, может быть, стоит попробовать как-нибудь, то есть генерировать интеграцию вот этой вот этого эпика, а сказать, что вот забываем все implementation планы и перегенерируем их заново в рамках объединённой вот этой всей функциональности. Ну, оно как бы к этому всё идёт. Это логичное продолжение развития вот э технологий, потому что там, я не знаю, какой-нибудь код или баййт-код он же тоже генерируется каждый раз заново. То есть мы мы же его тоже не храним. То есть он просто где-то там в памяти генерируется, потом компилируется в нативной инструкции. Это тоже примерно похожий процесс. То есть он просто спускается там на, точнее уровень абстракции повышается. Я скорее мы просто на уровень абстракции перешли на сл��дующий. То есть, если сейчас мы по правилам пишем код на языке программирования, то следующий уровень абстракции мы по правилам пишем спеки. Да, тут единственный момент - это, а, сейчас это масштаб подобного рода систем. Ну, то есть я могу консистентно перегенерировать пока что системы и

[03:58:00] функции небольшого масштаба вот в такой методологии. А, и если сейчас этим пытаться заняться, ну, масштаб будет небольшой. А вот в перспективе, когда мы пойдём к большим контекстам, а, к большей стабильности, к большему ризингу моделей, там, да, там уже можно будет такое осуществлять. Сейчас я пока что таким подходом пользуюсь в рамках, ну, реально очень небольшого количества кода, который вот действительно мне проще а взять и перегенерить. То есть это это я уже использую. А вот так, чтобы типа вот какую-то большую систему, ну нет, пока что всё-таки мне нужен рефакторинг. Вот мне нужно прямо вот в некоторых случаях менять систему аа не перегенеривая её целиком. Пока что не хватает контекста у нейронки, чтобы осознать там проекты, которые побольше, вот чтобы их так качественно перегенерить целиком, внедрив туда какую-то новую фичу по ходу. И есть ещё проблема фиксации конечного результата. То есть, грубо говоря, вот пользователь работает с калькулятором с каким-нибудь, у калькулятора стабильный интерфейс, он вообще всегда один и тот же. Тебе новую функцию в в калькулятор нужно добавить и нужно обеспечить консистентность пользовательского опыта, а абсолютную консистентность. Вот ты просто дополнительную свечу добавил, всё остальное осталось на своих местах. И вот с этим ещё пока что проблема. фиксация конечного результата тоже вот его бы желательно эту проблему бы тоже как-то решить. А так, да, направление в целом, мне кажется, прямо это нормальное. Так, в этом направлении всё движется. У тебя даже видеогенератор.

[04:00:00] какую-то новую фичу по ходу. И есть ещё проблема фиксации конечного результата. То есть, грубо говоря, вот пользователь работает с калькулятором с каким-нибудь, у калькулятора стабильный интерфейс, он вообще всегда один и тот же. Тебе новую функцию в в калькулятор нужно добавить и нужно обеспечить консистентность пользовательского опыта, а абсолютную консистентность. Вот ты просто дополнительную вещь добавил, всё остальное осталось на своих местах. И вот с этим ещё пока что проблема. фиксация конечного результата тоже вот его бы желательно эту проблему бы тоже как-то решить. А так, да, направление в целом, мне кажется, прямо это нормальное. Так, в этом направлении всё движется. У тебя даже видеогенератор сейчас референтный или там в генераторах картинок там референтная генерация, да, когда есть референция, она им следует вот и сохраняет консистентность. И я думаю, в коде будет ровно то же самое, только референциями будут спеки. И весь вопрос в том, что мы спеки немножко сейчас понимаем пока ещё одностороннее. Это когда мы даём нейронке задания, а тут должен процесс, мне кажется, быть двухсторонний, то есть итеративный. Ты дал задание, ��ейронка что-то нагенерировала, ты дал обратную связь, и нейронка уточнила спеки. И вот когда спеки генерированный нейронкой по готовой системе, тогда эти спеки могут быть крайне подробными и описывать всё как надо. Вот чтобы калькулятор свой консистентный пользовательский опыт не потерял. Только тогда калькулятор должен быть описан нейронкой, правильно? Потому что если ты будешь описывать калькулятор, ты что-нибудь не допишешь, как водится. Ну и в генераторах картинок и видео, ты же знаешь же, как с этим борються. Там нейронка описывает эти кадры, те. Вот, соответственно, мне кажется, просто мы ещё со спеками недостаточно правильно работаем.

[04:02:00] Ну, может быть, но в любом случае тут какой-то элемент такой стахастичности остаётся, и там рандомный результат сейчас получить прямо легко даже в случае с генераторами картинок. Вот. То есть это пока что даже там является проблемой. Мы пройдём некоторый путь до того, чтобы это всё стабильно начало работать. А по части восстановления, кстати, спеков по этим по готовому коду. Вот я, пока мы сидели, я тут киры тоже позапускал. Аа у меня там есть прототип проекта в начальной стадии, но она неплохо восстановила по тому коду, который уже есть в проекте. отметила в спеках те таски, которые уже реализованы. Вот, кстати, тоже такой обратный реверс инженеринг. То есть я думаю, что её вполне можно попросить по готовой реализации и спеки составить, потому что сейчас я ��ё просил из неструктурированных спеков к этой системе сделать формальные спеки, которые ей нравятся, она сделала. Но, скорее всего, то же самое можно сделать и с кодом. То есть дать ей код, сказать, типа, вот смотри, есть система недореализованная, она восстановит из него те спеки, которые уже сделаны, и можно ей сказать, типа я хочу вот ещё что-то сделать, и она добавит эти новые спеки к существующим. И потом можно будет догенерить вот то, что тебе нужно догерить. То есть кажется, что Kira уже позволяет такие сценарии делать. Вот только вопрос типа фиксации конечного результата. То есть, чтобы он прямо зафиксирован был жёстко. Вот так. Что интересно хотелось сказать, что мы-то, наверное, так можно сделать. Мы чуть-чуть ушли в деталь. А тут главный смысл был следующий. Будет ли рост м пользы от того, что мы каждый раз целостное решение генерируем? Вот, грубо

[04:04:00] говоря, насколько доработка софта по кускам вносит какие-то искажения или недост��тки некие. Вот. Но это как бы вопрос, на самом деле, требует исследования и вопрос философский, потому что, ну да, он, собственно, всегда он открыт и в случае людей, типа, как мы нам нам лучше сейчас всё переписать или всё-таки это разберёмся и добавим фичу? Ну да, до основания и затем как водится или всё-таки методом итеративным, да, там достройки. И вот это вот как раз, если раньше можно было сказать, что это безумие, всё переписывать каждый раз, зачем тратить ресурсы, то сейчас это просто получился вопрос подхода за счёт нейронок. То есть снижение трудоёмкости, что нейронки на себя эту трудоёмкость берут из-за недорого. Вот уже этот вопрос вновь встаёт, и к нему подходы уже могут и поменяться. Очень крайне любо всё. Дада. Он что прикрутил поверхгенетические алгоритмы? Пускай оно там генерит до тех пор, пока это нормально не сгенерит. Да. Так я тому что я уже ратимальности, да, туда прикрутить, сказать, ��то слушай, воткэнд, а, но давай ты будешь генерить до тех пор, пока этот бэкэнд не начнёт на 40% быстрее работать. Вот. Потому что не устраивает производительность, да, там оптимизируй. Мне кажется, кстати, легко у нас оптимизирует какой-нибудь там кэш вкрутят и телемаркет просто Да. Тут просто, а, всегда остаётся опять ещё одна из таких концепций, а потом способность в этом, во всём разобраться. Это типа, знаешь, как вот FPJ платы, а, генетическими алгоритмы пытались генерировать, там такое получалось. Ну,

[04:06:00] то есть оно работало, оно хорошо работало под свои задачи, но разобраться в этом было вообще невозможно. Точно так же, как вот, например, с биологическими системами. То есть те системы, которые аа выстраиваются эволюционным путём, там, как правило, столько всего интересного происходит. То есть, грубо говоря, на биологическую эволюцию в основном давит оптимизация энергетическая, там времена и всё такое. И вот там очень страшные решения формируются. Их невозможно понять. Это какие-то безумные киборги, кажется, проектировали. Вот проблема в том, что это никто не проектировал. Это в этом никому не нужно было разбираться никогда. Оно сложилось так, как сложилось. И вот здесь вот тоже нам в какой-то момент, видимо, нужно будет решить для себя, а нам вообще надо разбираться в том, что генеронка сгенерила или мы всё-таки к модели чёрного ящика перейдём. Генерит оно там пусть хоть ти��а кашечки или ехать. Ну да, да. То есть пусть оно там генерит совершенно какой-то безумный код. Нам не надо в нём разбираться. Нам вот, пожалуйста, все контракты снаружи описали. Пусть оно там оптимизирует всё, я не знаю, там, а потом слюте курсор на 500 млн долларов. Слышали, нет историю? Дада. Да. То есть и вот это вот такой интересный, конечно, вопрос, типа, а надо ли нам разбираться? Но вот я, например, во многих случаях, э, сейчас уже в тех местах, которые я знаю, что нейронка с ними хорошо справляется, ну, чисто вот по по наитию, я даже не проверяю, что там получилось. Вот. То есть мне достаточно тестов, мне достаточно формальных критериев. И насколько далеко мы зайдём? Всё-таки удивительно, как всё по спирали развивается. Я ровно эти же разговоры вспоминаю в момент, когда происходил переход от программирования на ассемблере к программированию на языках высокого уровня. Ну, типа того, да. Там некоторые адепты говорили, что типа, ребята, ну никогда компьютер и

[04:08:00] компилятор не напишут нормальный код. Потому что он будет неоптимальный там в каких-то местах. Вот тут, тут и тут. Он типа это не умеет делать. Типа нафиг это надо. Но как бы 99% людей просто забило на эту неоптимальность. И внутрь кода уже там на уровне инструкции давно никто не смотрит. Ну, может, как бы операционные системы кто-то ещё профилирует по перформансу, а потребительский софт, мне кажется, ну, только в самых запущенных случаях смот��ят, и то не на уровень инструкции уж, а на уровень исходного кода. И как бы все забили и смирились. И мне кажется, произойдёт здесь ровно такой же переход, то мы будем знать паттерны спеков правильные. как спросить и что нужно правильно спрашивать, чтобы получился правильный результат. А нейронки внутри будут уже всё формировать так, как надо, как попросили. Да. Да. То есть концепция чёрного ящика так или иначе, я думаю, наступит у нас. То есть мы не будем, точнее, как вполне возможно, что вообще вряд ли он изобретётся сам собой язык специализированный для работы LM с кодом. Ну просто потому что у нас с датасетами на этом языке будут проблемы. Но чисто в теории, если предпринять какие-то сознательные усилия в этом плане, можно действительно и язык сам придумать и обкатить датасеты им. И можно было бы тогда вообще хоть в машинных кодах, я не знаю, все эти новые программы генерировать. Вот без того, чтобы вообще вот этот этап этап человеческой человечески понятных инструкций в виде текущих языков программирования использовать, но это кажется уже чуть

[04:10:00] подальше, ну там году так 2027. Угу. У. Ну, а, кстати, интересно, кто-то учит модели на Можно ли сделать на базе модели компилятора? Вот теоретически, наверное, ничего невозможного нет. Ей какая разница? Ну да, хороший вопрос, вроде не очень нуж. То есть я, например, знаешь, у меня были эксперименты, я в чат GPT, короче, пытался, значит, как бы описать словами, как модель должна парсить, а, ну, например, ник вот или там email, да, вот описывал, что, короче, ну, очень часто люди употребляют там, например, или дату какую-то, или там год рождения, если пытаются сделать нек уникальным, или там год подключения к сети или что-нибудь такое, да. Вот. И имя чаще всего, значит, либо first name или name, или оба вместе. Вот, чтобы она, короче, для каждого там данного имейла она определила, ну, вот эти вот части, короче, э потенциальные части этого имейла. Вот это работает, не вопрос. Вот. Но это из пушки по воробьям. Ну, в этом смысле, да, если софтину, хотя если язык программирования переводится в код довольно быстро и просто, то, наверное, нет смысла учить модель генерировать машинные инструкции. Да. Да. Плюс там куча процес артефактов текстовых артефактов у тебя выше крыши, а бинарных как бы вот соответствующих тому, что делает, ну, это вопрос.

[04:12:00] Ну да, видишь, чисто трансляция одного в другое. Ну, в любом случае, мне кажется, что уровень абстракции сейчас примерно понятно, куда в программировании уходит. То есть вот очередной виток - это мы начинаем писать спеки вместо программы. Угу. Самое интересное, что язык оказался на самом деле, ну, то есть вот как бы язык общения, да, вот он оказался как это новым золотом, да, способность ясные солагать свои мысли, имеешь в виду, типа, э, не, не только, то есть ну то, что вот A, в принципе, оказался способен работать с Natural Вот, и обучаться на нём. И реально, короче, вот за счёт обучения этого начинать как бы понимать и выстраивать модель мира. Вот это просто шикарно. Угу. Да. Ну я жду brain tox for жди треба надо ээ ну это я так уж шучу но непонятно когда это будетгу потому что это ещё больше более эффективный способ ну ладно если не уходить в теорию, что можно применить через неделю темы сегодняшней, а то у нас прошлый звонок был. очень этот как сказать на все темы. Я вот

[04:14:00] сейчас, кстати, попробовал тривитер установил, он там проверил, но этот не так активно юзает, пока ещё не выжил. А Кира установил. Спасибо, Денис. Я просто сказал коду сейчас въебу, если не доделаешь. И он сделал. Ну там, мне кажется, у тебя это разрешение там он мною скачанный на твоём компе должен был заругаться по безопасности на это всё дело. Ну да, дада. Так, �� как смотрите на то, чтобы звонок провести следующий? Как мы можем сделать воскресенье, но сделать его прямо лимитированно коротким. Если, может быть, кто-то хочет уже на завтра лимитированно коротким до 2 часов или можем даже до часа, два по полчасика workшоп пробовать такой формат помимо фриток, чтобы как-то пробовать создавать общие common best practices и sharing knowledge and experience. А можем на следующую субботу уже так как по плану? Мне кажется, лучше попробовать на следующую субботу этот формат потестировать. Во-первых, что-то подготовиться и потестировать вот воркшоп именно, потому что пока, мне кажется, ещё никто толком даже и не смотрел, что там надо сделать. Не факт, чтобы завтра это всё клюнется. Да, хорошо. Я тогда в, ну, в группе начну или, может, в личках сначала спишусь, чтобы не этот, э, легче было какой-то формат. А я, например, беру триситер от себя и можно вот какие-то каждый, наверное, порепки и, например, какой-нибудь best practices типа делать. Вот, наверное, такой формат. Я не знаю,

[04:16:00] нужна ли под него запись или не нужна. А, а с фигмой дожмём. Ну, это надо Уримы спро��ить на Да, давайте я сделаю, конечно, уже доразбираюсь совсем с этим. Ну, у меня вчера самое главное всё работало, а сегодня всё полетело. Вот. Ну, я думаю, что за неделю я всё разберусь, покажу. Там есть интересные моменты, да, а как это всё работает. Ну, конечно, это не совсем с точки зрения девелопмента, но с точки зрения дизайна, да, и, а, вариантов так неплохо прямо. Угу. Тогда, ну, я думаю, оно оно будет короткое, то есть я не думаю, что это там надо делать очень длинльное. Ну, как раз там минут 20 всё это и займёт, и остальное там кто там ещё дальше хочет что-то показать. Я думаю, это классный формат, да, а делиться какими-то знаниями, ну, кто в чём разбирается больше. Угу. И хотел бы, знаете, ещё попробовать такой не блиц вопрос, а на концовку. Что-то поднёс такой тоже интересный вопрос. А кто как успевает черпать знания? Ну вот про источники мы проговорили. Я там ещё накидал чуть-чуть в хнгаус в чате. Аа кто вот смотрит, что курсы, книги, YouTube видео или просто в чатах ТГ? Как вот как-то если более системно, ну хотя чаты ТГ не совсем системно, но всё равно аа обучается. Я вот, например, или под оком получается у всех, э, антропиковским, например, смотреть, или с той же GPхой, а, ну там, кодом, да, прояснять. Лично у

[04:18:00] меня, чтобы начать с себя, например, а, топ пунктов по факту я что-то хочу. Я себе сделал такие такой промт, там у меня обсидиан, я какую-то тему просто делаю несколько типов заметок. Это либо чит-шит, либо вот как репорты, когда я проясняю какие-то вопросы и остаются артефакты, как мери у Дениса, только это resarch. И, ну, а на документацию попадаю только вот кусочками, когда решаю вопрос и там оттуда вычитываю. Но, судя по чатам, считаю, как будто нужно штудировать антропика. Вообще все доки, они помимо документации на продукты, у них ещё очень много качественных вообще любых э образовательных материалов. Но может кто-то использует там Юдами или какие-то YouTube курсы или канал или ещё что-то. Вот интересно, кто какие? Ну я на парочку подписыва, я YouTube смотрю. А, то есть как-то системно или какие-то типа топ чуваки? А по вопросом, например, возникает какой-то вопрос или нужно что-то сделать, я, например, не знаю, да, либо мне недостаточно, а, то, что мне выдаёт там, например, GPT, да, тогда я иду и смотрю по шагам, как это сделать. Ну, YouTube в этом плане лучше всего, да, я просто системно смот��ю, а то вот у антропика вышло и курсов много, и в целом deep learning и есть такие тоже ребята что-то показывают базовое. У нас Сергей ушёл со звонка, он вот все курсы, мне кажется, пересмотрел. меня всё время кидает,

[04:20:00] а я, ну, три, может быть, за год посмотрел такие: "А, ну вот, да, извини, что перебила. Я просто вспомнила, что я ещё смотрю дизайн код. Там у них тоже разные курсы. Вот. Ну, это по подписке, да, типа 20 долларов в месяц. И ты смотришь там, как это делать вот это какие-то разные вещи. Там их очень много видео разных. Ну я, в принципе, да, я люблю по видео всё смотреть. Кстати, по поводу подписки вспомнил AI Builders Club, по-моему, сейчас скину китаец с каким-то известным каналом. Или это не они? Ой, извините. Ну, короче, я скину попозже. У кого-то кто-то хочет ещё, может, поделиться. Не, у меня как-то хаотично обучение происходит. Я когда в какую-то тему погружаюсь, я там набираю, конечно, материал, но это такой ресё скорее, чем обучение. И вот ээ просто есть определённый поток новостей, каналов, на которые подписан. Вот. какие-то YouTube каналы, которые периодически что-то постят. Я могу что-то отсматривать, но абсолютно несистемно. Это хороший вопрос, на самом деле. Об этом стоит задумываться. И сейчас вот мы в какое-то такое время живём, когда вся информация доступна, да? То есть можно и нейронку порасспрашивать, она довольно предметно ответит, и даже той же нейронкой поискать и депрессио, если уж хочется углубиться. Так, возможности-то все, а вот как бы как этим правильно пользоваться, это очень вопрос на 100 руб. прямо. Ну я вот люблю системно ко всему

[04:22:00] подходить, точнее по-другому не умею. Ну, в то же время одновременно бывает и рандомизировано, но в большей части системно. Если выделить методологии обучения, я вот смотрю, для меня больше всего работает это какой-то такой на практике, то есть есть задача и ты всё под неё разбираешь, и он уже всё, конечно, закрепляется и так далее. Второй - это метод по сути через со вот эти действительно Telegram-группы или вот наши звонки или общения лучше оседают, как будто больше раз ты это проговорил, услышал, соприкоснулся. с разными людьми на эту тему. Тебя лучше это тоже осознаётся как-то в Q&amp;A. С нейронкой тоже хорошо, но это как будто больше режим сита включается. Вот остаются знания. А есть ещё подход, как будто вот такой структурированный через курс. Это я бы его выделил как какой? Четвёртый получается. И он как будто там много часто лишнего какого-то. то, что не знаешь ты как применить и как бы оно вот, не знаю, и ты устаёшь как будто от него. Но доки просто считать, ну, под демант эффективно, а так не знаю. Ну, я так скажу, что традиционно обучение хорошо, когда оно вовлекает себя разносторонне. А если хочется что-то усвоить, то, конечно, это надо, про это надо услышать, это надо самому покрутить. То есть ты должен послушать, почитать, сам скачать, с этим повозиться. Вот тогда ты это усвоишь. Если ты просто просмотрел видео в интернете и это никак не отразилось, ну, как бы это всё в одно ухо вошло, в другое вышло, по сути дела. То есть, ну, может быть, чуть-чуть как знание где-то там осталось в памяти, но не более. И

[04:24:00] классические приёмы обучения, как вот в университете учат, ты слушаешь лекции, а потом на семинарах это практически с этим работаешь сам. Но вот это никто не заменил. Это как бы технология не поменялась. Вот. Ну это естественно. М если ты просто будешь смотреть, навряд ли ты что-то поймёшь и запомнишь. То есть надо всё потом через руки пропускать. И иногда даже не один раз. Но вот то, что я сейчас замечаю, то, что настолько много стало, много информации, курсов обучения, что просто мозг взрывается. Иногда вот правильно, как Саша сказал, ну вот системы, да, какой-то не хватает. А что конкретно мне нужно там знать или выучить, чтобы, например, выстроить свою систему, да, там, ну, когда я что-то делаю, да, тот же, не знаю, дизайн, да, там от начала до конца. А вот, а получается сейчас, что у тебя и и это уза, это узаде так здесь. И вроде бы как всё это облегчает, да? А и в то же время это очень прямо overwelmм, я не знаю, столько всего нового и прямо не успеваешь за всем этим бежать, если честно. Но это вот мои какие-то такие личные ощущения. Угу. Ну, тут ещё как бы из комьюнити стоит выбирать именно как это, как я называю, high signal people. Ну, то есть есть люди, которые просто на хайпе э что-то пишут, типа вот какие-нибудь новостные каналы я вообще без перестал читать. Ну, потому что типа а смысл? Они каждый недель пишут о том, что новая пророная технология, сейчас всех заменят, роботы уже везде, короче, и всё такое. То есть и это вообще можно не читать. А желательно отбирать тех, кто, ну, практике как-то видно, что человек что-то руками

[04:26:00] делает, и вот информационную среду составляете из таких людей. Кажется, что вот это вот такой более гигиеничный способ, что ли, а-а, выстраивание вот этой информационной среды для себя. Вот это просто в качестве такой общей рекомендации. Ну да. То есть выбирать, получается, ну не то, что более популярные, а более quти кантен, правильно? Ну тот, который Ну да, да. Угу. Ну потому что часто вот бывают новостные каналы пишут, типа вот там вышел какой-нибудь этот ну типа вот агент от Open AI. Ну здорово. Он вчера вышел, там некоторые уже пишут, как будто вот это всё, типа, он всё всё в индустрии перевернул. С ним никто ещё не накопил опыт работы. Подождём недельку, послушаем тех людей, которые действительно с ним решили какие-то интересные проблемы. Они о них расскажут, напишут. И вот только после этого уже можно действительно серьёз какие-то штуки рассматривать. А то, что ты пропустишь неделю его использования какими-то другими, на тебе это не особо скажется. Вот. Но скажется потом на на том, что ты будешь будешь более осознанно относиться к включению какого-то инструмента в свою работу. В принципе, всё то же самое и с другими знаниями. То есть, если они не настоялись в сообществе, то тоже как-то я скептически ко всему этому отношусь. То есть я вот каждый день сканирую свою ленту в Редите. И там, во-первых, очень много людей, которые вот буквально вчера пришли во всё это, и они восторженно чём-то пишут, и там сразу вот по некоторым быстрым сигналам можно понять, что этот контент мне не будет интересен. Вот. И другое дело, что вот попадаются в комьюнити чуваки, за которыми я прицелен слежу, и я вот знаю, что от них интересные штуки приходят. Они там

[04:28:00] раскапывают какой-то процесс, какие-то технологии копают. Вот. И видно путь развития человека, видно, что он ушёл дальше меня, и мне интересно за ним следить. Вот. И как-то действительно вот такую информационную ленту лучше из таких людей стараться составлять. Вот. И в телеге я тоже практически от всех новостных уже отписался, потому что что-то как-то прямо грус��но за ними следить. Вот стоит искать практику в первую очередь. Угу. Ну, кем за себя могу сказать. Сегодня, кстати, разговор начался с того, кто сколько спит. Вот огня я выделяю не очень, правда, большое время, там, не знаю, десятка 2-3 минут ээ максимум в день. Ээ это вот как раз проверка этих, не знаю, интересных новостей. Вот ты сейчас сказал, что вышла новость аном агентей. Она по косвенным э параметрам меня очень заинтересовала, поэтому я потратил даже больше, чем 30 минут для её проверки. И если ещё какая-нибудь новость, вот тот же флуйс, про который мы сегодня говорили, тоже он меня тогда заинтересовал. Я я зашёл, попробовал, сделал эксперимент, и он у меня лежит. То есть какие-то новости, они не просто в закладки уходят, а они проходят следующий уровень. Закладки, которые я проверяю, они уже кусочке кода. Есть такая папочка у меня с этим микро, э, набросками, что ли, да? Где я уже это проверяю и дада, если да, идёт дальше? Нет, ну м отбросил. И это, кстати, тоже помогает. Потом по этой папочке можно поискать, а, вот эти вот эксперименты и ээ из них что-то вспомнить или вернуться уже

[04:30:00] с какими-то новыми знаниями и ещё раз попробовать провести эксперимент. Вот тоже помогает аструктурировать новую информацию. Я часто репу качаю. Если не запустилась за 3 минуты, значит Да, да, да. Это это вот как раз, да, один из подходов, что ты не так юмором сейчас сейчас-то надо читать. Не все уделяют время, ну, типалайнер такому, понятно, спеком. Иногда нужен код-код. Ну или самому вдумываться по старинке. А и и ещё вот задался задачкой, наверное, к следующей неделе я ситор и хочу подготовить какой-то обзервабилити код-кода. меня прямо вот никто, кстати, в папку глобальную код прок там же под папки путей аэ не заходил. Не, ну вот сколько у кого сессий код-кода существует, там 1.000, 100, 500, никто не знает? Не считал. Ещё раз. Ну вот типа есть код, он же как npm пакет установлен. У него на маке, например, есть папка вот эта глобальная, которой он хранит свой state. Ну вот эти JonL файлики. Я, например, часто мне лень вгонять в контекст, хоть говорят ценен свежий контекст кода и прочее, но мне как-то прикольно в этом одном треде решать прямо секцию

[04:32:00] вопросов. Мне было бы прикольно такое, может, кто-то уже знает MCP или какую-то репку, но мне что-то не попалось, чтобы был такой некий менеджер вот этих сессий, ему можно задать имя, там можно посмотреть статистику input outputs, можно subject задать, description такой смесь UЯ такой, ээ, количество там, не знаю, токенов, входящих вот как У, как ты с Сашей показывал, у тебя там только это код код что-то там сказал, да, сам или это кто, кстати, посчитал у тебя эти токены кэш и прочее, или как ты посчитал? Ну, Клод посчитал по по этим по по логам. Ну, он пиздун обычно. Ну нет, в данном случ��е нет. Да, ну, ну я всё равно, короче, я аппарат люблю им. Ну вот прикольно было бы такую репку. Ну вот у меня, например, 250 сессий. Из них на самом деле это где-то 7080 я бы оставил открытыми под какую-то таску. Вот я открыл сейчас репу, я там, короче, початился, там потратил 20.000 токенов, потому что с абогентами попросил там что-то решать. Потом через 3-4 дня, когда мне надо, я бы зашёл. Например, у меня есть там тременements, э, код improvements, там типа какие-то даже есть там что там. Сейчас посмотрим прифлек. Вот вот смотри, вот смотри, Денис рассказывал о том, что он, короче, этот а меморинком делает всё. Не, не, не промери Банка, а он рассказывал о том, как он оптимизировал размер контекста в оркестраторе, да, чтобы этот контекст он не засирался тем, что делают агенты. Вот. То есть, по сути, понимаешь, он он как бы каждому агенту он даёт свой

[04:34:00] контекст, который там его, значит, засирает тем, ровно тем, что ему надо. Вот. Да. То есть он ограниченный, он инкапсулированный и всё хорошо. Вот. Э, значит, соответственно, у оркестратора, значит, тоже, э, контекст ровно тот, который ему нужен, и больше ничего. Вот. И, ну, практически все агентские, мультиагентские системы, которые я видел, вот, ну, которые именно работают на на связь нескольких агентов, да, вот они работают именно так. Вот, то есть они не пытаются как бы всю историю всех сообщений держать как бы в одной. Ну, то есть представляешь, если мы, допустим, начнём там попарно говорить вот сейчас, да, вот это будет ээ абсолютно непродуктивноя. Ну, как бы мы мы перестанем понимать, кто что говорит и о чём вообще речь. Вот. То есть таким образом мы просто делим аэ делим разговор агентов на вот разные треды, да, вот и в рамках этих тредов они прекрасно там коммуницируют. Вот. То есть разделяй власт - это как бы, ну, этому принципу уже, я не знаю, тысячи лет. Вот. А, ну я, ну, то есть мой запрос, наверное, я его неправильно не ну не не до конца понятно выразил. Мне бы хотелось инструмент. У меня вот есть а-э, объясню на примере, чтобы было понятно, в чём история. Вот э Андрей, когда сказал, вот он зацепил у меня эту идею. Вот вот эти репки, которые Андрей там чекает. Вот у меня, например, есть э репка Bitча, есть пару три-четыре человека или пять обращались ко мне за какими-то вопросами, консультациями. Раньше бы это у меня заняло 4-5 часов. Сейчас я это дела�� за 20-50 минут. И какой-то им дал, ну, там знакомым, друзьям какие-то, да, и а потом они через неделю-две придут, а я этот тред хочу открыть. Удобно, как таску, типа. И мне вот иногда удобно было бы

[04:36:00] менеджериться этими код-сессиями, чтобы у меня была UIка. Я вот делаю код Resм ID сессии, чтобы я её там синкаю, например, потом на сервак. С сервака запускаю с телефона, диктую voice боту. Он Да, ну я я просто говорю, что как бы тебе тебе внутренние рассуждения агентов, они не нужны ��афиг. Да не, это две разные, кстати, задачи. Извиняюсь, что я, получается, да, я имел в виду, есть observability -э формат, где я упоминал, что когда приту и прочее, это одна история. Это когда, не знаю, когда я запустил пять штук, и мне просто нужно успевать где-то им там. Ну, ну, хотя у тебя совсем другой подход, но может быть я бы я тоже не хочу сидеть смотреть за агентами, но просто я сейчас, когда запускаю троих, ну, там типа посматривать было бы полезно, потому что вовремя не остановил и там что-то, короче, пошло не так. Это одна value, а вторая вот сейчас я сказал, как менеджер сессии кодкода. Вот интересно, есть ли такая репка или будем делать самому. А где можно нейминг задать, где можно удобно резюм, где можно синкануть? Максим, по-моему, был на каком-то звонке, где я пытался донести идею. Правда, слишком не пользуешься Клавдией? Да я пользовался, мне она не нравится. Там Uйка чуть-чуть подтормаживает. Она там типа тупит, да? Ну, короче, она это notable, да, она мне и не нужна. Ну, в смысле, там вот как там оно есть, мне нужно как бы свой тайтл задать. Ну, типа, то есть это получается, да, мне свой SQ или что-нибудь надо прицепить. То есть просто м какие value вообще как бы, то есть вот нормальный порядок, условно говоря. К чему это? к эпике или к чему-то. Вот

[04:38:00] твоим лайфхаком. Ну и я тоже так пользуюсь, как ты, Денис, когда сабагент, там действительно достаточно чистый контекст ��стаётся. И вот эти треды, которые потом нужны через 5 дней, через 2 недели, например, Ring - у меня сломалось. Я там вчера общался с чуваком, они мне привезут. Кстати, всем рекомендую вообще молодцы. 3,2 года прошло, 2 года гарантии. Они мне, короче, новое вернут, потому что их кольцо заглючило. Отправили мне вчера, и я забэкапил все данные себе в постгрес. Я там отдал эту задачку активного времени минут 10 потратил пассивного часа и у меня всё там есть, короче, моих там 500 м данных, типа. П��том ещё я такой хочу в этот трет зайти, сказать: "А давай то же самое по Гормину сделаем, а давай ещё вот это. Ну, я это сделаю, когда вот мне там ещё что-нибудь нужно будет. И вот такие мне сессии прикольно было бы держать и вообще синкать между устройствами. Вот на такой бы инструмент хотелось. Может, кто-то такие репы видел. Тебе тебе скорее нужно, на самом деле, не всю сессию держать, а тебе нужно иметь возможность просто конструировать контекст правильный, потому что ты не будешь сещую просто просматривать. Нет, я согласен конструировать контекст правильный, но там как будто мозги они уже так нацелены. И вот прямо собрать опять контекст и вот вогнать. Ну то есть я, когда каждый последующий вопрос задаю, если я маленький задаю вопрос, ну который немного токенов, он очень хорошо всё понимает. А чтобы вот он как бы того состояния достиг, как будто это нето лень это вгонять в контекст и самому вспоминать. Не, ну ты это не должен делать вручную просто, понимаешь? Тебе надо сделать, ну, наверное, на эти на эти разговоры отдельные сделать какой-нибудь рак, да, вот и

[04:40:00] сделать, короче, qu engine, который будет по этому рагу тебе отвечать на твои вопросы. Вот ты, то есть, формировать контекст каждый тред по 100 или там 500 Кб его засовывать в этот в мбединге. Ну, например, ну вот то, что то, что ты описал, ну, прямо очень напоминает интерфейс клмкам, тот жечат GPT, да, потому что ээ каждая сессия а она отдельно хранится, он автоматически её, э, даёт ем название, а всё это сохраняется в истории, и ты можешь просто поискать и вернуться э ну к продолжению какого-то задания. То есть, по сути, нужно просто сделать автоматическое, ну, автоматическую нейминг к этим сессиям, да, они вот тут кто-то показывал, вот я уже потом был на втор��м или на третьем семинаре, кто-то написал чуть ли не во время семинара тузу, которая как раз так это я и написал. А, ну вот, вот, вот, ну, значит, надо просто брать этот м эту мдшку, да, помню, это МДшка, да, её самаризировать, придумывать, что в ней, название, какой-то индекс и всё. Вот. И и складывать в эту же папочку, только уже с названием и получится совершенно нормальная штука, по которой можно поискам искать и продолжать её тоже. Сначала, да, ну просто мне лень. Это реально там дожать это, ну, типа 15-40 часов, на самом деле. Там нюансиков много. Я ей дописал, она у меня в этот в постгрес сохраняется. А, и как бы юайку, но я там столько фично выдумывал, думаю, ну, типа, короче, даже просто вот, чтобы это вабо, ну, не доделать, как будто может всё готовое есть.

[04:42:00] Ну вот так вот я подумал. Ну да, я ей пользуюсь вот этой туй. Я просто делаю экспорт. У меня это поделено по типам аа типа промты и аутпуты отдельно либо всё вместе. Иногда прикольно. Представьте, берёте все ваши промты, и это ваш контекст за день. Что вы смогли сказать своими словами, чтобы вас лмка лучше поняла и вы лучше рефлексировали. И в целом она типа вот нашпут. У наспут что это? Месенджеры, голос и промты сейчас становятся вот у меня, например, и вот эти аураданные там. Что мы ещё производим? Мысли осталось только. Вот Рима, да. И вам в общем, что предлагаю тогда на спишусь, может быть, на звонке кто-то ещё. Скажите, Анатолий, э, Джон и Саше, если что вы хотите, какие взять себе домашки или не хоте? У меня У меня пока это самое у меня пока, блин, загрузка хватает. Ну вот как раз, может быть, если из этой загрузки можно чем-то поделиться. Так вот, как ты же сегодня и показывал м скрипты, которые вот делали. Ну мне, смотри, мне, короче, за выходные надо доделать этот, я как бы у нас сервис, короче, который э-э делает ACR на это самое на Cloudfare, да? То есть ему закачивают картинку, он делае�� ACR. Вот. Ээ, там есть одна проблема, что это, короче, веб ой, не веб, что говорю, этот мобильное приложение уходит в слип, и оно не успевает получить, короче, этот результат сиара. Вот, в общем, надо пере переделать на из

[04:44:00] просто сервиса на workflлоow. Вот. То есть вот мне это надо сделать. Вот. Угу. И как то есть это надо с этим разобраться ещё, как это в CLР работает. Вот не звонок. В смысле на следующую субботу, Денис? А мы слыш субботу. Ну я я могу, наверное, что показать, да, наверное. Я посмотрю, я подумаю. Супер. У меня тогда программа минимум три ситер, программа максимум observability или менеджер сессий код-кода. Угу. Вот. Ладно, тогда всем спасибо. Был радться. Интересно. Спасибо. В чате предлагаюписаться, да, кто что может сделать. Давай. Спасибо. Спасибо всем. Пока. Пока-пока.