[00:00:00] Давайте откроем какой-нибудь репозиторий. Вернее, даже не репозиторий, мы сделаем так. Мы сделаем, значит, вот, ээ, ну, что-нибудь такое. Давайте сделаем там projects. Вот. И здесьделаем демо. Демо. Так, демо. Вот так. Хорошо видно экран? Да, отлично видно. Ну хорошо. Вот я сразу пойду в терминал. Вот. То есть я что сделал? Я просто открыл, значит, ээ, ну, сде создал директорию. Вот. Ээ да, этот у меня Макос. Вот. Но, в принципе, это будет также, наверное, работать и и в винде, и там в Линксе. В Линуксе 100% будет также в винде. Наверное, так же. Так, значит, и что я делаю? Я стартую сразу вот такую штуку вот. И, а, ну, я не знаю, можно сделать, можно не делать. Ебаг, вот. И это, чтобы просто видеть, что он там про себя думает. Вот. Значит, ну и давайте скажем ему. И пусть он у нас это сделает. Так, да. Вот. И теперь, э, скажем так, push this to git hub demo rle А вот вот, значит, ну то, что он там будет показывать, нам не интересно, а вот здесь интересно. Вот. То есть он создал там, ну, ту-ду для себя какие-то пункты и начал их выполнять. Значит, просит разрешения на то, чтобы это делать. Я вам скажу, просто вот всегда это, короче, позволяет себе, ни в чём себе не отказывай. Вот. Э, интересно, что он создал здесь вот такую штуку, конфигурацию, значит, и он в ней просто разрешил себе использовать. Я на самом деле сделаю вот так вот. То есть вообще разрешил его всё. Вот. Так. Аха. Да. Давай. Я се даже делаю в глобальном сразу очень много команд позволяемо. Дадада. Да, да, абсолютно. Не, ну есть есть вещи, которые хотелось бы контролировать иногда. Вот. Да, блин, надо рестартовать его, что ли, конечно, чтобы он не переспрашивал. Так, комиш. Я, наверное, рестартую, может быть, или как? Ну, ну, нормально. Ладно. Значит, и дальше я сделаю такую интересную вещь. Create rulits. А DS list and put Вот так. Значит, что я хочу? А у нас есть возможность в гие, короче, ставить хуки на разные, значит, события. Вот чем я сейчас, собственно, и займусь. А так делаю, да? Да. Вперёд. А что мне это даст? Это мне даст следующую

[00:05:00] штуку. Значит, э я смогу а гит при возникновении определённых событий делать напоминание, то есть делать через проompт и injection напоминание к лоду, что следующим шагом будет нужно сделать такую-то штуку. Так, давайте посмотрим, что он тут наделал сразу. Так, ничего будет, если я уменьшу немножко шрифт. Нормально будет вот видно. Вот так вот. Да, нормально, Так, давайте посмотрим, что он тут сделал. Прими код qualitys. Вот он, короче, говорит, типа runлин тыры-пыры. Вот. То есть он он, в принципе, сразу понял, что, в общем, как бы, ну, надо тут делать. Вот CCD, вот всякая ерунда, месседжи. Вот. И так. Сейчас он с этим закончит, и мы ему скажем ещё кое-что. Так, а он закончил уже, да? Это что такое? Вот. Да. Значит, now create to print. [музыка] Git flow. Кстати, а почему Git Flow, а не там Git там GitHub Flow, то есть более он стабильный, потому что инкрементируются номерные версии этих там релизов и ходфиксов или просто это, ну, более, я не знаю, я, честно говоря, раньше про про GitHub Flow я не слышал. Вот поэтому я использую. Вот надо попробовать. Можно и так ещё можно сделать. А так сейчас они противоречат лучше Gitф. Я на самом деле больше люблю Gitф тоже на нём просто было интересно в целом. Так, значит, [музыка] старт аа черate [музыка] Так. То есть, что я хочу сделать? Я хочу, чтобы, короче, он сделал мне хуки на тфлоу такие, чтобы когда я, короче, стартую там, э, этот самый фичу, да, вот, он бы мне, э, эту, короче, по по этой фиче а втыкал, а, environment variable. Вот какой, пусть он сам решит. Вот в этоммент варибли было бы было бы, короче, значит, записано, что мы сейчас делаем, да? То есть какую фичу вообще мы находимся в гифлоу фиче сейчас, да? Вот. И потом на комиш он бы печатал это напоминание печатал вот чтобы он же сам видел это напоминание вот и реагировал на него, соответственно. То есть очень просто. Prompt injection. Угу. Кстати, посмотрим, что он в коде написал. Он в коде должен был ссылочки

[00:10:00] сделать. Вот он сделал ссылочки. Вот. То есть при коментку Крузтырыпыры. Вот. В общем, вот такую интересную штуку сделал. Вот. И вот эт�� на самом деле всё, что вот он здесь сделал, да, он он в принципе как бы он ориентировал это на реакцию на пром. Вот. Но это ничего не мешает сделать тоже на это самое на гитху. Вот. То есть я раньше делал на гитху. Так. Git for. Да. Давай всё разрешаем тебе. Come on, come on, come on. Так. То есть это вот такие вещи, которые на самом деле шаг за шагом они помогут ээ сделать так, чтобы он мог там работать, я не знаю, там, допустим, 10-15 минут просто исполняя какую-то задачу. Вот. То есть вы а дали ему команду и пошли там кофе пить. А он же постоянно спрашивает там, да, нет, вот это тебя или ты как бы через вебхуке это можешь обойти ещё раз. продолжить, не продолжить. Вот постоянно же он он меня спрашивает на самом деле баш команды, правильно? В основном. То есть основная масса - это баш команды. Вот давай посмотрим сейчас, чтобы убедиться в этом. Башкоманды сес ты можешь применить. А вот он спрашивает ещё permission бывает, да? Ну, типа на какую-то папку внешнюю только. деле запустить в это самое как бы в режиме, когда он не будет вообще ничего спрашивать. Вот. А это какой флаг или какой режим? Это там надо его стартануть с флагом специальным. Там вроде антропик сам говорит, что это прямо типа только в контейнерах без интернета стоит использовать, но я почему-то вижу последнее время, что все начали активно это использовать. Реально, что это чёрто неудобно, да. Прямо при старте клода ему надо типа там minсangerous, типа, да, я не вспомню название, но короче, да, вот Угу. Вот. Ну, давай уже. Ну, короче, вот он уже начал пош достаточно как бы долго работать на то, чтобы что-то там сделать. Вот так. Отлично. Значит, он он нам написал, куда это всё он написал. Так, он в клод написал, просто добавил какие-то дополнительные правила. Вот. Ага. Ага. Ну, хорошо, замеча��ельно. Значит, написал и написал. Так. Ага. Ну что, можно попробовать начать разрабатывать что-нибудь. Давайте придумаем задачку. А давайте сначала делаем этот самый push init. Оп. Вот так. тех, кто пользуется Д код по Telegram-группам и делать эти randм кофе. Смотри, это это, блин, это, конечно, хорошая идея, да. Вот. Но у меня, значит, у меня не настроен, значит, у меня нет ээпиаки для Телеграма. Вот. А я не знаю, насколько это долго займёт, что это деле, да. Ну, какую-нибудь гипотетическую давайте вместе прошмим, потому что, да, скрапить есть моменты. Нет, что никто не знает, как им пользоваться. Все пробуют разные вещи и у всех по-разному это получается. как пользоваться, не знают или кто? клодкодом. Ну, в смысле, я имею в виду, типа все разные стратегии используют. Стратегия, короче, смотри, значит, а для того, чтобы как бы научиться пользоваться код-кодом, не обязательно писать Telegramбот, да? Вот, ну как бы понятно. кофе-чаты делать, про то, что типа там будет 100 разных стратегий у всех и типа и все правильные, да,

[00:15:00] или все неправильные. Так момент, я отойду на секунду, я воды возьму. Ребят, а кто как MD? Он, собака, не очень-то хорошо чувствует. То есть ты ему пишешь правила клод MD, а он не всегда их фолет. Кто как привык его заставлять его юзать MD? Я вообще у меня есть код MD Global, есть на уровне проекта и на уровне local. В целом он их учитывает, но просто его как бы явно надо, наверное, какой-нибудь keyкиворд иметь там и как бы эво типа ну напоминать. Есть такие пром. можешь сделать через кастом этот через custм comm, чтобы он заходил его перечитывал и использовал. Вообще самом деле подебажить просто там же можно мод включить и просто посмотреть, что ему идёт, какие запросы то, может оно просто в промт почему-то что-то не попадает или он у тебя огромный, и поэтому он просто типа теряется. Поэтому типа если оно идёт в промто, он на него забивает, то это скорее уже проблема промпта, чем там типа Ну а дальше типа решение стандартное. Ты либо 10 раз ему про это напомнил, 10 раз повторил, либо там, я не знаю, поменял чуть-чуть структуру. деле очень да кто-то говорил, я пере перебил. Я просто хотел дополнить то, что в любом случае поте, то есть со временем контекст начинает деградировать и какие-то вещи из него вымываются. Ну то есть вы не можете всегда 100% это обеспечить рано или поздно он всё равно начнёт какую-то информацию оттуда терять. примеру, в других инструментах штука по поводу контекста, ребята, значит, с кодом такая штука. А значит, у него вот эти вот файлы, да? плот там и так далее. Вот они сделаны для того, чтобы контекст а-а как бы вашего энваремента он не терялся. Вот. То есть, да, контекст, допустим, задачи он может потеряться, но вот эта вот штука, значит, плюс вот то, что я сделал, например, environment variable, да, вот оно позволяет вам сохранять контекст и инжектить его в нужные моменты. То есть вот так. Дальше вы можете ещё, на самом деле, сделать так, чтобы у вас, а, значит, записывалась, например, текущая конверсация, записывась файл, вот, а, или там сделать его, значит, чтобы он опрашивал у вас по поводу, допустим, ваших требований. То есть он ведёт с вами диалог, опрашивает требования, потом вы говорите, да, и он это записывает всё это в файл, допустим, да, вот причём можно попросить его записать это, а в Давайте просто сделаем, что говорить. Так F may in a of значи, что такое to do ltical, да? Это означает, что, короче, ну, lлиistical - это, а, скажем так, статья в виде какого-то, значит, там списка. Вот. То есть у неё есть пункты. Вот. И если мы говорим ту-ду, то это автоматически, короче, к этим пунктам списка добавляет ээ ну чекбоксы, да. Ну чекбоксы в формате этого маркдауна. Вот. То есть он сделает просто вот квадратные скобочки с позволением туда воткнуть, что выполнено, да? Вот. Значит, а дальше, если мы попросим его работать с этим листиком в качестве задачки, вот, то он просто будет обновлять этот листикол вот на на выполненной задаче. То есть мы ему сразу говорим, что типа вот мы сейчас по сути будем обсуждать, э, ну, что-то, да, какие-то там, я не знаю, реклайменты. Вот. И дальше в этот листикл ты будешь втыкать, короче, то, что ты понял. Вот. и использовать это дальше, короче, в качестве, ну, по сути, плана вот работы. Такая вот простая идея. А он разве не делает это из коробки? А, он делает немножко по-другому. Вот. То есть здесь мы будем будем контролировать этот список. То есть не то, что он там себе придумал, да, а мы контролируем, по сути, мы ему говорим, что что именно там должно быть. Угу. О'кей. Хочу. Ну, так или иначе, еслидушка разрастётся до, допустим, 200.000 токенов, уже будет

[00:20:00] всё равно проблема. Согласен. Значит, ну, нужно, на самом деле, вы же не не ну в работе в как бы, когда сами сами девелопите без A и да. Вот вы же не делаете так, что, значит, вот сел там, значит, и просидел там неделю непрерывно, да, вот и сделал там весь апликейшн за за вот этот один присест. Я шучу, слушайте, ну, сейчас пишу один проект на 200.000 строчек кода примерно. Это высоконагруженный proxy для lm, но я пишу с курсором в режиме SSH сервера к основной тачки, поэтому получается почти клодкод. использую тудушек и так далее, но есть такая история, что в курсоре ограничен клод четвёртый на 120.000 контекста. У меня тудушка уже на 20.000. она как бы поджирает, какие базы проинтегрированы. А, да. там где развёрнуто. Ну есть режим Max Mode, где будешь платить дорого за токены, и тогда будет на 200 или Gemini будет там миллион в курсоре. Есть ещё подход, как Emory, там Active contex. Обычно тебе все 20.000 уже не нужны токенов. подходы к меморинку есть. Вот как у Клайна, например. Тут можно раз. сейчас я сейчас одну вещь расскажу, ребята. Блин, значит, а я я сейчас на код Макс, да. Вот подписки. То есть 200 долларов в месяц - это, на самом деле, для меня это, я бы сказал, что, ну, прямо дёшево. Дёшево, потому что, блин, почему дёшево, да? Потому что, значит, месяц назад, когда я, ну, да, наверное, месяц назад, когда я, короче, начал интенсивно работать с клодом, вот у меня там было, значит, зафиксированный рекорд, короче, в этом самом в Гитхабе, да, 200, ой, фу, 300 комитов в сутки. Вот, значит, и, ну, как бы, я был момент, когда я потратил что-то порядка 700, короче, долларов за месяц, да, вот на клод. И 200 долларов - это просто, блин, манна небесная для меня. Вот. То есть это реально ��чень сильно удешевило мне работу. Вот. То есть у меня было там до 50, короче, долларов в это самое за 8 часов сессию, да. Вот. А, ну как бы для если считать это, что типа вот в месяц, это, короче, дофига, да? Ну, то есть есть 50 долларов каждый день. Вот. Но если подумать, что мы, допустим, пытаемся заменить этим разработчика, вот, то, причём, значит, производительность этого разработчика такова будет, что это примерно как 50 ээ 50 людей, вот, либо один AI, вот, а то 1.500 - это просто даром. Вот это находишься, Александр, нет, понимаешь, если ты, допустим, находишься, я не знаю, находишься вот где ты находишься сейчас? Я в Турции нахожусь сейчас. находишься ты в Турции, да? Вот. И ты нашёл себе, я не знаю, там ты на это по контракту работаешь или сам работаешь. Как это вообще выглядит? да. Вот ты нашёл себе не один контракт, а 10, да? Вот. всех, потому что вот, то есть ты просто успеваешь, потому что за тебя, значит, AI работает как это самое, причём ты на десяти контрактах, да, на всех ты это самое Shin Star, потому что, блин, ты работаешь гораздо быстрее и лучше там всех остальных. Вот. Ну, это же классно. Да, да, по просто ничего, конечно. Не, ну я, собственно, и делаю, но, например, без меня эта система не совсем работает, и у меня не получается дать такие задачи, которые бы там условно в фоне крутились 30 там 60 минут. До сих пор совершаются ошибки, но я параллельно делаю там что-то в курсоре девостаки мне удобнее в код-коде. Код десктоп мне нравится своей самостоятельностью, но за счёт вот там, кстати, потом в конце бы поднял вопрос по поводу контекстного окна окна код декто и как у код-кода работает. У них, кстати, достаточно эффективно и вот этот автоматический компактин conversation прямо как мне очень хорошо он там помнит. В принципе, можно бесконечно так,

[00:25:00] да. Значит, так, мы создали это дело. Ага, хорошо. Вот теперь, значит, что мы сделаем? Ну, мы придумали задачку какую-то. Давайте что-нибудь с Legac, потому что это всё очень сияет. Только когда Legacy появляется, сияние очень блекнет. Legacy. Ну, ну, смотри, значит, Legacy надо было начинать, наверное, не здесь тогда. Значит, я знаю, например, один проект, э, называется Noberce. Вот это, по сути, это, значит, ну, веб-сайт там с бэкэндом, который, ну, я бы сказал, что как минимум внешний это очень близко к тому, что там делает Amazon или Ozоon. То есть это этой значит Mentil, значит, вебсайт, на котором можно создавать там свои типа магазины, да? Вот, ну, кастомер может создавать свои магазины. Вот. Плюс, значит, ну, основная как бы компания держатель этого, значит, там, ну, Инстанса, она может там тоже что-то своё продавать через это. Вот. А я бы не сказал, что извини, что перебиваю насчёт теста быстрого. Я на клоде, на курсоре там за 3 часа своего одного курса, неважно, там закрытый был курс у меня в канале, векторный а поиск. Ну сайтик сделали простенький, квадрант подняли, векторную модель подняли, а на виллме и, соответственно, нарезали чанками какой-то там Telegram-чат или сайт и пообщались с подписчиками. Меня заняло это вот реально совсем там восемь человек сидело в курсоре с дебагингом, с примерами 3 часа. это можно автоматизировать, сделать быстрее. Это было полгода назад, тогда был 3,7. Он много тупил и медленно работал. Не, я к тому, что это всё очень интересно, но как только проект разрастается или есть какой-то кусок, который уже был давно написан и его нельзя трогать, например, по какой-то из причин, то как бы вся эта фигня не работает. То есть с нуля оно прекрасно пишет, когда оно само пишет. Но и в целом как бы разработчики тоже быстро пишут с нуля. А вот когда я я бы тут добавил, понятная болячка. Например, в чатике м под капотом, ну, месяц назад её очень подробно разжёвывали. И у меня вот одна из тасок такая стоит, там 300к строк кода нужно в этом сасе пилить фичи гарантированно и чтобы не поломало. Это как бы амбициозная, сложная задача, но даже проект на самом деле с нуля. Вот как это будет работать со всеми приками, руми прочим, а без ну относительно автономно зациклено. Это как бы решается, но когда что-то маленькое, тоже интересно. на 247.000 рочек кода. Я как прокси использую в большой компании в России сейчас. И курсор под был подрублен к этому проекту. Я хотел добавить одну из фичей Guard Rails, там собственный Guardrail с собственными настройками. Пока безуспешно, естественно. Ну не может он обойти и прямо найти, где же находится это место инпута. Возможно, конечно, я не такой разработчик. Мне просто сначала надо потратить время и архитектуру типа сделать проекты. Архитектура, тесты, документация, разбиение по таскам, как можно более гранулярно их давать. Всё, как в обычной софтерной разработке. То есть у вас не получист, да? У вас не получится, ну, естественно, у вас не получится набросить на большой проект ЛМКО и ожидать, что она там сразу справится. Ребята, получится, давайте, давайте так. Небольшой проект большим проектом будет работать прекрасно, так же как и с с небольшим проектом. подходы. Вот, значит, смотрите, какая проблема. Значит, ээ, давайте, наверное, просто возьмём, а, предложите мне просто проект, который вы хотите, ну, как бы, допустим, саппортить. Вот предложите мне какой-то такой проект. я бы взял какой-нибудь интересный, а а по поводу фич. Можем ли мы, вернее, такое сделать, взять какую-то GitHub репку и сделать там новую фичу? Вот. И вот давай, давай. Да, вот, вот я спрашиваю, короче, какой проект мы будем использовать. Как давайте слово передадим. А, да, привет. Я по предыдущей теме хотел прокомментировать. У меня репозитории почти на миллион строк. А, примерно, да, где-то миллион, наверное, строк. Это большая часть legси. Очень хорошо работает практика, когда прямо в clд ты прописываешь, что все именно вот квиркс, а, все странности и непонятности он заносит как документацию. И примерно через месяц-два он с тобой на пару уже нашёл все те места, где он спотыкается. То есть ему не нужно те вещи, которые он

[00:30:00] предполагает по умолчанию, то, что он то, что является для него ожидаемым, он не заносит. А вот те места, где он может накосячить, заносятся как раз-таки в кдмд тоже. Это ему очень сильно помогает. ломается, а поиск. А у тебя код - это не текст. И там используются же тулы и классический греп или файт. и заход в файлы. И вот здесь пока ломается, наверное, с поиском. Я неправильно сказал. Наверное, и на 2 млн строк будет отлично. Но когда ты говоришь и пытаешься детерминировать какую-то фичу и найти её просто где она, то есть ты как бы и сам не можешь, ты не знаешь, как её разработчики назвали, и курсор или неважно какая тула, агент не может её найти. И, соответственно, даже если он вот эти все странности будет записывать, просто тут по факту классический resarch. Если ты найдёшь место, где она находится, но не проблема будет собрать контекст. Если он не может какие-то вещи изначально найти, если он об этом спотыкается, то его в первый раз можно отправить искать ультрасин, ком он находит, а во второй раз он сам себе напишет напоминание, что я искал там-то, там-то, там-то, не нашёл. Вот здесь файлы лежат, для меня это неожиданно. И в следующий раз надо поискать ещё вот в таком вот формате папок. такие вещи лучше всего искать с помощью рав, да? Вот. И не просто рак, да? А тут есть такой интересный способ. Смотрите, обычно обычно, э, как бы рагольтются очень, так сказать, директли, да? То есть, а, мы пыта мы сначала индексируем контент контент, как он есть, да? Ну, может быть, чанками. Вот. А затем мы индексируем, значит, мы берём этот самое, мы берём рин от запроса, вот, и мы мачим этот бединг с эмбедингами, которые у нас, значит, ну, проиндексированного контента. Вот это ��аботает, но это работает не всегда. Вот то, что я выработал, значит, на самом деле интересная вещь. Значит, мы индексируем, а, во-первых, не чанками, да? То есть, а мы индексируем целыми документами. Вот это раз. Дальше мы в базе не сохраняем контент этих документов, мы сохраняем локацию этих документов, да? Вот это два. Вот. И мы эмбединг берём не от самого документа, да? А сначала мы этот документ обрабатываем лмом. Мы говорим, какие вопросы вот, э, на какие вопросы данный документ отвечает. Вот, parent document extraction называется. И в формате C была под капотом это выигрышный был самый первый. Илья Рис выиграл таким подходом. случае вы когда, значит, спросите типа: "А как мне имплементировать такую-то фигню?" Да, вот вы будете легко находить ээ значит ну или что у нас имплементирует такую-то фигню. Вот. А вы легко будете находить, значит, ну код или документацию, которая на это о��вечает. Вот. И больше того, значит, если вы сделаете, значит, трак, который там типа, а вот я хочу имплементировать такую-то штуку, значит, как бы мне её имплементировать? Вот он покажет вам, как это делается. А ещё очень полезно, значит, на самом деле начинать не, то есть не не использовать просто, а не использовать просто как бы код, да, в репозитории. Вот если вы получили откуда-то репозиторий, который, значит, вам неизвестен, значит, ну, плот, соответственно, тоже там с ним никак не работал. Вот начать очень хорошо с того, чтобы сгенерировать для него документацию полную. Вот. То есть сказать, что давай-ка мне сгенерируй, короче, а архитектуру техchnical архитектура документацию вот по, значит, этому репозиторию вот со всеми там деталями. Вот. А почему это интересно? Почему это помогает? Потому что документация, значит, в виде там, ну, каких-то там, э, то есть код, код он всегда более вербоз, да. Вот документация она более компактна, намного более компактна, а особенно что касается, допустим, там, ну, диаграмм. Вот. То есть если мы используем, допустим, план QML или Mermate диаграммы, вот которые просто показывает нам, что происходит в коде, например, да, вот это является очень компактным выражением вот этого вот происходящего в коде. Вот. И это означает, что если клод вместо того, чтобы каждый раз лезть там в ваши файлы там и искать что-то, он будет лезть в документацию, он будет тратить гораздо меньше токенов. Вот. То есть это будет гораздо более оптимальная работа. Вот. А просто. Это сравнимо с тем, как вот у вас пришёл новый человек на проект. Если у вас документация хорошо организована, то есть в условном там конфлюенсе где-нибудь, она иерархическая и вполне

[00:35:00] понятная, то, ну, можно ожидать, что человек с большей вероятностью быстрее решит первую поставленную задачу, чем если вы его просто кидаете в проект с кодом. пункту, потому что, значит, ээ мы понимаем, что документация нужна. Вот. И, значит, э-э, больше того, мы, допустим, хотим добавить какой-то новый фир в проект. Вот что мы делаем. А-а, мы просим кд, а, сделать нам дизайн этой фичей. Вот, пользуясь, короче, остальной документацией, значит, в качестве там, ну, понимания того, как работает система, вот мы просим встроить новую фичу. Вот. Ну, даже, может быть, для начала просим его не не встроить новую фичу, да, а сделать resarch о том, как встроить эту новую фичу, да, чтобы он посмотрел а документацию, вот сказал вообще это feasible или нет, и почему, если это не feible, то почему не feible, да? Вот. И как можно сделать так, чтобы это было feible? Вот. То есть он вам сделает этот отчётик, потом вы, значит, ну там, допустим, допустим, он сказал, что это возможная возможна фича. Вот вы говорите: "Ну хорошо, давай задизайним её тогда". Вот. Значит, он делает опять же, значит, отдельный документ или там, может быть, набор док��ментов дизайном этой фичи. Вот. Потом вы просите его, значит, ээ опять же ну, в идеале это делать автоматически, да. Вот. А значит, автоматически, я просто почему говорю про автоматически, я сейчас занимаюсь разработкой как раз, значит, тулы, которая, а, ну, сможет просто по требованиям вести весь процесс разработки. Вот, значит, ээ то вот как мы сейчас делаем, это, конечно, будет не настолько автоматизировано. Вот. Ну, тем не менее, значит, а мы можем мы може�� по архитектуре построенной вот дальше, значит, попросить Клод сделать нам таски в это самое в GitHub прожекте, да, вот и, ну, то есть создать GitHub Project, сделать им таски и потом просто выполняйте эти таски, понимаете? И он просто будет у вас идти по этим таскам. Вы, ну, если он будет останавливаться, будете спрашивать, значит, если ты закончил, то переходи к следующей таске, да? Вот. Причём не просто переходи к следующей таске, а используй канбан процесс. Вот для перехода к таске. Канбан триггерит сразу у него способ выбора этой этой задачи новой, да? Вот. То есть он будет выбирать аlнфрут вот всегда. И то есть, грубо говоря, а максимально лёгкая фича, которая даёт максимально полезный результат. Вот. Ну и по приоритетам, по по зависимостям тоже будет как бы ориентироваться. Вот насчёт документации можно немножко добавить. Всё-таки есть пример. И вот то, что ты сейчас рассказал, оно прям, ну, наверное, мне сейчас даёт инфы, как сделать лучше. А есть Telegramбод у меня свой личный на 20.000 пользователей, занимается транскрибацией. Когда-то я его сделал, а просто вайп-кодингом. Я даже не смотрел, что там делает LLM. Там 2,5 2700 строчек кодо в монофайле. И оно работает. Как-то работает с постгрисом. Всё как бы прекрасно. Там пользователи могут кидать файлы на транскрибацию до 2 ГБ. Большие, разные видео, аудио, неважно, там кружочки. В группах он работает. Много функционала у этого бота. И я как бы заболтаю идею тоже взять, сделать доку, разбить его на сервис адекватно, чтобы фичи дальшестраивать новые. И в общем сейчас положил, какая интересная ситуация. У меня всё произошло, ну, то есть разбилась на файлике, была создана архитектура, документация, а в докер контейнер всё собрал и запустил. После запуска я начинаю тестить функции, а они все замоканные. Я иду, грубо говоря, в логику. Он создал костяк, а логику ни одной из рабочей функции вот того большого кода он не создал. Скорее всего, я пропустил вот этот этап. О мне Валерий, а в чём вопрос? Или чем хочешь поделиться? На комментаски был бы прописан как раз вот, как ты говоришь на задание. Спасибо. Давайте будем в рамках модератора, чтобы все по очереди заговорили. Максиму, потом Ди на очереди. Ага. Ну я просто хочу сказать, что в таких случаях, то есть надо писать тесты желательно, которые не только будут тестировать юниттесты. И если мы говорим о более-менее системах побольше, я вообще как бы против юнит-тестов, а лучше писать сразу интеграционные, которые проверит сразу несколько слоёв вашей системы. И в этом случае вы хотя бы интеграционные тесты должны глазами проверить. А, и в этом случае у вас

[00:40:00] будет больше убеждённости в том, что система работает end to end. То есть таких ситуации элементарно тестами можно избегать. Вроде обязательно. Вот интеркие сложные вещи, но это холивар. Это холивар. Мы сейчас далеко уйдём. Смотрите, что я сейчас, короче, говорю ему. Да. создавать правила, чтобы всегда использовать и оплать solid kiss, dry clean code. Значит, напишем, что это принципы вот на любую активность, да? Вот. То есть что такое solid, да? Ну, это там, значит, single responsibility, там тыры-пыры и так далее, of substitution и так далее. Kiss keep it simple stupid. Вот. Drive, don't repeat yourself. плин-код, значит, соответственно, тоже там это самосвязано с тем, как это будет выглядеть. Вот. То есть, когда мы это ему говорим, он, значит, начинает сразу не писать всё в один файл, да, а пытается дизайнить это всё по разным файлам. Вот, значит, пытается разбивать это на классы. Это это если мы говорим просто вот мы кодим и больше ничего, мы не делаем архитектуру, да. Вот. Но на самом деле это вот этот вот эти принципы, они будут полезны даже при разработке архитектуры A, да. Вот. То есть он просто будет следовать им, и он сделает вам очень хорошую архитектуру. Вот создадим это правило. Там ещё ди п��днимал руку. Ага. короткий вопрос. Может быть нам построить так, что покажешь, может быть, свой проект, Алекс, а который работает и там всё уже внедрено, а мы таки ошаем с этого и такие: "А как ты это сделал? Как то что посмотреть это очень долго будет". показывать не буду. Я собираюсь продавать этот сервис. Извините. Нет. Ну, в смысле, готовый. Я не говорю код показатели rules твой, а просто типа как оно работает уже подкапо. Ну или всё р��вно не проходит, да? показать а демопроект, который я делал на самом деле. То есть я его сделал для это самое для кастомера или одного, да? Вот, значит, который ОR ОР, который Да, ну показать. сейчас быстренько. Мы всё равно тут больше трендим. Я потому что если оно само работает, оно сейчас быстро накодит нам. Мы тут пообщаемся пока. А потом в конце нужно посмотреть готовый проект, чтобы, ну, типа скипнуть. Надо, надо решить, надо решить, что мы, что мы делаем. Телетон, всем известная, самая популярная библиотека Телеграма. Токены все дам, всё, что надо. Ну, имею в виду эти ключи. Идея там вот, э, у него много возможностей, но нету транскрибации. То есть у премиум аккаунта он может транскрибировать и скачать телетон и сделать него фичу транскрибация. Там даже есть иш, он уже описан. Вот это немножко как бы может быть и не простой задачей с одной стороны, потому что телетон либо не маленькая, ну то есть вот. Но это к обсуждению. Вот в принципе я скинул в чатик ссылки, они уже улетели, не улетели. Сейчас посмотрю. телеге. В телеге. Не в Google мите. В телеге. какая-то идея там. Да, слушай, лучше лучше это в телегу скидывать, потому что, блин, здесь оно исчезнет после до Да, я я я скинул э- Саш телегу и сейчас ещё раз тебя попну. Вот хайлайт сделал, чтобы Так. Бля, где же это у меня? Где же это вот это вот? Да, самый самый низ. Да, тут уже у нас этот пошёл, да, в самом низу. Вот я процитировал спичу вот эту, да, кликну. Так, добавить transcription скелетон. А где остаток? О'кей. всем понятная. И там Дмитрий хотел что-то спросить. Я ничего себе. Давай попробуем. Почему бы нет? Дмитрий, сло��о тебе тоже. Ты хотел что-то спросить или случайно? мюте, сори. Я хотел просто спросить такой чисто на опс опыту. Там в клод в клодкоде есть такая фича, типа можно свои MCP сервера, то есть можно делать clotд mcp serve и давать ему системный промт условно какой-то. И там можно, например, создать кастомные MCP сервера, типа там, не знаю, продукт-менеджер, там документатор, вот, вот такая вся штука. Насколько вообще, может, кто-то пробовал или вот Алекс пробовал, э, насколько это хуже лучше, чем просто инструкции ему давать? Ло MD или где где-либо ещё?

[00:45:00] экспорить всякие штуки, но такое как бы не слышал, звучит норм, но это реально надо, чтобы кто-то потестил. Я просто знаю, что Алекс точно пробовал такой, что я видел это на одном завидел, вроде сейчас. Который Алекс, во-первых. знаю, как к тебе обращаться. Ну, ты, ну, Саша можешь назвать. О'кей. что ещё раз можешь повторить? Вопрос что в клодкоде можно типа свои MCP-сервера стартовать клодом CP. Да. знаю, за с кастомным CP-сервер, там документатор, не знаю, продакт-менеджер и так далее. Насколько это хуже лучше, чем просто кастомные инструкции? Это лучше, потому что это работает автономно. Вот. То есть у тебя опять же вот у тебя проблема, допустим, потеря контекста, да? Вот если у тебя что-то работает автономно, то контекст не теряется. Вот. И это большой плюс. А с с в клодом в качестве MCP-сервера, значит, я наткнулся, на самом деле на одну проблему, вот, которую я, значит, ну, нашёл, как обойти. Вот. А проблема заключается в том, что, значит, если у тебя вот эти вот, ну, агенты, MCP сервера, которые, значит, ты сделал с помощью, значит, клода, да, запущенного, как MCP сервер, они используют, а, какие-то, короче, тоже MCP сервера. начинается проблема, короче, с с пермишенами. Вот. И, ну, у меня не получилось, короче, разризовывать эту проблему как-то простым способом. Я в результате, короче, сделал так, что я написал просто свой ээ свой код на Тайпскрипте, вот, то есть свой свой MCP сервер на Тайпскрипте, вот, который внутри себя просто использует клод через клод SDK. Угу. запускает бинарник, он просто использует API. Окей, я понял. Ну, я там скинул, кстати, скинул в чат какой-то есть композер ещё. Это как докер коз, только вот cl. Там типа можно вот так вот их стартовать друг на друга тоже и права им настраивать. Можно через это ещё попробовать, наверное. Но, ну но да, я понял. О'кей, прикольно. смотри, значит, у нас есть этот, я склонировал этот телетон, да? Вот. Давай, значит, начнём с того, чтобы, э, так. Прит мо может он GitHub is прочтёт, которая там есть, и сказать ему. Ну да, момент, начнём с другого немножко. Это рано слишком. Так documentation. Можно я пока влезу с ответом на вопрос? Да, легко, конечно. Есть очень простой способ. Как можно это сделать? Можно клода заставить себя самого запускать. То есть у него есть прямой запрет на инстанцию себя. Но если делать симлинк на его же копию, и если ему достаточно хорошо объяснить, что его контекст является ценностью, поэтому для всех операций он должен вызывать миньонов, то, что у меня в промте, то тогда это будет работать примерно как то же самое через API. Вот смотрите, значит, я прошу вас сделать архитектурную документацию на телес. Вот. А значит, давайте так ещё вот детальную документацию, техническую документацию, короче, на Ton. Вот. И прошу его, короче, вот вот этим вот do notes hitate using creating multiple files. Я по сути его, значит, ему говорю, чтобы он создавал не один файл документации, а много. Это мне позволяет ээ ну как бы легко навигироваться между ними, да, вот и ну то есть как как вручную, так и к воду самому. Вот не забивать контекст большим количеством а символов. Вот. А значит, использовать РМЕЙ для диаграмм, я ему говорю, потому что иначе он начнёт использовать адские диаграммы, то как бы ни фига не хорошо. Вот. И что я ещё хочу от него, чтобы он это сделал, да? А прийдт так

[00:50:00] утер. Сори, я вот перебью просто сейчас важно. Пока мы тут смотри, вот ты сейчас типа склонировал репозиторий и предыдущий чат не удалил. У тебя контекст остался ещё предыдущего чата. Да, контекст он пойдёт в этот промт твой, потому что там типа, ну, вся предыдущая история, она всегда идёт типа следующий пром. Это норм, типа, то есть это же по идее ухудшает, типа немного. проблем, вообще нет проблем. А, значит, тут есть такая интересная штука. Значит, ну, это есть тест такой needleк, да, знаете такое? синтетически почти не работает на сложном рининге. Есть улима, которая говорит об обратном. штука, что, короче, ну наиболее как это, как у людей, да, наиболее хорошо запоминается, значит первые и последние слова, да, середины выпадают. Вот, значит, ну, влм, конечно, это не немножко не так, но тем не менее, значит, вот то, что я сейчас пишу- это последнее, и оно запоминается. Вот, то есть мы просто игнорируем этот факт, что у нас, да, есть что-то там ещё. Вот просто мы не хотим менеджить дополнительно прим при этом лимитов ты всё равно по сути больше используешь, но типа видимо хватает подписка жир, согласен. отношении своих предыдущих решений, поэтому запускать новую сессию проще, чем пытаться его переобдить в каком-то мнении. это если это как бы вот реально проблема вдруг, ну, возникает такая вот. Так, говорит, Алекс хотел что-то спросить потом. Да нет, не спросить, хотел поправить. Вот кто-то предлагал использовать Clot как, э, сайтпроцесс через параллельный запуск, но а 13 июня антропик добавили субагентов и а cloud сам себя запускает в в поднстанцах и как раз-таки анализирует, ну, анализирует файлы, может делать параллельно несколько задач и не обязательно мучиться с запуском вторых инстансов и так далее, но как MCP для прописывания роли это ещё не работает. Да, интересно было просто именно вопрос в том, что типа как его заставить себя запускать в том плане, что если ты ему в инструкциях это указал, типа каждый раз после там окончания фичи обнови документацию. Вот вопрос типа насколько лучше работает там просто ему сказать, чтобы ээ вон в инструкциях это нашёл и не забыл или вот типа у тебя будет MC CP-сервер, который будет ему напоминать всё время про это. Ну, короче, это вопрос, да, организация. Так, я думаю, что субагенты норм тема, да? Максиму слово там. Да, я просто пару вещей хотел сказать насчёт вот нидл бенчмарков. всегда смотрите, сколько там нидлов в этом бенчмарке, потому что та же самая лама четвёртая, она отлично проходит тесты на single needle benchmark, но её контекстом в 10 млн практически невозможно пользоваться. То есть смотрите на бичмарки, которые именно multiple needle используют или более sophisticated вещи по работе с контекстом, которые заставляют нейронку связывать разные места из этого контекста. К примеру, тот же самый Fiction Life benchmark, несмотря на все его проблемы, а их там хватает, в том числе и технической составляющей этого бичмарка, он довольно неплохо отражает то, насколько модель способна связывать разрозненные факты в пределах большого контекста между собой. Вот. А, же сторону советуюма посмотреть. Он как раз эту же проблему поднимает. Эффективность контекста там вообще 32 до максимум 8.000 токенов даже у больших миллионах моделей. тестируют они последние модели на это дело. А потому что, насколько я последний раз проверял, где-то вот недели две назад, у них там что-то, по-��оему, они не тестировали последние вышедшие модели, поэтому довольно сложно по нему ориентироваться в текущем состоянии. Слушайте, а он большой вообще этот теле? Сколько он будет? БН, сейчас гляну. Так, он 14 Мб. Нихера себе. Он, блин, долго будет с этим работать. А ещё просто хотел одну штуку дополнить насчёт контекста и насчёт вот того, что все вот сказал, хорошая штука, то, что, а, нейронка остаётся байzed в отношении предыдущего контекста. Я так иногд�� некоторые задачи реализую по методике скользящего контекста. Я вообще никогда не стартую новый чат, потому что если у меня задача составлена из нескольких подряд идущих блоков, которые явным

[00:55:00] образом связаны между собой, каждый следующий блок использует контекст с предыдущего. Я вообще новый чат не стартую, но это не к cloud коду относится, с ним, скорее всего, так не получится. А вот в курсоре есть скользящее окно, а и в некоторых других тоже вот агентах есть скользящее окно контекста, когда он просто постепенно его подъедает начало контекста, а конец контекста всегда вам остаётся доступным. И вот есть у вас, например, какая-нибудь задача, которая, грубо говоря, у вас есть там, не знаю, нужно структуру базы сделать, потом набор репозиториев по работе с изменениями в этой базе, потом набор сервисов, потом нужно апе поменять, потом нужно на фронтде что-то сделать. И каждый из этих этапов так или иначе опирается на предыдущий. То есть у них там на ��ранице перехода между этими слоями согласовываются контракты. И вам, по идее, не нужно, когда вы разрабатываете фронт, уже помнить о том, что у вас там в базе происходит. Вам нужно помнить о контракте, заключённом с предыдущим слоем. И вот в этом случае вообще можно новый чат не стартовать, просто прямо всё это делать, но не всегда. двойной экейп? А это кому вопрос? в первую очередь наверно тебе. В clдкод можно нажать дважды escape и перейти к предыдущему сообщению, как я клодкодом, к сожалению, не так много пользуюсь, поэтому нет, про эту фичу я не знал. Но вот в курсоре там есть эти, как их, чекпоинты, можно к ним возвращаться. А в данном случае переход он что обозначает? Ты переходишь к сообщению для, то есть ты им заменяешь текущий контекст или это что-то аналог чекпоинтов? Депно версии и веб-версии просто диту сообщения делаешь. То есть ты отгоняешь назад контекст. ну вот, кстати, да, чекпоинт по сути. Погоди, а ты отгоняешь контекст и ты файлы ролбк делаешь или чисто по контексту двигаешься? контекст нет такого понятия, как как отогнать контекст назад. Он всё время типа все эти лмки, они стейтless, типа, у них нет стейта. У тебя весь контекст - это всегда всё, что у тебя есть. Поэтому ты просто к следующему сообщению типа пошлёшь ему другой месседж и всё. У него типа у него у него нет стейта, типа, ты каждый раз ему посылаешь всю всю вообще. Нет, почему ты можешь то есть у тебя же история сообщений на клиенте хранится конкретно. Вот сейчас она хранится в кд-коде, и ты всегда можешь последних два-три, да, сообщений просто оттуда удалить. И апи, все апишки, которые он посылает, они стоит у вас. Понятно. Поэтому понятно. Да, конечно. Ну, потому что вот в том же курсоре там есть возможность даже ветвить чата. То есть ты хочешь, если, например, вернуться по истории чата там на 10 сообщений назад, сделать ветку чата и продолжить имплементировать какую-нибудь фичу вообще в отдельном чате. Вот. То есть такое возможно. И фактически это навигация назад по контексту с очисткой контекста до того места, до которого тебе нужно. пиши, как себя ведут в этот момент. он же может присанивать. Извини, не послышу. Можно ещё раз? Ну, сама это сама моделька у них теперь есть кши, по-моему, автоматически его менеджерот. Поэтому у тебя может кшенуться что-нибудь с прошлого сеанса. Нет, оно ремоется. сама вообще решает, что кашировать теперь, что не кашировать. Там более интересные механизмы, на самом деле, каширования используется. То есть, э, ну, как минимум, там она будет проверять длину пришедшего сообщения. И плюс ко всему там же этот кэш, э, работает именно так, что, короче, нормально всё будет. А суть в том, что он просто либо сбросит кэш, если ты ему вот так вот откат по контексту сделаешь, либо он будет использовать, конечно, ровно до того момента, где вот ты этот откат сделал, потому что там довольно хитрые алгоритмы определение того, что же, собственно, в кэш, э, точнее, а какое количество кэша использовать для последующего запроса. Они, к сожалению, не открыты. Вот их где нигде не это их не описывают, но просто чисто инженерно, если предполагать, ну, наверное, это было бы очевидным реализация контекста, кширование контекста именно таким образом, чтобы они хотя бы его примерно сравнивали и смотрели, можно ли какую-то часть кошировать или нет и использовать в последующих запросах. Вот почитать там всё, ну, как бы там деталей нет, но было бы описано. Ну да, да, я скорее всего её читал, то, что там они там оценивают первые несколько тысяч токенов, что-то такое. Ну да, о'кей. просто документация официальная?

[01:00:00] По что документацию я читала, статью, возможно, не видел. ста��ья, либо Ну, короче, где где этот механизм у них вроде так примерно описан. Можно примерно покинуть. на кафе. Ну, смотрите, как замечательно он у нас генерирует документацию. Он перешёл уже, то есть он overview, вот перешёл в cor вот вот такой вот замечательный фолдер с документацией. Вот диаграммки рисует. Вот. И, значит, ну, как я уже сказал, да, вот смотрите, значит, на самом деле много же вот, э- здесь вот как бы описано в этой диаграмме, да, вот, то есть архитект��рные слои описаны. Вот и размер текста этой диаграммы, он ничтожный. Вот. То есть это гораздо меньше того, что, э, значит, нужно было бы просмотреть, если просто, э, строить понимание из текста. Вот. То есть такое-то достаточно компактное представление, значит, того, как система построена. Вот дизайн принципа, например. Вот. Значит, так, блин, какого хрена она у меня всегда сюда пойдёт? Вот дизайн, в принципе, у нас какие это, значит, ну, тут какие-то примеры. Значит, опять же, какая-то география артищ им impact. Замечательно, значит, вот. Но она она ещё долго будет генерировать, я так понимаю. Давайте кор посмотрим. Вот так. Значит, compная [музыка] диаграммка, которая показывает просто, значит, отношения между компонентами. Вот какой-то там, значит, ээ ключевая фича в виде класса. Вот. Значит, это уже пошёл диаграмма, по сути, да? Диаграмма. Вот тоже очень компактно всё. Вот. То есть это эта штука, она хороша для самого ЛМА, чтобы он не был вынужден там перелопачивать кучу файлов для понимания того, как ему что-то сделать. То есть он может посмотреть документацию и сказать вот. А вопросик небольшой. Але, я правильно понимаю, что мы это как бы ему постоянно в контекст передаём и отжираем кусок контекста, да? постоянно в контекст. Вот мы, значит, смотрите, а когда мы будем, а просить его сделать анализ имплементации, ну, то есть анализ, скажем так, возможности существования фичи, который мы попросим, да, вот он просмотрит нужную документацию, значит, выдаст нам репорт. Вот репорт этот, он будет, по сути, а, я бы сказал, референсами на, аэ, фрагменты документации, да. Вот. Дальше, значит, используя вот этот вот репорт и, значит, ну, мы попросим сделать его архитектуру этой пичи, да. Вот, значит, в архитектуре, по сути, мы, значит, ну, при создании архитектуры он будет пользоваться во�� этим референсом, да, то есть репортом своим, вот, и будет пользоваться документацией, на которую тот ссылается этот референс. Вот, значит, что ему позволит, короче, опять же, не перелопачивать всё подряд, вот, а, э, делать, я бы сказал, точечные запросы, да. Вот, значит, ээ то есть мы ему выстраиваем, по сути, мы его ведём за руку, да, чтобы он шёл по по оптимальному процессу. Так, что такое? Не, это я понял, да, но только получается, если он что-то прочитал, о�� как бы контек занял этим. А я к тому, что если он что-то прочёл, например, из документации, то кусок этох этого этих токенов контекст уже занят эти этой информацией до тех пор, пока он не очистит контекст, насколько я понимаю, как это работает. Или я не прав? Ну, грубо говоря, чем больше мы документаци у тебя с у тебя слайден Window, да? Вот. То есть это как бы м у тебя слайдин. понимаю, что альтернатива это то, что он сам подожит что-то там копаться, и это будет долго и ещё, может быть, менее эффективно, но в целом как бы документация не будет долго, да? То есть долго долго здесь означает, что просто он а долго работает над какой-то конкретной задачей. Вот. А нас вот эта документация будет разрастаться, тем, а меньше по контексту мы будем, ну, грубо говоря, ограничены, насколько я это всё понимаю. Я спрашиваю, потому что у меня уже есть

[01:05:00] такая проблема на большом проекте. И после вопрос её решить, если тут, кажется, Максим может ответить на него. тут навигатор нужен. То есть, грубо говоря, перед тем, как тебе нужно какую-то фичу реализовывать, тебе нужно какой-то топдаун навигацию провести по документации, а чтобы найти в ней конкретные ветки. которые относится к твоей задаче. То есть сама документация должна выстроена быть иерархически. Её не нужно целиком каждый раз пихать в контекст. Нужно пихать только те куски, которые непосредственно к задаче относятся. Но тут возможно, что понадобится чуть больше возни в том плане, что тебе сначала нужно собрать релевантную документацию, а потом уже начинать с ней чат, который непосредственно будет фичу имплементировать. Но это вот больших проектов. Тут возни больше, да. Ну, я к тому, что это получается, мы уже переходим в ручной режим, по сути, и ити это можно на самом деле, да? То есть это просто вот такая как бы задача. Её в больших проектах ещ�� удобнее решать, точнее, нет, не удобнее, а приходится решать вручную, просто потому что большие проекты - это, как правило, довольно ответственные и старые системы. И я им просто пока не доверяю такие вещи в автомате агентам решать. Но чисто в теории сама задача вот подобного подхода, она довольно рутинная и видится автоматизируемой. Просто я пока что этому не очень доверяю. Так, у меня продолжает генерироваться документация. Вот, ну вот классовая иерархия. Замечательно. Значит, опять же, всё очень компактно. Есть имена классов, вот, есть методы в них. То есть всегда система может найти, то есть, ну, всегда может найти, а, что-то в коде просто по вот этим вот именам. Причём она может использовать, ээ, ну, в данном случае там, допустим, Regular Expression или там какой-то поиск вообще. Вот, что будет очень быстро работать, даже даже если мы не используем этот векторную мазу. Так. А, ребят, а вот ещё вопросик. А есть какая-то вот готовая векторная база в DMCP или что-то такого, чтобы можно было проиндексировать Legacy? Есть есть, но все векторные базы, которые я видел, значит, у них в основном а работа идёт через ээ чанки, во-первых, да, вот э то есть чанки они, наверное, хороши, допустим, я не знаю, там проиндексировать тебе а какие-то там свод законов или ещё какую-нибудь там legгал документацию, да, ещё что-нибудь такое вот. Но это не очень хорошо работает, когда у тебя, а, нужно проиндексировать, ��опустим, код base. Вот. Да. А, а так их несколько. Я я на самом деле начинал, значит, делать ээ свой ээ м свой engн такой, значит, который, значит, там, ну, будет хранить именно э эти э ссылки на файлы. Вот, и, э, делать запросы, значит, ну, вернее, как сказать, делать делать индексацию по вопросам. Вот. А, но потом, значит, я просто подумал, что какого хрена я буду делать это сейчас, когда я смогу это сделать потом просто автоматически. Вот, в общем, как это проблема курицы и яйца была у меня. Вот так вот он у меня выполняет эти кто-то слышал променc там и инвест был вроде неплохой, ребята крутые. Это типа проект специализируемый специализируется на больших кодовых базах Legacy для рефакторинга и что-то такое вот. Может кто-то из Тут скорее интересен опыт. слышал о нём. Ну типа не непонятно. Они вроде да специализируются на том, что они там все эти кодовые базы могут успешно хорошо индексировать, но непонятно, как они это дела. ссылочку на это дело в телеге. Угу. Ага. Я положил. описывает, это очень похоже на то, что сделано было Винсрфе и это была их корфича. Они об этом даже на диплёнинг рассказывают. Ну, как вы видите, работает так себе, если честно. курсор его обогна Винтёр, ну, я правда постоянно не сижу в винтёрпе, но типа я

[01:10:00] на нём побыл месяц очек, а потом курсор выкатил от агентов достаточно самостоятельных. Это было декабрь, январь, там январь, наверное, и как-то в принципе то же самое. А вот год самый агентный. Да, я делал, значит, винсрф, вот, потом с него ушёл на курсор. Вот. Потом, значит, я в курсоре начал запускать клод и потом избавился от курсора. Угу. Тут у нас и аидеры есть. Вот Сергей, я знаю, этот евангелист Аидора был. Интересно, но это по факту Аидор - это вот такой улучшенный код-код. Хотя они до сих пор у них фишки берут там такие как что там репозитори, разные подходы. Может Сергей тут подсветит. Кстати, одна из причин, на самом деле, почему я с с клодом остался, значит, это потому что, а, клод, во-первых, ну, то есть он сам работает, ну, может работать как MCP сервер. Это раз. Вот, то есть можно просто на на основе него строить вот агентские системы. Это это первое, да. Вот. И второе, то, что у него есть API, вот, ну, SDK его, да, на котором тоже можно строить, значит, что-то вот такое. То есть, по сути, мы мы берём, э, такую рассуждающую, значит, ну, как бы резание модель вот клода, да, вот которая способна работать долго и которая просто из коробки имеет значит возможность работать с кучей пузов. Вот. И просто используем её, понимаешь? Вот. Ну, как бы вот для меня это оказалось ээ ну просто как это самое hlyгrail. Вот. Потому что, значит, ну, это удобно, просто тупо удобно. Вот, то есть мне не нужно решать самому кучу задач. Ну, Аде он был чем прикольным? Сейчас я Алексу отвечу, что он был один из первых. И даже чуваки, которые вот там на презентации cloud кода, они говорили, что мы тоже вдохновились Аидоро. Он, грубо говоря, дедушка вот этих всех агентов ээ терминальных. А, ну просто проблема в том, что там мужик пилит один, хоть из коммьюнити, и он, ну, не успевает уже. Короче, понятно, что антропик релизт крутые фичистрее и качественнее, просто потому что у них денег больше и команда больше. Поэтому я тоже последнее время пришёл. А, но, кстати, хочу отметить, что кучу фишек, которые в Айдер заложены, вот, например, там у них тоже есть крыширование в виде базёнки, которую он там контекст кширует постоянно. И тебе не надо вот этой всей хренотой, перегрузкой контекста заниматься. И репозиторий, дерево репозитория он неплохо выстраивает. Вот этих фишек до сих пор качественно нигде не сделали, хотя идеи уже больше года, так-то в це��ом. Угу. Спасибо. Передаём Максиму. Ага. Я про Эйдер сначала добавлю. Там забавно то, что я слежу за Эдербенчмарком у них в дискорде пасусь когда особенно новые модели выходят. И да, вот вот этот прессинг на чувака в плане того, что он один довольно сильно сказывается. Буквально до того доходит, что вот сейчас вот отри вышло, он в канале спрашивает: "Ребята, а нет у кого-нибудь денег просто, чтобы тесты прогнать?" То есть там тест стоит, я так понимаю, порядка 100 100 баксов для того, чтобы вот полный тест сют прогнать AOR benchmark для O3 Pro. И чувак просто элементарно, у него даже денег на это нету. То есть вот это проблема open онрсного тула, который поддерживается одним человеком. собственно, просто хотел сказать про огмент. Я вот его последние где-то 2 недели тестирую. Аа до этого у меня был на него заход месяца два назад, но на то время он был, конечно, гораздо слабее. И плюс ко всему модели ещё пока не те были. ��н там под капотом то ли Sunet 37 использовал, то ли GPT какой-то из вариантов. А ни то, ни другое на тот момент не было достаточно хорошим для работы на больших проектах. Но вот в последнем релизе они они не не раскрывают, какие модели у них там используются. Судя по всему, у них там микс моделей, сам ты поменять её не можешь. Вот. Но у них вроде сейчас базовая модель SN 4 и работает она вполне неплохо именно на больших проектах. Это не отменяет того, что вам всё равно нужна документация, но вот их контекст engine, а то, как они именно индексируют кодовую базу, очень хорошо. Мне прямо очень нравится. То есть вот именно по тому, как он находит, что где в проекте лежит и релевантные, скажем, это

[01:15:00] куски релевантные задачи, куски он находит прямо очень хорошо. И у него ещё дополнительные фишки сейчас вот появились. То, что он, например, тасклист составляет мелочь. А приятно, тем не менее, он перед задачей составляет тасклист, который ты сам можешь отредактировать именно в визуальном режиме. У него прямо UI для этого есть. Вот. И можешь на ходу вот эти таски для него менять. Ну, оно как бы мелочь, да, но приятно. Ну, вот контекст Engн - это самое его большое преимущество. А по контекстнену, собственно, в современных вот этих утилитах у меня очень большие претензии к рагу и вообще к Грпу, когда ты, я не знаю, в языке по типу тайпскрипта или сишарпа смотришь, как агент пытается грепом что-то найти, это прямо боль. Это это вообще что это такое? Почему у тебя language server протокол есть, у тебя есть статический анализ кода, у нас есть abstract syntax 3 в языке. Ты почему грпом это ищешь? Вот не знаю, как омен сделали, но у них явно это хорошо работает. По поводу, да, по поводу абстракт Synx 3 есть проблема, что у тебя, то есть либо надо грузить какую-то дополнительную библиотеку для этого, да, всё такое, то есть, ну, как бы этого может либо не быть, либо, короче, у меня у меня другой, на самом деле, вопрос к этому всему, да, то есть вот существует langage сервера, то есть сервер протокол, есть такая штука, вот, через которую работает, например, тот же курсор. Вот. Да. Вот. И почему не использовать это для редактирования больших файлов? Вот это я не понимаю вообще. есть элементарно вот фак. Я постоянно привожу такой пример. Тебе нужно отрефакторить класс. Предположим, у тебя есть файл, в нём лежит класс. Естественно, на этот класс много референсов в других файлах, там, в других классах, и тебе нужно переименовать этот класс. Это к чему обычно сводится? как в хорошей Д. Ты просто там зажимаешь какое-нибудь сочетание клавиш, переименовываешь сам класс, у тебя автоматом переименовывается файл этого класса и все референсы на этот класс переименовываются в других файлах. Для LLM эта задача практически всегда фейлится, ну, просто в силу механизмов работы, да. Это элементарная операция с точки зрения вот к��ассических рефакторингов, к которым мы привыкли, классический ХД. Почему они не сделали этого как набор инструментов, которые выставляются для самой неронки? Загадка. Ну, возможно, сделают. Всё, вот ты на звонке. Отчасти, по-моему, твоя идея предыдущего звонка была. Это целый звонок про это можно делать отдельный. Они просто хотят, чтобы мы тратили больше токенов. абсолютно другая парадигма просто должна быть. Я этим вопросом уже где-то полгода занимаюсь полноценно. А код всё пыхтит. Вот это настоящий вайп-кодинг на компашку. Ну вот он ещё, короче, он пропустил вот диаграммы, значит, и API вот два фолдера. Вот. И может, да, internal тоже пропустил. Сейчас он проверит. Вот так и пройдут, продолжит, контекст заканчивается. 19% остаться. Насрать. Ну это вроде как не проблема. Вот вот этот компактинг, он достаточно хорош. Меня, кстати, ээ подниму пр�� контекст. Вот анроopic, вот этот код десктоп, прямо очень мне нравится его самостоятельность, когда слм коман, но там вот вот эта их фича, где он на 200.000 токенов, условно говоря, там 10-30 шагов и сломался, он как будто даже посообразительнее код-кода, но я опус везде использую. Вот. А вот ээ код код, вот он в принципе сам контекст экономнее расходует и компактн, в принципе, позволяет, ну, хорошо, как бы, не знаю, нечто, многие всё равно советуют типа останавливать его, когда там процентов 50 или там 40 остаётся и делать слшкомпакт руками, типа, потому что иначе типа там у кого-то бывали случаи, когда он во время компактинга у него заканчивался контекст, он такой: "Ой, О, он вроде типа по умолчанию, когда 5% остаётся или что-то такое типа компактное. Я с таким сталкивался, кстати. Да, он реально сказал мне: "Ой, один раз я, блин, ну как так-то?" Да. Ну вот как раз в этом случае удобно перейти к предыдущему сообщению и попросить сохранить контекст.

[01:20:00] Ну да, я знаю, что такое есть. Ой, там очень много ходкеев появляется постоянно. Я вот в шоке был, когда узнал, что туда скриншоты можно вставлять через Ctrl V. это я первое, что попробовал под виндой. Оно, естественно, не заработало. Вот. Ээ, увы, да. Ну, потому что винде там же он через VSL, а его можно только использовать. Родной версии под винду нету. А, ну vs там свои приколы, да. Клод через ВСЛ только в новинке. нету родного клиента, как ни странно. Что я не знаю, почему, казалось бы, же там на терите наверняка всё написали. И ещё интересный, короче, вот скажу вам такой лайфхак, значит, для, ну, для клода, да, вообще для разработки, собственно говоря, агентской. Значит, если вы сразу же, короче, при старте проекта настроите, значит, CBC CCD, вот на гитхабе, да, вот, то, значит, каждый раз, когда вы, э, то есть, по сути, что вы сможете сделать, да, вы сможете, э, контролировать качество кода, вот каждый раз, когда вы, короче, делаете пуш в репозитории. Вот. И этим будет заниматься, короче, в правильном энрименте будет заниматься GitHub, а не вы сами. Вот единственная проблема в этом такая, что, короче, у меня, например, вчера закончились лимиты на CCD, вот, ну, они каждый день, по-моему, обновляются. Вот. Но тем не менее у меня был эпизод, когда закончились лимиты, короче, я не смог посмотреть результаты, короче, билда. Вот. Можно вопрос? Он за вас выполняет GitHub за вас выполняет все тесты. Вот так. он полу А чем это лучше, чем при комиху? Тем, что оно там выполняется или как? Есть, смотри, значит, у меня, например, Mac, да, допустим, я делаю там Windows приложение, да, вот Windows приложение на Макее как-то протестировать, наверное, проблематично. Вот. А GitHub он позволяет просто запустить Windows envirймете это делать. А всё. А вот извините, сейчас моргает постоянно. У меня такой баг тоже есть. Вот сейча�� вот всё моргает. Меня это дико бесит. И нашли решение или так оно и будет моргать всю жизнь? просто наплевал на это дело. Ну новую новую вкладку открыт, оно убьётся, как бы. Но потом она через там 20 минут опять будет так прыгать. Это жесть просто. Это это, мне кажется, это ну проблема того, как работает с консолью. Ну то есть это просто надо, я не знаю, они должны просто зафиксить, если им не всё равно. Оно от терминала зависит, как я понимаю, вс-коде просто менее функциональный терминал. Если взять какой-то другой, то может получше быть. норм. Так, можно ссылку скинуть? Попробую. It для Мака, для виндыва, по-моему, вполне себе работает. И ещё есть парочка хороших терминалов, модных, симпатичных. Все, кстати, настроили себе в терминале, там можно в клодкоде сделать, чтобы он звоночек делал, когда ждёт экшен от вас. Типа там есть специальная настройка, типа, для каждого терминала она своя, но он умее�� автоматом интегрироваться, типа он будет звонить, когда ему что-то от вас нужно, чтобы пожалуйста, там нене не в смысле он прямо в терминале будет звоночек. То есть там, например, он сай точно интегрируется с обычным терминалом, вроде тоже с bскодовским. Я хз, но я 2 настроил. Там надо просто, короче, лучше загуглить просто. Там он прямо типа клод код знает, как с конкретными терминалами интегрироваться. наверное, есть. надо его открыть и там всего надо его открыть сшконфиг и что-то там дальше выбрать. посмотрю. А то просто в это в стандартный это в стандартном маске там же есть прямо специальный символ, который пык вот это вот в консоли вызывает, когда ошибка какая-нибудь происходит. Вот. общем, да, Cl/fig, и там есть. И вот у меня стоит 2bell будет звонить. штука в курсоре тоже включаю voice кодинг какой плагин юзаете или как там супервиспер какой-нибудь или там подключаете кс-коду какой-то кстати хороший вопрос я только хочу

[01:25:00] знать годовую подписку education взял там за 60 баксов анлимитный он очень хороший в плане того, что можно сделать, например, диктовать, и он обрабатывает тем же кодом выставить стпроцесинг, там, например, я диктую идею, он мне мермей на выходе даёт или я диктую идею и с какими-то кастом промтами она типа структурируется чуть получше. Очень удобно. Но вот на это тоже в этот в Telegram, да, я прямо на видос кину, где фаундер показывает все эти кейсы автомейшные свои. А вот я ещё видел в на каких-то видосиках. Ну, это было вскольз. И сейчас просто вспомнил, можно это найти. Ну вот, может на звонке пользовался в де чем-то. Я где-то полгода назад завайпкодил себе такую штуку. Вот. То есть у нет, ну, она просто виспром под капотом пользуется, потом на выходе либо вот структурированный текст выдаёт, либо там, не знаю, просто почищенный без структуры. А сейчас вот иногда, когда приходится наварименте, где эта штука недоступна, так как она у меня в домашней сети расположено, Visperflow под виндо использую. Она, к сожалению, вот таких возможностей, как супервисper, не даёт, но супервисперу нету под виндой. Ну, ну как это? Ну, короче, вот нас опять обделяют. Короче, я я с клод-кодом каждый раз изучаю английский. Вот что это типа в консоли шлепин. Я таких английских слов вообще ни разу бы, во-первых, не использовал, во-вторых, не знал, что это за процесс, но я уже перевёл. Но это жесть он там. кстати? Мне тоже было интересно. таскает. Я вот эти его словечки постоянные, да, как-то типа хихиканье, типа. Я думаю, что ты, чувак, я там с матами ему косяки наговорил. Кстати, я не знаю, пр��вда или нет, но я слышал, что для этих словечек и для кратких описаний в терминале, в названии в шапке используется Хайку четвёртый. Может быть так. Ну, я надеюсь, он уже скоро закончит. ��ак такой такой ещё есть вопрос. ээ психологический ээ э короче проблемы есть вот с вайпдингом. Ты типа что-то его просишь сделать и тебе нечего делать, хочется. не знаю, что-то делать и всё, потерял внимание. Надо потом опять с рилсиков переключаться на работу. Как? Что что, как либо параллельные процессы делаете, либо вообще как что делать, чтобы внимание не терять? параллельные ��роцессы какие-то, то есть тоже что-то там, ну, то есть в другом в другом терминале там что-то ещё, например, делаю, да. Вот. А тоже с кодом. Второй вариант, значит, ну, как бы смотри, а если ты пошёл спать, вот и утром потом продолжишь, ну, как бы всё равно проблема остаётся. тут просто это постоянно происходит, типа, значит, что типа, ну, я отходил, напомни мне, что мы делали сейчас. Да не, не то, что ты забываешь, это скорее типа как именно сосредото, ну, типа фокус теряется. Я к этому типа, когда ты сидишь, код пишешь там постоянно, то ты как бы в фокусе сидишь там, типа, что-то делаешь, мозг работает, а тут он там говорит: "Всё, я пошёл на 15 минут работать". Ты такой: "Ну, пойду шортики посмотрю рилски там, а потом уже и всё". И забыл. Ну видишь, вот я в телеге же писал в группе, короче, что я сейчас, значит, я делаю вот систему, которая просто девелопит ну софтве. Вот, то есть вот она весь процесс вот состоянни, она, короче, вот весь выполняет. Вот. То есть идея такова, чтобы ээ ну пришёл пришёл какой-то бизнесмен, да, у него есть какая-то интересная идея, вот, и чтобы ему не нужно было там находить команду, да, то есть он он в этом может быть вообще там ноль, да, абсолютный. Вот. аэ он решает какую-то бизнес-проблему, чтобы он просто мог, значит, ээ сделать себе аккаунт в системе, вот, и начать просто, значит, ээ диктовать системе, что он хочет. Вот. И всё. И чтобы система всё это выполняла, чтобы она всё это имплементировала, там, деплоила там по по максимуму там и так далее. Вот. А у него фокус будет на бизнес проблема. У него не будет фокуса на код. Ему этот код вообще а 100 лет не нужен. Но он не

[01:30:00] знает, что это такое. Вот. И, ну, как мне кажется, вот такой вариант он, ну, наиболее правильный, как бы, ну, в плане работы с вот этим хозяйством, да? То есть, э, у меня есть, на самом деле, моральная дилемма, вот такая очень интересная моральная дилемма. Значит, я как-то проводил исследования, что, ну, в США, а, порядка 8 млн, короче, софтовоинженеров. Вот. А в Индии что-то порядка 15 млн. Вот. Ну и, короче, по всему миру там где-то, наверное, до 50 где-то миллионов. Вот. И то, что я сейчас делаю, значит, оно, в принципе, может ну, очень существенную часть этих людей э лишить работы. Вот. И ладно бы оно только лишило работы. Значит, ээ, как бы в Великую депрессию, значит, в США, значит, вот это в Детройте было уволено миллион, э, людей, которые работали на конвейере, собирали машины. Вот это было 100 лет назад, и регион буквально там, я не знаю, лет пть, может, 10 назад только-только начал прокашливаться после этого всего. Вот. То есть реально, короче, если такое количество высокооплачиемых людей потеряют работу, вот это может не просто там обрушить экономику региона, это может, в принципе, повлиять на всю страну. Вот. И вот ��акая у меня моральная дема. ли это только из-за тебя произойдёт, но можно этому поспособствовать. Ну да. Так как, ну какая разница, не ты так другой это сделает. Это ж все оди вот это вот это меня заставляет продолжать, понимаешь? Ну дилемма остаётся. полгода ещё лишних поживу живём. Максиму слово Максим поднимал руку. будешь запускать проект, тогда скажи, чтобы мы готовились там. литкод, чтобы начали прорешивать. выложу в группу, что короче как это использовать обязательно. Угу. искать, где ферму гусей открывать, потому что ликод-то уже будет не нужен. Я думаю, не ферму гусей, просто каждый станет отдельным предпринимателем. Вот. То есть он просто придумает идею, которую будет пилить. Вот пилить и А Так, а давайте по поводу этого, по поводу отвлечения. Есть такая проблема, да? А я её сейчас решаю тем, что появились фоновые агенты, и у меня работа стала больше похожей на мою обычную работу, как вот как я техледом работаю. Вот. И у меня сейчас работа именно с АИ, она стала больше похожей на работу, как вот я обычно с людьми работаю. То есть у меня есть, а, грубо говоря, в течение дня фаза, там есть фаза планирования задач. То есть я просто планирую определённый набор задач, раскидываю по людям. Вот. А потом занимаюсь своими задачами, потом спустя некоторое время проверяю статус того, что получилось, аа ��ам в виде каких-то полуреквестов или ещё каким-то образом с людьми созваниваюсь и даю фидбэк. И дальше этот протез вот так вот просто по циклу повторяется. А в случае с фоновыми агентами, вот у нас очень похожее сейчас происходит. Фактически из своего бэклога задач, которые у вас есть для проекта, вы выбираете те, которые подходят фоном фоновым агентам, перекидываете на них, а дальше спустя, э, некоторое время э к ним возвращаетесь. Но вот пока они там этим занимаются, вы работ��ете над своими задачами, планируете следующие задачи и так далее. То есть у вас вот этот вот, э, э, момент отвлечения становится более коротким, потому что вы в режиме конвейера сначала проходитесь по бэклогу, назначаете задачи агентам, а агентов много, сразу в параллели работает, а описываете задачи для них и так далее. Это занимает всё ваше время. Вы не можете отвлечься в этот момент. Вот. Потом у вас есть большой блок отвлечения. а-а до того, как агенты не закончат работ��ть, вы занимаетесь либо своими задачами, либо планируете следующие задачи, там согласовываете какие-то требования. Вот. А после того, как а ката закончили работать, вы возвращаетесь и начинаете работать с плерквестами, которые они сделали. И это тоже такой конвеерный процесс, и вы тоже не можете отвлечься в этот момент, потому что это сфокусированная работа по проверке полуреквестов и по предоставлению фидбэка по каждому из полуреквестов. Вот. И это как раз-таки по��воляет сильно сократить вот эти моменты отвлечения, потому что у вас несколько задач в параллель выполняются. А, ну а если параллельности не получается, это по многим причинам может происходить. Излишняя связанность проекта, недостаточно широкий проект, а невозможно выделить задачи, которые не друг другу не стали бы мешать потом в итоге их выполнения. А в этих случаях,

[01:35:00] если у вас условный курсор ушёл на 15 минут работать, а открываете ещё один чат и в нём планируете следующую задачу, вот и или следующий несколько задач. Но в любом случае вот эти вот моменты отвлечения, а в этом при таком подходе они минимизируются не полностью, да. И на самом деле, я бы даже сказал, что они нужны, потому что когнитивная нагрузка сейчас на нас возрастает, а мы делаем больше задач. Аа но при этом когнитивная нагрузка, я бы не сказал, что уж прямо сильно уменьшилась. Она скорее возросла, потому что задач стала больше, а мы переходим на больший уровень абстракции, и нам нужно о более аб��трактных вещах думать. А поэтому, может быть, не так уж и плохо отвлекаться. Ну я, например, уже перегружаюсь, когда в несколько потоков делаю. Я понимаю, что мозги больше архитектурно, но уже мозги не вывозят. Держать только контекстов. Да, это ещё, видимо, работает, если у тебя типа вот этот агент фоновый, он не спрашивает разрешение на какие-то действия по дейст Да. Да. Они вообще в облаке работ, смотря как ты настроил. Типа клодкод-то может типа что угодно там спрашивать, е��ли ты им разрешение не дал. зависит от мастерства, потому что почему я контекст держу? Потому что мои агенты косячат. А почему косячат? Потому что я вот, наверное, плохо даю задачи или какие-то, ну, не куски выбираю слишком большие. А вот, например, у у Александра раз запустил и всё сделали. Потом только прийти посмотреть. Кстати, а у меня вопрос: а кто-нибудь вот этим Openчным облачным агентом пользуется и можно ли также сделать? не пользовался, но пользовался, короче, этот чувак, короче, из партнёрской компании. Вот я наблюдал, как это мы, короче, вместе ездили в этот на веб-саммит Канады. Вот и я наблюдал, как он это делает. И это на самом деле Ата Израиль. Вот. Потому что, значит, там, а, когда работает агент, он не может использовать какие-то там внешние тулды, например, он не может там, допустим, прогуглить что-то, да? Вот, то есть он не может не может, например, там решить ээ ну какую-то проблему, да, которая у него возникла по ходу, вот путём того, чтобы найти, я не знаю, там решение в интернете. Вот. То есть он не может этого сделать. Вот, э, квот это может сделать. То есть ему можно сказать, что, ну, как бы не заморачивайся, короче, просто поищи решение, да, если если вдруг там встретишь проблему, и он это будет делать. делает сам. Нет, только если попросишь его типа поискать. Ну, а понимаешь, это это всё решается правилами, да, правилами и автоматизацией. Вот. То есть, если ты, если ты, короче, как сказать, заврапишь, короче, этот клод в какую-то автоматизацию, вот, то ты можешь ему автоматически там, ну, то есть он тебе репортит эту проблему, да, вот, а внешний, короче, к нему агент, он говорит: "Ну, проблема, тогда поищи решение, что ты, понимаешь, там паришься". Вот. То есть вместо вместо они будет А же это можно также клода где-нибудь на удалённом серваке развернуть и в контейнере и всё будет то же самое. То он будет иметь в разы больше именно. Я знаю, как делают. Да, это работает. И вот я сейчас делаю, я говорю, полностью автоматизированную вот эту вот систему в кодексе ещё. Я пробовал просто у нас у нас на работе просто чат GPT team, поэтому все эти фичиматом включаются. Я его пробовал на нескольких репозиториях, но это, конечно, ад полный, потому что т��па э ты его что-то просишь там. Я настроил ему контейнер, то есть он же всё в контейнере делает, я ему настроил установку, там всё это сделал, попросил его там типа какую-то штуку сделать, он её сделал. Я говорю: "А теперь там типа поправь". И он начал заново спинить контейнеры. Я такой: "Зачем?" Типа, то есть на каждое следующее сообщение он почему-то начал спинить новый контейнер. Ну я не понимаю, что как как они что. То есть если там ваншот, то он прямо типа может, конечно, что-то круто сделать и пиар создаст тебе, и всё. Но если что-то надо потом поправить, то до свидания. Я прямо очень много по этому поводу могу рассказать, но это на сечас затянется. Ну просто нас время есть. У нас у нас ещё документация сделана и время есть. В кодекс, кстати, лучше CLI просто использовать. Если вы хотите прямо open работать, он в CLI лучше работает, как агент. звонке. Я думаю, он он нам ещё на 3 часа может про фоновых легентов рассказывать.

[01:40:00] Короче, просто эта специфика такая, то что они пока что предназначены для тех задач, которые вы не хотите делать, э, в отвлекая собственный фокус внимания. Ну, грубо говоря, какой-нибудь тест поправить, а там где-нибудь надпись заменить, а мелкий рефакторинг сделать, э, документацию обновить, вот такие вот вещи, которые на которые вот прямо вообще не хочетс�� активное внимание тратить. Вот их можно фоновым агентам отдавать. А плюс этого подхода в том, что они где-то там в облаке работают, независимо от вас. А, и при этом они решают вот именно такие вещи, которые вам иначе пришлось бы просто ждать генерации токенов вот в в том же самом в том же самом код-коде. Предположим, вам нуж нужно в рамках какого-то рефакторинга провести простые изменения, но в большом количестве файлов. Не хочется тратить на это своё активное внимание. Или вот, как человек говорил о том, что приходится переключаться на условный Reals или TikTok, а вот это вот как раз можно фоновому агенту отдать. Пускай он там где-нибудь в облаке запустит контейнер, э, с нужным совтом, сам пройдётся по проекту, сам вот этот вот мелкий рефактор рынк осуществит. У него это может занять там пусть 20 минут, пусть хоть час у него это займёт. Главное, что это не занимает моё активное внимание на текущий момент. Я просто потом приду и проверю полрекст. Вот. А настройки, связанные с интернетом, они настраиваются. То есть в большинстве сейчас вот этих фоновых агентов появились настройки работы с интернетом. То окружение, которое он поднимает в контейнере, тоже можно настраивать. То есть необходимый софт аэ либо поставить изначально, либо просто делать какой-то снапшот вот этого контейнера, который он сконфигурирует для себя, и в последующем его использовать. Но надо понимать, что он именно statтless. И каждый раз, когда вы какую-то новую задачу ставите или изменяете существующую, ну да, он будет заново этот контейнер инстанцировать и заново поднимать вот это решение. Но это специфика его работы такая. Пока что очень простые задачи можно давать, но вот как раз хорошо то, что это всё работает независимо от вас и в параллель. Вот. То есть профит в этом определённо есть. И при этом вы сейчас уже можете начать заботиться о том, чтобы покрывать свои проекты хорошо тестами. А потому что вот именно по новому агенту тесты прямо обязательно нужны. А потому что после того, как он сделает какую-то часть работы, единственный вариант ему убедиться в том, что он всё сделал правильно- это прогнать тесты по проекту. Вот. И они это успешно делают, то есть прогоняют тесты, фиксят потом появившиеся проблемы и вам уже дают кодовый пореквест. А и если сейчас начать думать именно в плане построения своего проекта, так чтобы с ним могли работать фоновые проекты, фоновые агенты, в ��удущем для вас будет только плюс, потому что кажется, что эта технология будет только развиваться в будущем. То есть это сейчас им можно давать относительно простые задачи, а в будущем явно это будут задачи побольше, посерьёзнее. Вот. И вы будете превращаться именно больше такого менеджера. Аа потому что какие ещё бенефиты во всём этом? Вы не обязательно за компом должны этим заниматься. То есть вы вполне вот в случае а с каким-нибудь GitHub Copilot Coding Agent, который тоже в облаке работает, вы можете ему прямо в самом гитхабе набросать задач и там же ему их назначить и там же проверитьреквест и там же мерть, а и там же там, не знаю, какой-нибудь ему фидбэк дать для того, чтобы он продолжил работать. И всё это не обязательно делать, находясь за компьютером. То есть вы вполне можете там, не знаю, вот у меня в прошлую субботу была долгая тренировка, там трёхчасовая, и я порядка десяти вот этих мелких задач просто решил на ходу. А как раз-таки, работая чисто с гитхабом, просто туда писал задачи, агент делал, я потом проверял полреквест, мерл в основную ветку и так далее. Вот. Так что эта штука интересная, ей, по крайней мере, стоит попробовать заняться. Но, как я говорю, очень простые задачи, и они все практически эти агенты пока что нестабильно работают. Вот на это тоже стоит закладываться. А от Гугла аналогичный продукт Джус Джулис, да, тоже пробовал и Joles, и Коeкс, и гитхабовский. Вот этот вот агент тоже пробовал. И вот сейчас огментовский тоже пробую. А, аропика же у Анторопика есть гайд, как его в облаке не пробовал. Не, не пробовал, но там две

[01:45:00] проблемы. Первая проблема то, что это только по токенам оплата. Вы не можете его привязать к своей подписке, да, и это уже прямо заградительные меры довольно серьёзные. И второе, то что у него в этот, ну, вы за GitHub Actions, то есть он же как он поднимает контейнер на основе GitHub Actions, работая, и вы ещё за GitHub Actions будете дополнительно платить за те ресурсы, которые они вот в процессе работы потребили. Ну, то есть можно, работает. Ну, просто здесь это подороже чуть будет. Ну да. тебе больше всех понравился из этих решений? GitHub Copilot Coding Agent. Он самыйчастый и самый костоюзируемый и лучше всего интегрирован в сам GitHub. Ну, как бы кто бы мог подумать. Вот. И у него ещё очень широкие возможности по кастомизации того окружения, в котором он будет работать. То есть, грубо говоря, ��от у меня есть один из процессов, который, а, при тестировании, точнее, в одном из проектов при тестирование запускается Playgite, и там очень много тестов. И Playgite он запускает, естественно, разные браузеры. То есть там целая матрица тестирования такая получается большая, то есть браузеры, а, разные версии браузеров, а, разные разрешения и так далее. И вот это вот всё хозяйство выполняется очень долго и жрёт очень много ресурсов. Вот. И те контейнеры, которые непосредственно GitHub э предоставляет у себя в рамках GitHub Actions, они просто с этой нагрузкой не справляются. Ну либо это очень дорого выходит. Я штатными возможностями вот этот вот контейнер, в котором происходит запуск фонового агента, перенёс просто на одну из своих машин, которые просто у меня есть, вот на толстую машину. И вот он там это всё делает. То есть он там запускает агент в рамках этой машины, и Play WRght запускает вот эти тесты. А, и по сути для меня это довольно большая экономия. И очень клёво то, что именно так это можно кастомизировать. Пока что ни у кого из других фоновых агентов я такой возможности не нашёл. Но это довольно специфичная, на самом деле, возможность, поэтому это ж я так вот. Аа, но, но буквально пару дней назад они что-то там сломали в билинге, а, в GitHub Капайте. И я бы его сейчас не советовал использовать, потому что у него начали тратиться премиум запросы, которых даётся 1.500 в месяц. Они начали тратиться, а, по одному за каждый вызов тула. Не за задачу, а за вызов тула. А он в процессе решения задачи может там и 100 тулов вызвать, например. Короче, не надо. Следующий за ним, который стоит использовать, это, наверное, всё-таки кодекс. Он, пожалуй, сейчас в плане кастомизаций и в плане там каких-то мелких фиксов будет следующим в списке, а после него Google Jus он хорош, да, прямо мне нравится. Если ценовой проблемы не стоит, то, пожалуй, самым хорошим сейчас будет, э, клодовский, да. Несмотря на то, что вот он там оплата по токенам и вам ещё дополнительно платить за GHup Actions придётся, но вот именно с точки зрения качества, пожалуй, он будет самым таким нормальным, если проблема цены не стоит. Вот. А вот в курсоре же тоже появились эти background agн не попробовал. А они как тоже самое. Аа с ними [музыка] во-первых очень глючный. Пока что там прям прям плохо работает всё. А, и там тоже только в макс-режиме это работает. То есть это тоже довольно дорого выходит. Там оплата по то��енам. И причём тарификация в курсоре, она в макс-режиме таким образом устроена, что вы платите на 20% больше, чем если бы вы использовали апи вендеров напрямую. То есть максрежим он дороже, чем прямое использование апи выходит. Я бы не стал его пока использовать. Просто и в силу вот как раз глючности, и в силу того, что а он вот пока что не очень а по цене выходит. И плюс ко всему он не поддерживает вот именно такого режима работы. Вы в этот компайти не можете. Вы не можете ему пр��сто поставить задачу, грубо говоря, в каком-нибудь тасттрекере или в веб-интерфейсе для того, чтобы он начал работать. Вот пока что такого нет. В случае, например, с тем же кодексом, с Jeshubiling coding agent, вы можете поставить задачу и проверить её выполнение прямо онлайн. А вот в в курсоровском нет. И в агументе тоже нет. Угу. Я вот, кстати, интересный опыт, а то бывает не с кем пообщаться, у кого спросить, всё же не успеешь потыкать. Очень круто, что ты, Максим, столько инструментов успел. А вот стало

[01:50:00] интересно, вот этот Firebase, который web AI и DE от Google, вот в нём кто-то имел опыт? Я что-то не смог с ним качественного результата добиться и забил на него. AI Studio даже лучше, чем этот Wibas Base, там какая-то у них баг на баге. я не понял, это одно и то же или оно отличается там отдельная штука. Там ты билдрежим выбираешь, а он типа там есть проблемы у них, но он типа в своём контейнере будет прямо запускать всё билдить. Там просто есть некоторые у них проблема, потому что они приустанавливают некоторые зависимости туда. И по сути он там пишет очень быстро до фига кода, он типа у них сразу всё работает, всё круто, а потом локально это нихера не стартует. Поэтому там есть приколы. Вот тесты, да, прямо очень важно для таких вот всех вещей, чтобы они сами имели возможность тест запустить и проверить свою работу. Вот снбокс со с��оими зависимостями. Типа ты ему ты его просишь, типа говоришь: "Сделай там что-нибудь мне на вдже". Он такой: "Не, нихера, я на реакцию буду делать". ещё что-то подумал из таких вещей, которых ты не знаешь у кого спросить. Ну, в плане обычно никто не сталкивался, а у кого-то уже есть доступ к deep thinking от Гугла, который вот типа минат deeping. Ну, это типа, который в подписке ультра они обещали выкатить в мае, потом в июне. Так на США и так не выкатили. Ну, типа это как бы О1 Pro, О3 Pro. Но как бы от гугла от Gemнай 25 Pro, который будет долго думать. Я, если честно, не знаю. Мне кажется, сейчас основная проблема уже реально, типа, не в том, что модель уже пипец умная. Типа ты берёшь, как обычный, он пипец умным, типа, что он там делает, это жесть. А вот агентные системы всё ещё типа можно дорабатывать. То есть сами лмки, я хз. Если ты ему дашь больше времени, подумать, что изменится, если он запускать всё равно не может. сейчас клод, он очень долго думает, как бы, а, ну, в этих в токенах как бы 500 Кб - это 130.000 токенов, там, ну, 700-600 - это вот 200. У гла получается 4 Мб - это вот, ну, 1 млн токенов. А этот deep sinking, он 2 млн ест. То есть он типа 8 Мб кода legacy и как бы Zero хорошо, типа deepsн подумал и вот сделал сразу за один прожов. Ну, может быть, такой кейс, может быть, вот какие-то вещи, где агенту сложно настроить, чтобы он всё это в контекстное окно вместил. Вот. Ну, мне кажется, во�� по таким каким-то кейсам он, может быть, упростит вот ответ на вопрос, типа, что мне кажется интересным у него, типа, большое окно и как бы и так уже и без промотги умные у него, а с про, наверное, интересно потыкать. Вот. Ну, я так понял, они не выкатили всё-таки, и ни у кого пока нету доступа. Ну, я вот, кстати, тоже, наверное, с прошлым человеком больше соглашусь. Сейчас вот даже если смотреть на какой-нибудь Sonet четвё и смотреть на хардовые бенчмарки, там п�� ризингу, по тому, как он кодовые задачи решает, вот по отдельным бенчмаркам смотришь, ну, так себе модель. Вот. А когда начинаешь его агентские возможности задействовать, такой типа вау, прикольно. То есть, э, мы, кажется, сейчас находим в интересной точке перехода, когда аа не то что, скажем, интеллект модели является определяющим, а в том числе какие-то вот такие нехордовые вещи. Э, ну, точнее, они всё ещё хардовые, просто они не настолько хардовые, как решение алгоритмов, к примеру, или ризинг. То есть то, насколько хорошо модель способна управляться своим контекстом, с теми тулами, которые ей выдали, а вот насколько она способна долго тащить задачи. Вот какие-то вот такие вещи начинают быть более важными. И, к примеру, вот я прямо вот не люблю работать с утри просто потому, что ризингто у неё хороший. Вот она способна решать какие-то узкие задачи, но вот как только её помещаешь в среду, когда нужно подёргать много инструментов, пройтись по проекту, собрать нужные сведения, тут она уже не очень хорошо себя проявляет в сравнении, например, с тем же самым сантом, а, четвёртым. И поэтому не знаю, как насчёт вот, конечно, про режима, точнее пдицинька в случае Гугла. А как это всё будет работать, если он, скажем так, на большом проекте? А и при этом, если он сможет эфферено задачи задачи решать без вызова внешнего тулинга в

[01:55:00] ваншот-режиме, здорово. Но есть проекты, которы�� просто в его контекст не влезут. И тут от него понадобятся как раз-таки вот эти все дополнительные вещи: способность использовать внешний тулинг, а способность грамотно обращаться своим же собственным контекстам и так далее. То есть все эти вещи хороши до тех пор, пока вы либо либо сразу предоставите контекст весь необходимый, то есть, грубо говоря, соберёте проект и бахнете прямо сразу в контекст модели, она один раз подумает и выдаст вам ваншот решение. Либо вы полагаетесь на модельку поменьше, у неё и контекст помельче, и, возможно, хардовые бенчмарки похуже, но зато у неё есть способность эффективно этот контекст собрать за счёт использования внешнего тулинга и потом с ним аккуратно обращаться. И вот здесь вот какой-то баланс между разными проектами в зависимости от специфики у каждого будет свой. Как-то так. Там же ещё вышел этот Google diffusion, но что-то про него пока молчат. который типа генерирует код как картинку. Прикольно. Интересно, то есть насколько это себя покажет. Ну так а непонятно, что это даёт. Ну в смысле, будет у тебя код в пять раз быстрее генериться. Сейчас же нет проблем в том, что он медленно генерится. Ты не успеваешь его. как вот мы бы сейчас не ждали типа час, а ждали бы 10 минут. Генетический алгоритм используют для написания кода. Выбирается самое лучшее решение. И, честно говоря, уже так делают. Вот в Open AI кодексе там же сейчас есть возможность, вы ему пишите задачу, и вы можете запустить сразу несколько инстансов э вот этого облачного агента для решения той же самой задачи, а потом по итогу выполнения выбрать из них то решение, которое вам понравится больше всего. Так можно пойти дальше, алгоритмы использовать и у вас эволюционны. Я немножко не про это, я про то, что узким звеном буде там что интересно модели. Да, да, конечно. Извините, а и ещё интереснее с Defusion моделью, на самом деле она, скор��е всего может быть меньше существенна, чем LM. Вот. То есть у неё просто другая архитектура и она может быть меньше, компактнее, соответственно, меньше рать компьютера и так далее. Самы самая большая проблема сейчас, мне кажется, точнее, одна из самых больших проблем - это контекст. Хочется впихнуть модель побольше и чтобы она с этим контекстом ещё хорошо работала, не забывала отдельно его части. То есть, если диффузионные модели нас приблизят к к тому, чтобы пробить вот эту пробл��му контекста, а, ну, это просто совсем другое будет будущее в том плане, что вот даже сейчас по сути работая вот во всех этих инструментах, мы ограничены контекстом вот, ну, по большей части 200 ак токенов. А когда ты переходишь к работе с GMI, где 1 млн токенов, но это уже ощущается как качественный переход. Я очень часто пользуюсь возможностями того, чтобы собрать в проекте нужное мне набор файлов, бросить Gmin, там задействовать задействовать его вот большой контекст для ��ого, чтобы архитектурные вопросы обсудить или вопросы рефакторинга или, может быть, там документацию какую-то составить по проекту. Большой контекст прямо очень хорош. И если мы решим эффективную проблему контекста, там расширив его до 10 млн, до 100 млн токенов, а большинство проектов просто туда целиком влизут. И сказали только это дорого, может быть, вот они делают. Вот, да, если если эти diffusion модели позволят именно пробить вот эту планку, верхнюю границу контекста, которую мы сейчас имеем, и она, кстати, обусловлена самой архитектурой трансформеров, если уж на туда пошло, то прямо это было бы здорово. Но я не знаю, как как там с этим дела. Ещё подумал, знаете, какой вопрос хотел поднять, затронуть, пока наш кд пыхтит. А получается, антропик, они же как бы вот хорошо натренили, может, свою модельку на вот эту mcpшность, чтобы агентность у неё была высокая. А вот Google же тоже выпустил A2A Framework. Кто-то вот изучал, вникал в чём он. Я так насквозь, когда посмотрел по диагонали, как будто он чучуть отличается принципами, как бы между серверными агентами общения. Может быть, кто-то уделял время, вникал. Слышали? A2A Framework. Я вот скинул ссылочку специально в группу 1958 сообщения. Ну, это ближе к тому, что Алексей делает в плане, что это когда у тебя разные агенты, например, там Cloud CД и какой-нибудь ещё агент менеджер и какой-нибудь агент аналитика. Вот они все вме��те будут как-то там

[02:00:00] взаимодействовать друг с другом какой-то проект. Это близко к этому. Вот, кстати, обратите внимание, значит, у нас 15 Мб исходников, да? Вот. И, значит, ну, последний раз там, когда этот самый Клод сказал, какой у него прогресс, там 56%, по-моему, он сказал, вот, значит, у нас 578 Кбку, то есть разница существенная. Угу. Мы будем как-то его или будем ждать всё часа полтора? Не, не, не, я думаю, что он уже близок к концу. Смотрите, короче, я я никуда не тороплюсь, да, если ребят, вопрос. аналог хороший openсоourceный clт? Вот кто-то из ребят Гусь рекомендовал, и у меня, честно говоря, не доходят руки его затестить. Там вроде тоже есть MCP и вроде он мультиге, ну, мультилмный. Кто-нибудь пользовался, не пользовался? Скажите, в целом? да, да, для кода. Ну, вот аналог кода. А, open source напа. А его, причём, кстати, уже умельцы переделали в плане того, что есть это его форки, которые не только с OpenA моделями работают. Ну так это ж и подразумевает открытый Open. Там это конечно. MCP типа это системная часть спокойно поддерживает и Rleкод, и Codex Cit, скорее всего. всё это поддерживать. Там же главное просто, чтоб эти токены, которые лм генерирует, обрабатывались в инструмент, делали запросы. чтобы сама модель, которую ты подрубишь, умела работать с вообще, в принципе. Эйдер не умеет разве сам себе работать? Мне кажется, он один из первых должен был вести. По-моему, до сих пор не не в реализм это всё дело. уже куча там форков с MCP, но, по-моему, автор ещ ещё не не доехал до этого. Ну, кодексхли точно. Это, во-первых, open source, во-вторых, э ну форки точно работают со всеми моделями. Сам официальные репозиторы, не знаю, вряд ли такого. MCP, кстати, у них это было чуть ли вообще не первый полуреквест, точнее, не первый. То есть они как только выпустили, там сразу набежали люди, типа, давайте нам MCP. И они буквально через некоторое время добавили поддержку. Да, есть. Ну ладно, о'кей, спасибо. Но гусём никто не пользовался, да? Не может ничего сказать. ведь не не на код заточен. Он именно инструмент общего назначения. Нет, просто если кто-то с ним работал, это Ага. Его это его переводят в плоскость инструментов по типу Clesktop или cherry Studio. Есть такая штука cherry AI Studio. Вот. И, ну да, вот человек там пишет в чате то, что это не тот инструмент. То есть если он не заточен чисто под код, то я говорю, это просто локальный чатик. Это не делает его применение невозможным для написания кода, потому что вы можете подрубить тот же самый деstop командер, к примеру, MCP, и он довольно эффективен, кстати, и код может через него писать. А я так кладу десктопу подрубал вот этот вот десктоп командер MCP и небольшие проекты с его помощью реализовывал, но если у него внутренней заточенности на код нету, ну он, конечно, похуже будет, да, чем специализированные инструменты. Так, у меня поправка. Кодекс в официальном в главном форке поддерживает любые модели. У них конфиг снизу есть, прописывают, что вы можете использовать любые провайдеры, любые модели и так далее. наверное, не на поверхности, а так спокойно. раз уж затронули open sourceные, не доходили никак руки до Open Hands, но слышал там на Редите хвалили, никто не пользовался. Хотя это, наверное, отстаёт от код код, конечно. Слышали это? Open - это типа такой с философией Аирн тоже open sourceные. Я так понимаю. У них сразу как и DE было

[02:05:00] типа какой-то как AI Studio то ли же как Девин. Они же и назывались раньше Open Devin. А это как раз один из первых таких агентов, которые предполагалось то, что вы его добавляете как джуна в свою команду, а через лаг ему ставите там задачи, он идёт потом запускает как раз-таки вот какого-то фонового агента где-то, а пишет код, там тестирует его и возвращается к вам с лреквестом. Вот openстон как раз сделан как такой клон Дэвина. сам не пробовал, но слышал хорошие отзывы. То есть там, естественно, оплата по токенам, то есть там нет у него какой-то подписки. Это именно инструмент, который просто сам по себе он openсourсный, а за апивендеров вы платите самостоятельно. Но вот из того, что слышал, у него довольно неплохо работает сам агент. И некоторые люди говорят, что да, вполне достойно можно использовать. Но его в силу онсорсности, в силу того, что его всё-таки надо интегрировать со многими вот этими внешними инструментами, там типа Слаck или там GitHub и так далее, некоторое время придётся провести над тем, чтобы его сконфигурировать. Чисто админская задача. Кораткевича. Кстати, Гена, кстати, не так далеко от тебя Саша живёт. Он в Менлопарке живёт. Так что можно контакты держать. Короче, готовят они какие-то оно там скоро. Угу. И они, кстати, если зайти к ним на страницу Википедию, там написано, кто работает Геннадий Колевич. Угу. Ну, это серьёзное преимуществ��, да. Угу. Ну, кстати, вообще в целом сильная команда и математиков, и олимпиадников, бывших именно по программированию. То есть мм это как бы с одной стороны плюс, а с другой стороны минус. То есть по-разному пишут. Если они там типа что, если они модель делают или обучают что-то, то иногда. Open source, короче, дороже. чем не open source на данный момент. Это да, это скорее всего ещё из-за того, что аа ну вот, например, тот же самый курсор или вот все вот такие продукты, которые сейчас по подписке доступны, они очень сильно субсидизируются своими инвесторами. И там, как я понимаю, что вот многие из них, они просто и денег-то сейчас не особо зарабатывают. Они больше работают на то, чтобы именно аудиторию набрать, а постепенно всё равно мы увидим тренд на то, чтобы цены поднимать. То есть, к примеру, тот же самый курсор, вот там у него появился под план, точнее режим работы Макс, бграунд агенты только в макрежиме работают и так далее. Кайлот вот этот вот гитхабовский буквально на днях изменил, э, точнее, как он он включил-таки наконец тарификацию, и она не всем понравилась. То есть кажется, что сейчас постепенно субсидии будут сходить на нет, и оно всё будет дороже и дороже становиться. А возможно, что мы придём к тому, что а не так уж и плохо будет испо��ьзовать openрные инструменты с прямой оплатой за апитокины, потому что они могут сравняться по цене с вот этими коммерческими инструментами. Это если не будут повышать цену на модель. И это тоже Да. Да. Когда мы перейдём в цело в Hed Solution, кстати, вспомнил про этот кдор для SH Hosted. Есть же, как это правильно называется, VS-код там API или GitHub, когда, ну, через GitHub Copilot, наверное, а, когда в Copilot же есть модели, там и Sonet были и прочее. Это я где-то полгода назад в кл��не начал использовать, когда его тестил. Ты покупаешь за 10 долларов подписку или вообще даже можешь без подписки купайлота, там даются нормальные лимиты. И вставляешь её в клайне и юзаешь эти модели через там О1, например, был безлимитный, но оно вот на вот этой прослойке, ну, если ещё раз правильно обозначить, что есть как бы такоя поддержка Апи. Она сначала была не официальная, потом официальная. И внутри клайна можно как бы сделать модель

[02:10:00] провайдер не по токенам, а вот чере�� коilot апи ты юзаешь свою прокси такой апи. И то же самое как бы вот в Аидоре и ещё в каком-то в Open Hands как бы вот все так стараются. Это вот такой есть маленький трюк, но как будто модельки чуть-чуть хуже рабо у меня хуже работали. Сейчас мне пришло пару людей на звонок, которые раньше приходили. Они адепты Квайна. Они вот полностью довольные. Вот я вижу Денис пишет, что CL с MCP хорош, но у него агентность была хорошая. Вот, может быть, кто-то прой расскажет или это как курсор аналог там с этим LM, как уж это LMI или LM в общем, да? То есть Google Studia наружу выставляет какой-то интерфейс для работы как раз-таки с лмками. И вот как раз вот этим вот хаком люди и пользовались. То есть они использовали подписку GitHub Copilot и поверх неё использовали Rкод или Client. А и это там проблема ограничения контекста. А, как я понимаю, до недавнего времени там то ли 32, то ли 64 к токенов было доступно вот через это. То есть ты, в принципе, в рамках чата больш�� не мог контекста использовать у моделей. А на днях, опять-таки, я вот ещё раз говорю о том, что не изменили, наконец-то систему лицензирования, точнее, а начали считать токены, и народ уже предварительно, кто вот этим пользовался, они начинают жаловаться на то, что сейчас каждый из вызовов тулов использует один премиум запрос, а в рамках подписки там за вот эти условные 10 баксов их даётся что-то там несколько сотен в месяц. Они улетают буквально за пару дней, поэтому этот способ сейчас, по крайней мере, стоит пересмотреть. Не очень понятно, то ли это ошибка самих Microsoft, решение, то, что они решили вот таким образом тарифицировать премиум запросы. Но вот на текущий момент, я говорю, народ очень сильно жалуется. Вот на самом деле даже вот какие-то дорогие нейронки, они вот, как сказал Алекс, в разы дешевле, чем потеря времени и бесплатные нейронки. Не, ну если вот клод использовать по апи, то, наверное, это ��удет очень дорого. А если вот по подписке, то да, пока не нужно. А-а, нет кейсов, которых тебе у тебя не получится сейчас использовать подписку. Макс, допустим. Не, не, я про я больше как продолжение разговора, что они будут дорожать со временем. Типа подписка-то точно мастхр, да? удешевлению, так что вряд ли дорожать прямо. Со временем у нас и железо улучшается, дешевле становится всё это запускать, и сами нейронки улучшаются. Так что скорее цены на на том же уровне останутся. А то, что Максим, кстати, сказал, я написал, а есть варианты запускакод а на своих серверах для actions, и там просто прокидываются ключи, а для клода. раз, но я не думаю, чтороopic это очень понравится, и когда-нибудь они это прикроют. Ну, сейчас доступно. Угу. Я знаю некоторых этих чуваков, кто это использует кд-код, они его ставят на этот ударённый сервак, а, и типа вот у меня есть проект, сконфигурируй мне сервак под этот проект. Работает. Ну, то есть там ставит какой-нибудь, настраивает эти все необходимые библиотеки. это всё к одной подписке привязано? Я имею в виду, с точки зрения антропика, это пофиг. Нет. смотри, даже если лимиты одни и те же, они вот в своём, а, в своих правилах прописали, что нельзя использовать несколько аккаунтов на одной машине. Странно, почему, но вот они это прописали. И обьют их системы. То ��сть это звучит как опьюз, когда ты используешь фичуку, которой за которую ты должен доплатить сверху и ты не доплачиваешь. Так что вообще они прописали себе, а у меня брат постоянно жалуется, что вот есть какой-то тайный лимит, у них, э, задано, что есть фиксированное количество сессий на месяц. И если ты его превышаешь, они могут по своему усмотрению взять и ограничить э-эвою подписку. сколько у них сессий, там типа 50, вроде

[02:15:00] максимум за месяц. И после птися они по своему желанию могут граничь как раз-таки твои подписку. 50 Ты же всё равно можешь за день там типа стартовать клод, выключать его, стартовать, выключать. полная сессия 5 часов. То есть сколько хочешь открываешь акон, это ничего страшного. Но если ты за полмесяца 24 часа в сутки используешь вот, у тебя как раз заполнится всё это количество сессий. Они не гарантируют, что они заблокируют аккаунт, но они это прописали, что есть такая возможность. А вот они они в минусы идут. Ну да. Вот такой вопрос. А вот когда там ведь какие-то сабагенты сейчас можно запускать в код-код, по-моему, да? Как вот это с точки зрения сессии, это тоже как бы укладывается в эти 5 часов, если ты там этих сабагентов в параллель там 10 запустил. То есть это всё равно в рамках одной и той же сети работает. Идёт тарификация 5 часов всегда, и ты в рамках своей сессии всё равно потратишь максимум те токены, 5 часов, даже если у тебя несколько аккаунт открыто. прописаны. А лимиты на токен токены, они у тебя за 5 часов там как раз-таки X20 от базовой подписки. А хз сколько, честно, но они должны быть где-то. То есть они же прописали, что у тебя 900 условных часов есть вообще. Не 900 условных сообщений. Аа вот как-то они высчитывают как раз-таки лимиты и на 5 часов, и в сумме. Вот он сказал: "Брат, 379 млн токенов - это общий лимит на месяц, если считать по использованию". Так-то это дофига, конечно. меня вот они даже не всегда день в день обнуляют подписку, когда я денег на карте нет, допустим, пару дней могут оставить подписку и ну как бы это тоже удешевляет подписку. И так она дешёвая. Ну, ещё вот дополнительно. Ну да, там иногда посмотришь отчёты этого CC USA, народ выкладывает, типа вот если б�� я по токенам, то у меня было бы там, не знаю, в 10 раз дороже, чем Cloud Мак подписка. Ну да, максимально 2400 можно её выжать подписку долларов, если 24 на7. Это же как в зал ходить, типа абонемент купил, а дальше, день работал на 1.000 долларов по сообщениям он там 8.000 3.000 1.000. И мне кажется, как раз на этот счёт, э антропик перестраховались и добавили лимиты на 50 сессий за месяц. И если ты там, допустим, закроешь эти 50 сессий за месяц, все 379 млн ��окенов за 15 дней, то, скорее всего, ограничит как раз твою сессию. Ну, это на случай, если ты захочешь перепродавать апишку, завернув контейнер. [музыка] Это очень легко вычисляется. Угу. А у меня ещё такой вопрос. Смотрите, я вот не так много работал именно с опусом, а, ну, то есть какое-то количество денег я на него потратил, когда ещё Cloudду Маx не появилось. У меня, собственно, вопрос: кто у кого какой экспириенс в плане повседневной работы между Опусом и Санетом, если такой экспириенс есть? То есть стоит ли а-а на какие-то задачи повседневные, скажем, опус использовать вместо Санета, если у тебя есть подписка за 200 баксов? Ну я честно скажу, вот сегодня был такой случай, OPUS отказался инит для проекта делать просто потому, что OPСus начинал генерировать нул токены, даже не скопировать. И Sonкра справился с этой же задачей. Опус прям в течение часа точно отказывался генерировать. Кое-как я его заставил просто через пром не через командут сделать. Это он сделал, но всё равно криво. И я уже забил, перешёл на сонет. А как будто бы сонет во-первых и быстрее и

[02:20:00] типа, ну, э вот на личных бенчмарках там кто-то на Ютубе, допустим, делал Son лучше отрабатывает. Опус нужен вот для каких-то режимах, где ты пытаешься ультрафинк использовать. всего будет отрабатывать. Есть проблема, что вы когда cl стартуете и вот там есть сшмоду, он по дефолту стоит в режиме default. И они, короче, они типа по идее хочется, чтобы это работало так, чтобы там для сложных задач опус вызывался, а по дефолту Son, но что-то они, короче, не смогли это пока реализовать, поэтому по дефолту там работает опус, пока у него типа не остаётся от лимитов 20%. Вот поэтому если так уж выгоднее нат переключиться типа по дефолту, а опус только включать, когда реально нужно или опус. Ну я вот, допустим, на подписке Макза 200 ни разу не доходил ��о лимитов один. То есть параллельно я шарю аккаунт, мне пофиг. А три человека со мной ещё сидят. И единственный раз вот вчера дошёл до лимитов, э, за 2 часа до конца сессии. Это за несколько месяцев единственное единственный случай вообще такого. Так что я не знаю. Опус на макс подписки прямо супер долго нужно заморачиваться. Я на опусе доходил практически, ну, не дошёл до лимита, но практически дошёл до лимита. Там типа чуть-чуть осталось -э на опусе, когда я там что-то в LEGC проекте что-то долго долго писал. А но у меня подписка ещё 100 долларов, не 200. Ну то есть такое типа, работать, то тяжело дойти лимит. desktop попробуйте. Он, короче, очень резвый. И 100 баксов у меня в течение ближайших 10 дней я всё время в 3 часа лимитов упирался, а потом как бы вот купил макс, пока не встречал. А код-код он как-то, ну, экономнее используется, то есть дада, то же самое дело. Кстати, вот проблема. Я не знаю, насколько она острая у вас, но у меня кучу треш-файлов делает и Sonet, и Opus, как бы вот Алекс делает всю эту документацию, она как бы полезна, но с другой стороны иногда сонты и опуск генерирует прямо много трэша, который useless, там, допустим, временные файлы. И даже вот в этом репозитории, который Алекс скидывал, там тоже такое такая проблема. Много SH-файлов, а много документаций, которая никогда нигде не будет использоваться, она просто лежит. Ну это чисто засоряет не контекстное окно, а мои мыслительные процессы, когда я всё это вижу. Ну, у меня, кстати, ну, зная об этой особенности, у них, кстати, прямо в документации в CLДФ, когда вот семейство вышло, у них там прямо в документации написано, типа, может генерировать, э, типа свои инструменты, какие-то вспомогательные скрипты в процессе работы. Вот если вы не хотите, регулируйте это промтом. У меня вот прямо при работе с анетом у меня в промте прямо указано, когда заканчиваешь задачу, удаляй ворунды, удаляй временный код, удаляй временную документацию, не делай ничего из того, что тебе не потребуется в будущем. Вот. И да, во многих случаях он просто сам это чистит. А так, да, вот он реально иногда ему нужно вот что-то сделать. А, и он даже вот эти вот встроенные механизмы блокировки некоторых вызовов в курсоре обходит, грубо говоря, в курсоре запрещено удалять некоторые файлы. Ну, просто правило есть такое. Это самим курсором регулируется. он напишет рядом консольный скрипт просто для того, чтобы удалить такиму тот файл, который ему не понравился, а и скрипт потом оставит в проекте или там для тестирования какого функционала он не тест напишет вот именно с использованием какого-то тестирующего фреймворка в проекте, а напишет тест, который запускает, условно говоря, какой-то веб-сервер, сам пишет запрос к этому веб-серверу, тестирует, работает ли этот запрос, а потом опять бросает всё в проекте. И вот как раз вот для таких случаев, я говорю, приходится прямо в промте отдельно прописывать, что типа удаляй за собой все вот эти вот вещи, но не всегда удаляет. Раздражает, да, тоже иногда прямо. Зачем мне это всё? Ну, я прямо ловлю умственный перегруз. И, ну, как по мне, самый классный способ

[02:25:00] использовать сейчас нейронки - это всё-таки, когда человек думает, э, а нейронка просто как инструмент, то есть опус перебор, э, просто потому что он слишком долгий для этого. А Sonet как раз-таки быстрый. конкретно каждый файл по отдельности берёшь, обрабатываешь и так далее. Ну, работаешь с этим. автомате, но при этом за счёт контроля а прямо сильно убирается количе��тво времени, которое ты тратишь на работу с репозиторием. Просто потому что ты это контролируешь Ну да. И я для себя сейчас вот над более-менее такими большими проектами выработал именно топдаун подход. То есть ты как обычно, то есть это такой минитерфол получается. Ты стараешься всё заранее распланировать, заранее расписать все таски, а заранее там гранулярность их обеспечить. И потом вот просто с ними уже ходишь по отдельным чатам или даже по ��оновым агентам раскидываешь для того, чтобы в конечном итоге получить тот результат, который тебе нужен. И тут, по сути, это всё ограничивается тем, сколько у тебя времени и желания есть на то, чтобы этот план составить так, чтобы он был достаточно детальным, вот достаточно хорошим. То есть можно вот прямо по режиму теркола двигаться, а, сразу всё прописав, а можно по идее в процессе постоянно вовлекаться в процесс, постоянно там в каком-то ажайлile режиме пытаться всё это делать. Вот. Но в любом случае, да, получается, что если ты держишь процесс под контролем, оно лучше получается пока что на текущий момент. Тут я прямо согласен. Вот. Особенно в случае больших проектов. Ну, кстати, вот в Айдере, слышно, ребят? Да. сделали такой механизм, и мне он показался довольно интересным. То есть, э, там, когда появились вот эти рининг модели, они попытались их состыковать, и там была у автора следующая идея, что вы используете вот этот ринер, ээ, который долго обдумывает саму Сичу, да? То есть, грубо говоря, вот как прожект-менеджер, она всё распланировала, а, короче, долго это обдумывала, обнусоливала и выдала, ну, короче, вот план имплементации какой-то, да, а уже быстрая моделька по этому плану быстро генерит код, и зачастую она даже это делает лучше, чем поэтому я тоже вот скатился к такому, что я планирую с какой-то большой моделью, она больше параметров может учитывать, лучше пропланирует, а уже при генерации кода вот, ну, как обычно, отдают, да, там самому быстрому ты отдаёшь уже вот более простой моделит, и ты это всё сделает именно напишет мясо вот это, которое нужно. Ну, уже по плану заранее создано. Ну да. И тут вот кажется, что это должно быть автоматизировано с течение времени. То есть какой-то оркестратор должен, а-а, хорошим То есть сейчас уже появляются вот подобные оркестраторы, но пока что что-то тут я не вижу хороших примеров, чтобы можно было их типа вот взял и использовал, но кажется, что вот это довольно рутинная задача в том плане, что определишь, какая задача требует какого агента? Ну какую модель спросить другую модель. Вот. Ну, то есть ты можешь условно у того же большого ризинера спросить, точнее, ты ему можешь сказать, что типа распланируй мне задачи так, чтобы, а, у тебя в проекте есть дополнительные пара синьоров, там два джуна, и вот распланирую задачи так, чтобы некоторые задачи можно было отдать синьорам, другие отдать джунам. Ну и, соответственно, для ризнера-то это будет выглядеть, как будто он действительно разным по скилам людям эти задачи передаёт, а по факту ты будешь у себя внутри использовать просто разные модели под эти задачи. И вот это вот кажется, что в какой-то момент должно быть автоматизировано. Просто вот сейчас пока я не вижу готовых примеров подобных регистраторов, но кажется, что они появятся рано или поздно. Ну да, справедливо. хорошо. Но скажите, почему ещё никто не сделал виспер для cД код? Ну да, английский, русский же вроде была для голоса, для кладкода. Виспер. Ну там не виспе что-то можно было, что он голосом в неё. нет, чтоб вставлять голос.

[02:30:00] Так, а, ну, по сути, тебе же надо просто, чтобы она расшифровала и воткнула в терминал. Ну да, я говорю для кода. костомную слш-команду нельзя сделать? Да, можно. какой-нибудь свой глобальный и чтобы оно вызывало её что-нибудь там куда-нибудь кого-нибудь. Тут проблема, что его всё равно где-то запускать надо. Это Виспе. всё-таки ещё и не нет. Ну ты можешь локально и там, если это смотря что используют, там либо по ахить. Ну да, не можно, можно. Задача-то вроде выглядит вполне решаемой. Странно, что вообще сейчас вот этот вот функционал не идёт из коробки в вайпкоде утилитах. Вроде как бы ну логично же. там уже Джарвис будет также, Встаёшь утром, говоришь: "Джарвис, что-то у меня в задачах сделай всё и всё". Потом днём полуреквест посмотрел и всё. Я планирую порелизить это дело через 2 недели. Так, ждём. У нас будет скидка на подписку. Я думаю, что антропик использует группа тестирование. Да, короче, я я начал анализ на самом деле э��о ищу, да, вот на на тему имплементации. Угу. исходники, а, 13 там с небольши почти 14 Мб. Вот документация 900 Кб. Вот нормально, да? часика три. вручную, то это, конечно, геморрой. Вот. Но если это предоставитьму, то меняет всё. На на самом деле интересная штука. Я, короче, делал, э, пару месяцев назад я делал документацию для одного кастомера, короче, этот ERA называется, короче, компания. Вот у них 200, ну, чуть чуть меньше 200 репозиториев, да, вот, которые, в принципе, не име не имеют никакой документации. Вот, значит, а, и как бы они там, ну, люди, которые работали над этими продуктами, значит, они там чаще уже и в компании-то не работают. То есть там нет, в принципе, людей, кто бы знал об этих проектах хоть что хоть что-нибудь. Вот. Значит, а так как у компании очень много клиентов там в milлиitри и, короче, там, в общем, спецслужбах, вот, то, значит, им эти проекты важны. Я, короче, сгенерил там, ну, на это самое, на пробу сгенерил документацию по там одному из их там самых простых, наверное, проектов, э, называется LM Gateway. Вот, значит, ну и так читаю там, ну, проверяю, как бы, что там оно сгенерило. Вот. И, значит, ну, я сижу у них в офисе, значит, и говорю там, типа, вот у вас интересная штука какая, значит, у вас, оказывается, тут кэш есть, вы не знали, что кэш есть. Вот. Да ладно, типа, какой кэш, я говорю, не просто кэш, а семантический кэш. То есть он, э, значит, исходный запросом проверяет там, ну, делает мбидинг на него, да, и проверяет, значит, ээ на это самое, на наличие в кэше, э, значит, запросов ответов, ну, вот аналогичных вот, э, значит, не может быть, короче, я говорю, блин, ну, сейчас поищу в коде, нахожу этот код, да, действительно, есть такая штука. Всё. Вот, то есть, э, если, короче, этот упал, сейчас. А из-за того, что он, э, не то стоять. Вот из-за того, что он, короче, сейчас работает так из-за того, что он сейчас работает с этими, как его называется, с с ID. Вот, э, у него есть проблема. Он периодически ди валит. зачем они это сделали, я не знаю. наверное, в терминале переполнился. Такое вполне может быть. А у меня я в курсоре вообще сижу в код-код. Там у меня только 1.000 этих символов он даёт, потом чистит. Интересно, тут в ВС-коде, если не огра��ичивают, иногда полезно, то он куда-то убежит, отойдёшь.

[02:35:00] Происходил курсор я вообще не понимаю, на чём зарабатывает. Если Open AI на свои 20 долларов месяц теряет деньги, то как курсор там хоть что-то должен зарабатывать. должен их терять ещё там в геймберической прогрессии, типа. Ну да, то есть это они там хвастаются своимR годовым годовым этим доходом. Ну что-то про прибыль молчат. Да у них партнёрки партнёрки токенов у них может быть слоузапросы на самом деле. Ну хотя да, всё равно. партнёрки токенов? Типа в чём прикол там атропику или там open давать им? ниже кост. Ну там 30% может они дают скидку, но всё равно это же дорого, капец. Мне кажется, они просто жёстко оптимизируют как-то вещь, типа что-то там типа какими-то другими более глупыми там или локальными вообще моделями там типа индексируют, предпосчитывают что-то там типа обрезают, не знаю, короче, там жёсткие оптими��ации должны быть какие-то. Ну вот скорее всего. курсор по-любому оптимизации, да, делает жёсткий по по контексту и там это люди как раз на этот счёт. Это это основная а одна из основных претензий к курсору, то, что они иногда какие-то странные вещи с контекстом делают. Но я встречал мнение о том, что infence, э, вот этих вот lm для вендеров, типа Open AI или антропик обходится намного дешевле, чем они его на самом деле продают. То есть ��уквально там на порядке дешевле. Вот. И если предположить, что это правда, то более-менее экономика, по крайней мере, инференс начинает сходиться. не сходится экономика тренировки моделей, потому что она всё равно очень, ну, она опять-таки в несколько раз превосходит затраты на то, чтобы, точнее, затраты на сам, а, на само построение дата-центра, на покупку видеокарт, на то, чтобы потом натренить модель, они во много раз превосходят профит самих компаний в целом. Но вот если отделить infренс от тренировки, то вроде как inнференс прям супер прибыльный выходит. А это логично, они же они же огромные вообще деньги тратят на там этот же, как там Карпатый говорит, что типа лэмки - это новое электричество. Типа, что вот, э, у тебя компании вот эти вот, которые электричество предоставляют, они сначала тратят огромные деньги на на постройку типа этих электростанций огромных, да, вот типа тренировка модели, а потом типа само предоставление электричества - это вот там у тебя маленький счёт. по-другому чуть-чуть, но всё равно как типа как бесперебойная по поставка электричества в дом тебе, типа та же стратегия. И типа вот, что в будущем этим НКИрен всё будет как на уровне электричества. Угу. Ну и вот в этом случае получается, что возможно, что и курсор, э, если у него есть действительно прямые а контракты с вендерами моделей, возможно, у них там скидки не 30%, а прямо намного больше. Вот есть предположи макс режиме при этом они тебя чат нормально. Ещё плю 20%, Ну, то есть неизвестно, как там на самом деле сходится у них экономика или нет, но мне кажется, что всё-таки большинство вот из вот этих вот инструментов сейчас пока чисто на на инвесторских деньгах держатся, а постепенно будут всё это зажимать. Не знаю, посмотрим. По поводу биллинга что-то вспомнил, как мен�� немножко этот Винсрф, когда я вник в их политику биллинга, как-то это возмутил. Там они же билят зако call, то есть за степ. И получается, ну вот эта подписка их 20 баксов, это, по-моему, 1.500, ну, типа степов, ну, толков. Это вообще я там тратил за 5 дней. Получается, надо там никто не пользовался нёрфом, не возмущался на этот кост или не спотыкался. То есть не токены, а просто итереation их софта агента. Я просто а я им давно довольно пользовался, но вот в эту проблему конкретно не утыкался. То есть А давно ты про это читал? пользовался месяц или полтора. просто упёрся, когда было задачек побольше. Он же резвенько в декабре он, короче, лучше курсора всё это решал, там

[02:40:00] делал. пользовался. он как бы приходит этот в режим чата. Я думаю, что такое происходит. Там начал вникать в модель, а у них на за вот эти 15 баксов, точнее, по-моему, было там тогда, э, он шагов делает и всё. Ну, а как бы ты его отпустил на часик, на два, он там себе, ну, 300л и всё. Ну, типа, и это было как бы очень удобно. Я купил потом на 60 баксов, потратил её там на двадцатый день и что-то мне А потом курсор уже улучшил агентов в январе. Я просто перешёл, уже не возвращался. Попробовал пару раз зайти, такие же задачи решить с Винсрфом. Ну, плюс-минус похожие качества и и больше не возвращался туда. Угу. Ну вот, да, то есть я с Винсрфом в такое не упирался, но вот в курсоре такое ��дно время появлялось для максмоделей, они там тарифицировали, в том числе и каждый из шагов, каждый из тул колов за 5 центов у них там был. Или вот сейчас Gthubile для некоторых случаев так начал тарифицировать запросы. То есть за каждый лolл, за каждый прочитанный файл, грубо говоря, за каждую запись файл он дополнительно с тебя премиум запрос берёт. Ну да, это намного дороже выходит. Сейчас не знаю, как вопросик с небольшой. А вот то, что вы, ну, как бы я так понимаю, многие используют там курсоры, это клали код. А как компания вообще относится к тому, что, э, всё это как-то через, ну, по сути, пропритарные модели, потому что я знаю у знакомых, кто там, ну, в банках работает, у них всё как бы в контуре. И модельки гораздо слабже, и им не так весело, как всем остальным. И я почему спрашиваю? Потому что если, грубо говоря, раньше был вопрос, да, там учат они, не учат, но как бы недавно Open просто сказала, что вот мы там читаем переписки пользователей, но очевидно, что это всё летит в аналитику, летит там в обучение. Ну, то есть как вообще безопасники на это смотрят в компаниях? Если есть опыт, расскажите. У меня сегодня был опыт на пробежка айтишников была. Там пару ребят такие, ну, программисты со стажем там и вот. И они делают что-то, какую-то биллинг систему. А там они по всему миру провайдеры и типа такой тезис кинули: "Да это и Айка, она херню какую-то пишет, короче. Ну, типа, что там она тупа��". Я говорю: "А что вы не юзаете?" Типа, ну что неза? Да у нас компания не разрешает. Вот у них типа на виртуалках они работают, ну, подключаются там им там даётся слабенькая среда, типа, чтобы код был более эффективный и не шерить им какие-то больше доступов, энваронментов. Им даётся прямо заведомо заниженные ресурсы. Они вот пишут код, их айка в режиме Wizard опрашивает, за ними смотрит, типа, ну там они свои, не знаю, что там мистрали юзают, ламы. Короче, вот такая как бы большой брат компания, которая разработчики, которые даже, ну, ни разу не пользовались AI, вот нормально они вот сидят вот пишут без AI на их виртуалках, их там точно скоро добучат и автоматизируют. Ну вот вот такой подход. И им строго запрещено везде там что-то юзать. Вот, ну, если из Полисе, как смотрят, вот в наручниках программисты, просто, что пока ты не разрабатываешь что-то вот типа реально там на государственном уровне, то всем пофиг, типа, что там может, ну, ��ипа оно утечёт в аналитику, но, блин, оно и так утечёт там деле на самом деле пошли сейчас проблемы с тем, что некоторые модели в некоторых случаях могут прямо ответить на вопрос, например, про конкретного человека, потому что это у них попало в базу. Это не всегда работает, это понятно сталистическое, но за счёт того, что обучается на предыдущих моделях, ситуация, когда ты пытаешься нагенерить информацию из приватных данных, она вполне себе реальна. Угу. Я тут, пока мы разговариваем, скинул Клаудия. Никто не слышал. Клаудия - это вот 900 звёзд на гитхабе. Гуи сделали для кодкод, ребята какие-то. Он типа, я так понял, кушает эти все штуки. А штуки, я имею в виду конфиги, ну, типа мою глобальную папку, локальную. Я сейчас зашёл на страничку дашборд. Он, короче, мне тут этот мои эти посчитал все расходы. Прямо прикольно. Скриншот сейчас кидаю в группу. Вообще топчик. Я прямо кайфанул. Типа гуя. Я, короче, потратил на 450 баксов. Только я не понял, как я 2.000 сессий сделал. Вот если вы скриншот открыли, то 45 млн токенов я съел.

[02:45:00] Вот такие удобная штучка. 90 какой-то бред, на самом деле. Я не пойму, как это я мог 2.000 сессий сделать за 2 недели. Я, конечно, активно использую, но не так. Meanwile, короче, у меня, значит, сгенеринтирепорт на это самое, на имплементацию фичи. Вот. И сгенерена архитектура вот на имплементацию фичи. Вот я сейчас это загоняю, короче, в в этот самый вот в репозитории с документацией. Кстати, документацию я выложил, значит, линк на неё на на репозитории в телегу. Вот. Угу. Угу. Я запинил. И планирование, короче, да. И, в принципе, можно запустить имплементацию. А расскажи вот поподробнее, как ты планирование делаешь, что на что внимание обращаешь. его сделать этот project вот GitHub Project для этого и разложить там все эти айтемы. Вот, собственно говоря, так. Мм, так. вот вопросит. Ээ увлеклись разговором. А так вообще-таки, ну, видно, например, меня вот когда он генерит кучу документации, разлетаются мозги с этим. Я не могу столько файлов что-то там смотреть, хочется, может, это разобраться. И это как-то этот вот у тебя получается оркестрировать это, вникая и не вникая, и ещё оконичные промты делать. Ну да. А там пром нельзя экспортнуть? Нет такой фичи кода? А по-моему, это в это самое в клоде надо посмотреть. По-моему, это есть где-то там. Вот. То есть вот, ну, например, техническую, вот техническая архитектура, например, возьмём, посмотрим, что там наделал. Вот так. Телефон тыры. Так. Ига. Так. Transcribe transcription transcribe 8000. Так. А интересно, он учёл премиум подписку там. Просто я такую задачу на Голенге делал в другой библиотеке. А Goсал, взял как бы, но с Винсрфом тогда не так всё основательно. Там вот для премиум аккаунтов нужна это фиг штучка работает для премиум только аккаунтов. Ну хотя может для она по лимиту делает для бесплатно. что именно говоришь? сообщение отправили, э, нажимаем тук. аккаунт, у тебя условно она без лимита, хотя вроде какой-то там лимит есть, но большой. in mons. Интересно, он скетчел. Вот. ну, ну ты же ты же ты же всегда можешь как бы сказать: "А добавь ко мне такую-то фигню или там сделай". я понимаю, имею в виду. Просто он вообще это как-то типа обыгрывал, учитывал, задетектил ли он премиум, например, киворд написать? Ну, можно, можно у него спросить. Можно спросить. такие вопросы задани. Я шучу, что так. users? using transcription function. Ну, что-то что-то такое вот типа. сейчас тут вопроса закончить там тут добавлять. Вот напиши в телеге этот самой Месдж, я ему просто передам. Ага. Сегодня прямо аншак получился с этим звонком. Народ добавляется. Ну, хорошо же.

[02:50:00] Кстати, пока пауза забью это. А кто-нибудь пробовал какие-то? Вот я помню, что ещё год назад были какие-то многоагентные системы, где там менеджеры, тестировщики и всё это вместе. И что-то как-то сперва хайпили, хайпили, там куча этих многоагентных систем получилось, а в итоге как бы всё обратно скатилось к развеситому агенту, который просто через разные приложения всё делает. Тестировал вот эти многоагентные штуки. GPT инженер, ты имеешь в виду что-то такое, да, там было, да, ты же сам в каком-то хакатоне делал многогенновую штуку. Когда это было-то там почти гот года назад это сворм. Это в итоге есть у кого-нибудь положительный опыт или всё равно нужен человек посередине, который бы просто переключал её на разные роли в зависимости от контекста? Ну, я пробовал много разных, на самом деле, этих мультиагентных систем. Вот. А мне что не понравилось, то, что, короче, они, в принципе, работали все, значит, ну, как это традиционным путём. То есть либо там они делали вызовы там друг друга, да, вот передавали данные какие-то, либо, значит, это был какой-то workркфлоу сделанный. Вот. То есть, а, ну, ту��а было достаточно проблематично втикиснуть, например, человека. вот то, что я делаю сейчас, когда у меня, значит, в принципе, там всё общение между агентами происходит через, а, GitHub Project айтемы, вот это, наверное, самый лучший вариант, потому что в этом случае, значит, ну, если если систему выключить, да, вот, то можно, значит, людям продолжать с ней работать. Вот. Ну, конечно, если если эта автоматизация будет работать вместе с людьми, ну, я не думаю, что у людей будет какой-то шанс. Вот. Потому что она реально выгребает воркайтемы из прожекта очень быстро. Вот. То есть человек просто не будет успевать ээ не знаю, там посадить на себя айтем. А кто контролирует вот консистентность всей этой кодовой базы, если это всё делает? Ну как бы не получится, что это вот её разносит, да, и она там нагенерит какой-нибудь всё поломает, как бы как кто это потом выгребать будет и восстанавливать. Смотри, значит, у меня �� меня агенты, на самом деле, каждый агент, он представляет из себя на самом деле не не одного агента, а троих. Вот. То есть один оркестратор и, значит, двое как бы агентов, работающих в паре, да. Вот. И они, э, как бы один делает что-то, другой ревьют. Вот. И они переключаются постоянно. Вот это раз. Второе, значит, э я настраиваю этот самый CCD таким образом, что у меня, короче, на каждый там, ну, чих у меня происходит там запуск тестов, вот, и обновление тестов тоже происходит. ��от. И обязательно, короче, он этот ээ пул делает, ну, всёвсёвсё вообще, да. Вот. То есть, а у тебя, да, у тебя, ну, как бы как абсолютно так же происходит, как в человеческой команде. Вот. Потому что, э, ну, с людьми, да, если кто-то, значит, много людей работает над одним проектом, у тебя обязательно там происходят конфликты и так далее, да? ��от, то есть всё абсолютно так же, та же ситуация моделируется, и поэтому оно разруливается. Ну, о'кей, звучит интересно. Посмотрим, как получить. Просто удивительно, что какая-нибудь мета до этого не дошла. А насколько я знаю, что Цукерберг прямо мечтает всех программистов на улицу выкинуть и заменить агентами. У вот смотри, значит, user type based voice transcriptты. Так, э, так, сейчас посмотрим. Так, [музыка] котик, отстань. Так. [музыка] user type man cashes user types. Ладно. Так. User qu trs. Так. Unlimited transcriptions rate limits, duration limits, free users, weekly quota. Ну вот, короче, вот такая вот штука. Ну прикольно, короче, те-то там он учитывает всё, Вот. Ну что, будем лимитировать, да?

[02:55:00] Окей, давайте, значит, начнём тогда. А это опус или сонет под капотом у тебя сейчас? Вот. [музыка] Так, это можно через модел просто посмотреть, через команду, да? Ну, может быть. Ну вот опус. Ну причём три, которого нету уже у них физически его нет. если то будет что там покажет контекст. Он обману, что это опу Ну он стеснительный просто. Так, значит, сделаем так. for [музыка] EXC МКС коды То есть вот он у нас генерирует По сути, по сути, он сейчас делает работу скрафмастера, пр��дукт-менеджера, а, ну и так далее. Всем этим людям приготовиться на выход. Так, давайте сразу посмотрим. инженеров там сколько в мире было? 50 млн или оста? ещё, ну, типа, костировщики, это, ну, это все вот эти люди, да. все, Вот. И, ну, там, короче, вот, ээ, если вы помните, этот когда был этот Lon Brothers, ээ, значит, ну, просто нараздавал кредитов там на на недвижимость, короче, кому не попало, да, вот и к чему это привело. То есть по сути весь мир провалился в это самое, в кризис. Вот. Значит, и теперь представьте себе, значит, высокооплачиваемые люди, значит, теряют работу, там перестают платить кредит за квартиры, за машины. Вот перестают снимать дорогое жильё, если они снимали, да, вот перестают пользоваться какими-то там, я не знаю, там бизнесами или там, не знаю, покупать дорогую еду становится. Ну, в общем, короче, экономика, блин, начинает проседать. Вот. Причём эффект тут так��й, что, короче, там, ну, не только они провалились, да, вот бизнесы, которые они кормили, они тоже провалились. И это это на самом деле, может быть. Ну да, они создавали сколько вот 50. Ну, пусть будет 100 млн, чтобы 100 на 100 умножить, да? 100 млн и на их зарплату типа 100.000 в год. [музыка] 10.000, сколько там, триллионов, миллиардов, да? И им ещё надо платить, извините меня, этот самое пособие по безработице. Угу.

[03:00:00] Так, давайте посмотрим, что тут у нас создало мне. Так, это документация, это неинтересно. Это хер с ним. Смотрим проекты. Так. Телефон. А что он? Где он склонировал-то? Так, экономиков. 1 2 3 10 млрд. [музыка] Вот так. Это где он? Почему с мировой экономики? На самом деле больше. Там зарплаты ж усреднить, если больше сот. Так, [музыка] [музыка] Так. Так. Камн, по-моему. Там вот это вот ищ. Так, это вот оно, да? Вот оно, да? Вот оно. Короче, это моё. Отлично. А project А. А почему не Linked? Окей. Link Project. Ага, это не то. Так. запушил project. А вот код МД он попутно изменяет ключевые точки. А ключевые точки? цепочку прихуки доки, ну, основные такие эти малстоны GitHub Project, вот внедрение спека, это вот как он самые главные эти малстоны держит в голове сейчас через код MD их изменяют или как-то сейчас он, короче, он, ну, как бы в текущей прямо задаче он использует свой этот тудулист. Вот. Но, значит, я почему создаю эти самые эпики и и таски буду создавать, да, вот чтобы он мог как бы просто в любой момент вернуться к ним и, значит, посмотреть, что сделано и что не сделано и, короче, что надо сделать. Нет, да-да, я понимаю, я имел в виду, что вот глобально ты же с ним пока что сообщениями, ну, сколько было их там уже, наверное, 20-30. И как бы вот ты так как бы говоришь ему: "А вот ты проект забыл, он там уже нигде не теряется. У него как-то вот майлстоны. Вот когда мы приху, например, сделали, они как-то видишь, пока до компакт контекста вот 20 28% осталось, да? Вот у него как минимум до тех пор и есть эта информация". Хорошо соображает пока в них. Угу. так. тасочки нарезает. Угу. Здравствуйте, коллеги. А, а кто-то пользуется методологией мемори банки для того, чтобы как раз парточками забывал и я что-то пробовал, у меня не получилось нормально что-то внедрить её. Taskmр мне чуть лучше работал, а тут вот подход Александра как будто с GitHub Ишу с вот этими всеми выглядит надёжнее. Там уже фишка в основном в процессе сапихать, это, наверно, да, но фишка в том, чтобы перед любой задачей клод читал бы мемори банк и немножко приходил себе. А что нужно из

[03:05:00] из мемори банка этого? Архитектурные паттерны и контекст разработки, например. Вот это в первую очередь. Вот это то, что ему нужно поти для любой задачи. Значит, если мы говорим об архитектурных паттернах, используемых в коде сейчас, да, вот, то, значит, это надо обновлять документацию. Вот. И тогда архитектурные паттерны будут там. А документацию было бы хорошо, конечно же, индексировать в векторной базе. Вот. А значит, если мы говорим об архитектурных паттернах вообще, вот, и, в частности о тех паттернах, которые, допустим, он, а, вдруг, значит, при анализе кода выделил оттуда, да, или там при при попытке там что-то зафиксить, он, значит, пришёл к к решению, что надо здесь, значит, ну, такое решение использовать, да, и выделил это решение в паттерн. Вот. то это тоже, короче, надо документировать и, ну, дальше индексировать, само собой. Вот. То есть это это отдельная задача, которую надо сделать. Вот. А если мы говорим, значит, так, кроме паттернов, что там ещё было какое? Ну, паттерны и контекст разработки, то есть прошлые задачи, разработки, смотри, ты контекст разработки можешь писать, допустим, в комментарии к GitHub ещё вот. То есть ты просто записываешь: "Я вот сделал такую-то фигню". Вот. Ну как бы не сам записываешь, а клоду, значит, говоришь, чтобы он записывал это всё. Вот и всё. И у тебя весь контекст, вся вся ерунда у тебя получается, короче, ээ документировано. Причём не просто документировано, а если у тебя вдруг клод исчезает, то ты можешь продолжать это всё вручную. У тебя всё есть для этого. Вот у тебя нету, у тебя нету, короче, зависимости на какие-то очереди, на какие-то там workкфлоу там в клоде, да? Вот. То есть этого ничего нету. Вот у тебя есть нормальный человеческиймент, с которым ты умеешь работать. Ну я почти то же самое делаю, когда просто е��ть внутри про коррек папка банк с оперированная музыка. Она под каждый проект чуть-чуть подстаивается. И при каждой таске есть кастомная команда вдкоде, которая заставляет агента читать это всё дело и формировать контекст стартовый для задачи. И потом оно тогда успешно это всё пережёвывает, потому что образуется консистентность подходов в решении каждого таска. То есть она по принятой методологии в проекте делает не так, как она выдумала в этот раз. И потом просто соблюдает некий процесс, чтобы и документацию в результате выполнения задачи обновить, и тесты правильно запустить, что всякие линк, тест, компиляцию, там порядок запуска тестов, чтобы соблюстить, ну, всякие такие мелочи детали. Вот не кац консистентны. А можно ещё GitHCup Project пошарить? Хочу посмотреть, что он нарезал. конечно. Я я всё пошарю, на самом деле. Вот я имею в виду так интерактивно прямо могу даже сейчас поискать. сейчас, если он его создал уже, то посмотрим. О, ничего не создал пока. Ребята, можно вопрос для совсем новичков? За клодкод надо платить подписку, типа 20 баксов и всё безлимитно или там оплата за токены? Да, такой вопрос пропускаем один на всю сессию, потому что нужно сертификат на 100 часов плюс в код-коде, чтобы попасть на звонок. Обратите внимание, что создал. Дадада. А-а, Алексей, в общем, подписка экономит кратно в 5, 10-20 раз, условно говоря. Тебе можно за 20 пользоваться, за 100 и за 200. За 20 тоже дают, но они очень быстро исчерпываются. Там буквально ну типа полчаса по коди активно за или полчаса, полтора часа. Если за 100 баксов, то ты будешь там 2-три, а за 200ми ты не упрёшься. Кайф. Там ещё надо понимать клоновскую систему с сессиями, что у них лимит каждые 5 часов выделяется. Но я просто совсем округлил, что как бы всех же людей интересует прямая суть. Вот сколько там покодить активно. А так

[03:10:00] у них на сайте расписано, да, что есть окна, 50 сессий, всего пять сессий, сессия 5 часов длится, на неё даётся 2 млн токенов и так далее. А ещё интересно, что вот сколько я не пробовал пользоваться кодом для на задачи, а уходит примерно 20-25 долларов в час при работе агента. И подписка получается десант. То есть мне даже сложно посчитать несколько раз. Чудовищно дешевле. Вот поэтому очень коллегам рекомендую попробовать как бы 20 баксов на подписку уклода. Это копейки в сравнении с тем, сколько можно сжечь просто за попробовать. Да и там ещё важный акцент. опус в пять раз дороже, чем sonet, то есть и быстрее расходуется. Вот это важно знать. Как красиво, конечно, круп, но, наверное, только для отдельных занятий, потому что я очень модный и дорогой. Даже если подписка, даже если за безлимитны, он хотя бы купо есть. Так, значит, что у нас тут получилось результаты? Отлично. Эпики есть. Так, теперь уர் Я вот тоже так делаю, но я, честно говоря, проваливался на том, что я это делал в Маркдауне. Может, GitHub Pages лучше там с GitHub, но тогда это было месяцев 9 назад. И потом типа он где-то на реализации у меня стопорился. Ну, мы тут ещё вот типа как-то дело так себе, средненько, долго, но это выглядит сейчас уже, наверное, relableл сходом. Угу. У меня, я с курсором, ну, когда-то вот тогда был Sonnet 3 с по тоже, э, этой же иерархии придерживался стандартизированной, ну, эпикстори, таски и спека, PVD, PRD и TDD. Угу. Я делал интересную вещь. Я, короче, делал cast def. вот, ээ, для своего проекта, вот я, короче, с попросила проанализировать, короче, Target Audience, да. Вот потом поэтому Target Audi значит попросил сгенерировать типичные профайлы, короче, вот, э, типа кастомеров, вот, или юзеров. И потом по этим профайлам попросил сгенерить, короче, инстансы типа юзеров, да? Потом, значит, попросил, а, сгенерить, значит, симулировать, короче, этот customer survey вот для этих юзеров. Вот. Почему я вообще этим занялся? Потому что я, значит, находил этот paper, значит, на это самое, по-моему, Стэнфорд или что. Вот. Короче, такие симулированные customer survey, они дают, значит, 85%, а, значит, совпадений с реальными людьми. Вот, что очень высокий такой результат. И, ну, просто это удешевляет очень сильно такие такие вещи. Угу. Ну да, это столько сил, из-за него это у меня примерно ну, наверное, час. Так, детализируем, дитализируем. Тут пишет Максим, что не может голоса. Но вот прикольно было бы к плану добавить зависимости между задачами, встроить что-то типа будет, да. Он сейчас будет у меня анализировать и стоять в зависимости. А, и часть задачи - это раздать фоновым агентам для параллельной имплементации. Ну, фоновым это, чтобы фоновые агенты были, ему надо, короче, дать ээ, скажем

[03:15:00] так, фичу для того, чтобы он мог запускать их в фоне. Вот. рассказывал сегодня. Вот субагенты есть. А используется Task Tool, да? Вы прямо прописываете про использование субагентов, и он начинает использовать Task tool, который как раз-таки и запускает клода. интересно. Это очень интересно. Попробуем сейчас вас. Да, Александр, полезного я как бы я из разговоров очень много полезного. Я не зря просил, например, выложить линки, да? Вот. То есть очень много полезного. Это фича. Она вот вы да. Говорю, новая фича 13 июня вышла и антропик сказали, что мультиагентность повышает по метрикам там на 10% производительность. Так что это даже не то что полезно, это ещё и лучше работает. Ну и окно контекста не засоряется, потому что супагенты у них свой своё окно контекста. Ну вот сейчас, короче, попросим его выгребать э воркайтемы а в режиме этого самого, в режиме канбана и независимые друг от друга. В общем, посмотрим, что будет. Это, блин, будет вообще пушка. самом деле большой проект Летон и не, ну, вроде бы говорят, что неплохой код там, но этот, но большой. Ну вот больш задачупаем амбициозную. Угу. принципиальная разница между программированием на каком-нибудь курсоре, меняя модельки между 37, OPUS, Gmini? и клодкодом. Вот я пару месяцев программирую. самостоятельный, и он хорошо использует баш, другие MCP агенты и так далее. И если абстрагироваться и сказать в общих словах, что, наверное, име суть, потому что можно долго объяснять это. Ну, как бы он твои задачи successр будет как бы �� полтора раза выше, чем любой другой инструмент. Поэтому он так всем и нравится. А он умеет в больших монолитах из там 250.000 строк тоже в них приходить. И вот если ему подробно задачу опишешь, он в монолите тоже всё сделает. Вот курсорная там сыпется только в путь. тоже так же будет сыпаться, но будет чуть-чуть получше. А дальше уже зависеть от твоих навыков. бы добавил к этому такую штуку. Значит, если если эклоду навязать процесс, вот, то он будет successрей делать. Ну, я не знаю, там 99%. Вот. То есть его надо, короче, по сути, э создать ему такой, где его будет вести за руку. Вот. И тогда он будет с этим хорошо справляться. Это это большим промтом системным делается по шагам. То есть большим системным промтом. Это может быть ну вот я тут небольшие промты, на самом деле делал. Вот. То есть, ээ, сгенерирол, например, архитектуру, да? Вот архитектура, значит, ээ ну ты не был сначала, да, сначала сессии? 10 минут позадуш. почему я сделал архитектуру, да? Вот весь весь код он занимает примерно 13 Мб. Вот, значит, ээ документация архитектурная занимает 900 Кб. Вот. То есть это уже намного компактнее, да, и он с документацией гораздо проще ориентируется. Вот. То есть он, посмотрев документацию, может понять, что ему нужно поменять или что добавить. Вот. А чтобы твоя фича заработала. Вот. А значит, соответственно, контекст ему нужен гораздо меньше. А дальше, значит, почему я делаю сейчас, например, вот эти вот, ну, планирования через скрам? Потому что, опять же, значит, ээ, а-а, мы по сути делаем работу, ну, вот как люди, например, делают работу, они планированием занимаются сначала, да, вот а мы упрощаем ему задачу, значит, до как бы до размера, который он может переживать. Вот если мы попытаемся дать ему, блин, там, я не знаю, там гигабайт кода, вот, и сказать: "Давай разбирайся, чтобы делать такую фичу", да? вот, то он, конечно же, там в этом коде утонет. Вот если мы ему если мы ему дадим, короче, дорогу, как именно с этим справляться, да? Причём он, в принципе, он об этой дороге знает сам, да? То есть он знает, что такое, например, схрам. Вот. Но его надо, короче, подтолкнуть в нужном

[03:20:00] направлении, и тогда будет всё хорошо. Спасибо. Понял. так, А в нём приходится явно следить за размером контекстового окна 128.000 токенов или он сам ги��ко сжимаетрует? Он смотри вот вот здесь вот справа, да, внизу, значит, контекст left антикомпакт 3%. Вот. То есть он он компактирует сам. Блин, надо пробовать. Кайф. Вот. Ну и он тебе позволяет, по сути, ээ работать ээ максимально, как бы, то есть ты руководишь клодом, а не участвуешь в процессе. Так что тут у нас? Вот просто самый простой способ пополнить топ-ходом это взять весь проект покануть промиксом кинуть в гемени с большим производством там запланировать работу и вот эту работу уже кинуть к лодкоду чтобы её делать тогда оно работает себе быстрее ста Так, ну посмотрим, что он там запланировал уже. Так, Telegram премиум фтыстыры пыры. Ага. Вот здесь что? А, а что это внутри получается этих задач? Он скопировал фича, которая из оригинального репозитория или как это вот вот эта, которая номер шесть support voice. Она vo Да. кодовских. Ага. Аватарки как-то что-то умудрился. [музыка] прилинковал, может. Странно, что эту фичу на самом деле за закрыли. Да, непонятно, она, да, реализована или как будто не было. Судя по реализовано. Comping conversationры. [музыка] Так, так, дорогая редакция, ты что, её не сохранил, что ли, или что? Сейчас посмотрим. Так. Ну вот если бы это работало, короче, �� в автоматизированной системе, я бы сейчас ничего вообще это не смотрел. Вот я бы просто давал ему задачки и всё. Окей. Компали. Вот. Но в целом так получается, что надо осваивать навыки не столько программирования сейчас, сколько проджект-менеджмента, потому что вот всё вот то, что сейчас Алекс показывает, оно реально вот классический проject-менеджмент. То есть вот чем лучше вы с этим справляетесь, тем проще вам, конечно же, будет во�� в подобную методологию включиться и вообще управляться там большим количеством агентов, большими проектами, которые при помощи нейронов пишутся. Ну и архитектура этих лидин архитектуры, да. Ну да, да, да, да, да, конечно. А, ну, кстати, нет, если ты делаешь что-то сложное, эффективной, то тебе нужно техледа скорее навыки, чем Тимлида. Пока что вот может научиться делать хороший код, если датасет для обучения в основном состоит из плохого? А вот это, кстати, хороший вопрос, потому что ведь сейчас они уже точно начали использовать генерионные куски кода. А, ну скажу, клод до четвёрки, проект, над котором я работаю, один эток, очень сильный форк он openсорсного, который выложили примерно в двадцать четвёртом году Open source. Угу. И там действительно там разница 80% ядро только осталось то же самое. И он пытается усиленно использовать паттерны из того старого проекта, опознав его по названиям перемен и прочего.

[03:25:00] проекте нигде абсолютно не используется название старого проекта. Он использовать старые функции, старые методы в абсолютно другом проекте. пытается восстановить то, что видит, а видит он не очень хорошее. Там даже если есть система ранжирования, то нормальный датасет для обучения тому, как делать конкретные, сложные вещи хорошо, по большому счёту отсутствует. Поэтому я не верю, что ближайшие года три-четыре, по крайней мере, для серьёзных разрабов это будет угрозой. Наоборот, их будут расхватывать больше, возможно, но просто в целом рынок, скорее всего, будет уменьшаться, а также, как он уменьшался в своё время для там тех, кто писал на, ну, условно на семблере, вот он схлопывался, да, они были очень востребованы на определённом этапе, но тем не менее он будет уменьшаться. По поводу сложности, вот я говорю просто сейчас, э, на синтетических датасет��х начинают учить, и эти датасеты не обязательно в себя включают именно какие-то, а, существующие проекты. То есть вот сейчас а Алекс пишет по сути новый функционал при помощи нейронки. А частично, да, частично какие-то паттерны, какие-то куски кода, которые Нейронка видела раньше, она будет включать в этот проект, но в том числе она сейчас будет решать те задачи, которые а не были решены до неё. То есть понятно, что это не новое какое-то не суперкреативное знание, это синтетика существующего знания и чуть-чуть добавленного ризнга, который чуть-чуть опять-таки добавляет нечто такого нового а в этот код. Вопрос в том, вот насколько это уже философский вопрос, то есть насколько вот эти вот синтетически сгенерированные куски кода смогут при условии того, что они будут хорошо протестированы, они, возможно, будут человеческий ревью даже проходить, ну, для того, чтобы на них можно было учить учить следующее поколение нейронок. Насколько вот именно эти куски кода смогут обеспечить лучшее качество написания кода нейронками в следующем поколении? Это философский вопрос. Я вот не знаю на него ответ. Ну я пока, в принципе, согласен. Мне ничего тебе ответить. Ну да, не очень понятно, как всё это будет развиваться, то есть. Но интересно. Тут ещё, э, такая вещь, то, что, по крайней мере, некоторое время будет работа для профессионалов ещё и в том, чтобы проекты либо переводить на совместимость с LLM, чтобы можно было в них при помощи что-то писать, либо выводить проекты в прот, либо, а, разбираться с проблемами на вайбкоженных проектов. Я встречал тут недавно ссылку кто-то кил скидывал на какую-то компанию, которая специализируется уже на том, чтобы брать напкожаные проекты, притчёсывать их и выводить в продакшн. И они прямо много денег за это берут. Вот просто потому, что кто-то, видимо, взял идею из там каких-нибудь людей, кто не разбирается в коде, проверил её, увидел рын��к для этой идеи, понял, что туда реально надо вкладывать много денег, а и с этого много денег можно получить. И они готовы очень много денег потратить на то, чтобы это всё вывести в продакшн и запустить на большую аудиторию. Ну вот там, кажется, тоже сейчас есть какой-то рынок в плане того, чтобы грамотным людям продать свои навыки. Вот. А так-то да. Ну я ещё вот просто опять-таки соглашусь с тем, что нейронка не всегда осознаёт, а нарастание сложности в проекте. То есть а буквально приходишь, говоришь, типа, давай сделаем вот эту задачу. А в этом проекте она говорит, легко. Давай делаем. Вот сейчас вот берё давай берём и пишем код. Даже ты можешь попросить сделать план, она тебе распланирует, а начнёшь имплементировать таски, и в процессе выяснится то, что те решения, которые она приняла, они либо не очень хорошо совместимы с существу существующей архитектурой, а заранее нарастание сложности интеграции она не смогла осознать, либо это те решения, которые они являются настолько сложными, что их потом будет очень тяжело поддерживать. То есть этот фактор она тоже пока не может учитывать, то есть насколько йтенс дальнейшей будет осуществим. Потому что вот есть у меня некоторые такие хитрые задачи, с

[03:30:00] которыми я вот каждую нейронку тестирую, и каждый из нейронок радостно мне говорит о том, что да, давай сейчас сделаем, сейчас напишу код. Начинает писать код, аа я даю ей просто стандартный свой комплект тестов для этой задачи. Она продолжает писать код, изобретает какие-то новые решения. Но я-то знаю, что в публичном домене эта задача вообще не решена. Она не то, чтобы нерешаемая, она прост�� решается очень большим количеством кода, исследованиями и так далее. Нейронка тебе заранее не скажет о том, насколько реализуема эта задача. А смотря на эту задачу со стороны и будучи погружён немножко в предметную область, я могу сказать, что это сложная задача. На неё надо много времени потратить человеку. Вот. И очень много исследований провести. Нейронка заранее такого сказать не может. И вот это вот понимание ограниченности собственных способностей нейронкам пока что не характерно. И то, насколько они делают, ээ точ точнее, они не понимают кривое нарастание сложности. Вот это одна из фундаментальных вещей, которые вот отличают хорошего инженера, которые вот хорошо справляются задачами. Понимание сложности и умение с ней бороться. Вот как, э, нейронки с этим будут справляться, пока не очень понятно. Вот пока что не очень. промт и использовать его как стартер, особенно с инструкцией drт. Я скидывал в чате здесь. Это очень интересный эффект даст. Возможно, у тебя изменится мнение. спорю, что инновационные задачи там решать невозможно, но это будет интересный опыт. Угу. О'кей. Я, кстати, пробовал твой пром Gemini тоже. Вот тришки. Они, конечно, его не кушают, но у тебя он его и кастомизирован под антропик получается. Да-да. Да, он прямо чётко под ээ cl, причём на на опусе и санете он очень по-разному себя ведёт. Санет начинает вести себя как весёлый друган, а опус такой размеренный, солидный становится сразу. Это вот очень интересно. То есть я прямо реально вижу у них разницу характера. Угу. А где, собственно, про он тут? чате, в чате. Telegram или звонка ну тогда он мне уже стёрся. Я потому что переключался между разными устройствами. А, ну я могу повторить, несложно. Так, А, [музыка] Ну, дава��те пока сюда скину. Тем временем, пока мы тут всё обсуждали, я заставил Клода сделать диакторную базу для поиска по проекту. Если кому-то надо, могу скинуть. Я даже не знаю, работает она или нет. Я в код не смотрел, но работает. да. мне интересно было. вообще не взаимодействуя с ним с кодом. Просто что он промт, промт промт. Я вижу, что штука работает, по коду пишется что-то интересное, но как это работает, я вообще не представляю. Это просто из спортивного интереса скорее. Ну вот АСТ креп для постреления абстрактного синтаксического дерева уже давно использовалось для поиска по коду, по всему репозиторию для рерайта кода и так далее. Вот так что для нейронки он тоже вполне подходит и не нужна векторная база. Тут более ценная как раз-таки документация, чтобы была, что, ну, это как индексирование кода тоже идёт документация.

[03:35:00] Вот под конец мы попробуем попросить Клод оценить человека часы. На этом проекте всегда весело. Я когда прошу планы составить, он иногда это добавляет туда типа, ну вот сейчас вот эта вот фаза работы, она неделю займёт, вот эта фаза работы 2 недели, а потом мы с ним Да, да, да, да, да. Он он он оценивает с человеческой с точки зрения, понимаешь? Ну да, да, А потом можно посмотреть, сколько мы на это потратили времени, и, короче, удивиться немножко. Ну, сейчас у него этот есть конкурентность. Мы в этот на 20 человек надо умножать в разные на пике. Кстати, звонок получился большой. Где-то суммарно, мне кажется, человек 25 было. Сейчас 12. Я всегда этот какие-нибудь Лекс Фридман там, он часто брал интервью там всяких интервью 45 часов 6. У нас хороший тоже воркшоп. Да. А кто откуда сейчас вообще? Ну, я уже говорил из Турции. Ребята, кто расскажите вы. Я вообще в Банкоке обитаю, но сейчас приехал призывал в Москву. Угу. Максим, а ты? Я в России. Угу. А провинциал. О'кей. Я вообще в оригинале. Я из Екатеринбурга. Вот. И с 2004 году года живу в США. Вот. Вот сейчас в Санкасе, Калифорния. По сути, это то место, откуда начиналось Силиконвали. Угу. Кстати, насколько чувствуется атмосфера вот всего вот этого вот, ну, просто даже в общении с людьми? Аа, ну я не знаю, в 2000 году чувствовалось сильнее, на самом деле. как-то это, по-моему, как-то всё улеглось. окружение очень большую роль играет. Такой вот тусовке ты варишься прямо по себе ощущение. очень интересно. Я не знаю, это, ну, как бы может кому-то поможет. Очень интересный, значит, способ продаж. Э, ну, не обнаружил, а, скажем так, п��реоткрыл для себя. То есть когда-то в девяносто четвёртом, по-моему, году, значит, ээ была выставка в Екатеринбурге там, значит, и мы представляли там, значит, наш маленький стартапчик представлял, короче, этот складской софт. Вот. И мы, значит, за это самое, за неделю там, ну, за 5 дней, которые, значит, там мы были на этой выставке, мы продали порядка 200 копий своего софта. Вот, значит, то есть просто к нам подходили люди, мы просто показывали, вот, и они тут же говорили, что типа они хотят это дело. Вот. назад значит, то есть огромный перерыв, да, между тем событием и этим. Значит, я съездил в этот в Канаду на веб-саммит. Вот, значит, у нас там был стенд, всего один день был стенд. Значит, ну, на стенде мы там показывали, что-то там рассказывали, вот, и, значит, говорили там с подходящими людьми. А, ну, люди в основном подходят, а, в основном это были, короче, тоже стартаперы. Вот. А значит, и практически, я не знаю, там процентов 80-90, наверное, их, да, был, ну, сразу же интересовались, значит, как как получить себе это вот. Ну, то есть вот это вот тулзу для разработки. Вот. Потом, значит, в другие дни, когда у нас не было стенда, я просто прошёлся по другим стендам, значит, тоже поговорил с людьми. Вот. И внезапно, короче, это, ну, по крайней мере, вот для моего продукта это оченьочень такой эффективный способ продаж. Вот. То е��ть, по сути, значит, ну, если бы я,

[03:40:00] допустим, давал людям подписать там Letter of Intense, то есть протокол о намерениях, да, или там контракт о том, что они, значит, там готовы там наш нашу тузу использовать, вот я думаю, что они сразу бы и подписывали это всё. Так, ну вот он, короче, создал вот эти вот детальные такие. Блин, надо было, конечно, ему сказать, чтобы он код не писал. Ну ладно. Вот. То есть вот по этим по этим штукам уже можно идти, короче, и по сути дела��ь работу. Но мы сделаем ещё небольшую, ещё маленький шаг. Значит, for each user story. Всем привет. А ты записалась на разработку телетона, прежде чем cloudкод запускать? Я Нет. какой-то скидывалось. Ага. сколько не ходил с ним. Кто-то, короче, кто-то дал этот самый, ээ, вот в в Гитхаме, да, на телетоне. Вот мы просто его взяли за основу и, ну, как бы из него развели всё это дело. У меня очень круто он работает связки с гемий. То есть геми можно слить вообще всё, что угодно в контекст мил миллионный и попросить составить ТЗ с а томарными шагами, покрыты тестами. Потом этот ТЗ кормится к лоду, создаётся несколько веток. Вот мне вот так он хорошо работает, но при этом промты там более сложные, то, что он много от себя тены даёт. Я вот, кстати, тоже сейчас подумал, а не будет ли это раздутием типа доков, а по факту нужно сделать маленькую типа оверменеджер. Ну сейчас вот увидим. Он как будто столько сделал этих. надо для тупых моделек нуже нужно чуть больше менеджерить, чтобы они как раз-таки всё по факту делали. Там, где кажется, что можно быстро выкрутиться, без тестов, всё запустить, э без каких-то проверок. Наоборот, если пропустить эти этапы, чуть больше времени потратишь как раз-таки на потом тестирование, на восстановление логики. И тут тоже, казалось бы, фича маленькая, но из-з�� того, что слишком много уже кода прописано, надо очень много написать как раз-таки менеджерского текста. По по сути то, что, допустим, ты бы делал там общением там, значит, с кводом сам, да, вот расписывал бы ему в деталях, значит, вот эти вот задачи, которые ему нужно сделать, да, или там писал бы огромные промты. Вот здесь это делается вот таким путём. То есть мы, ну, как это, знаешь, divй conquer, вот, то есть, разделяя васту, вот мы, ээ, вот именно та подход используем и заставляем его самого, а, делать для себя, короче, описание вот этих задач, которые он должен выполнить. Вот. То есть тут ничего, как бы. этот GitHub сейчас пошарен? Нет. И я, этот GitHub, значит, смотри, этот, ээ, поша GTHub Сейчас, сейчас будет, сейчас пошарит. бы, я бы его посмотрел просто этот, там прожектов не видно, а сам код есть. Сейчас будет всё. Так, [музыка] телефон. Так, вон онзис. Так, стоп. Это не тот. непонятно. Как будто он только прокт есть, а самой репы ещё нету. Да. Что-то Куда-то не туда, скорее всего. Ну, я у него сейчас спрошу, когда он закончит, потому что он он это проще всего мне даст. Ну дада. Он походу в оригинальный телетон Ишу отправлял. Вот я нашёл по комитут. да, А раньше отправлял или сейчас отправляет? оригинальный теле выше пошли. Слушай, ну они, конечно, красавцы, не

[03:45:00] дали запрет. Мы им сделали там нормальный прожектменджмент, да? Всё очень красиво. Сранится как раз-таки в коми захватили библиотеку. собственный телефон Forфк. Да, всё нормально. А, не вижу. Я он? вижу эти Ишу. это было, да, в начале он пытался там это сделать, да, было дело. 50. Ишу как раз я скинул. Все они в теле не в той, что ты скинул. наконец нормальный протич-менеджер пришёл. Вообще, да. Некуда бежать. Так, ээ, сюда. Так, эпики записались. Сейчас сделаю. Сейчас, подожди. говорю, в оригинальный телеписались только пять эпиков. Остальные покупали. Угу. почти. Вот, короче, первый - это GitHub репозиторий для телетоно, да? Вот. И второй - это так. И документацию ещё надо, да? Документацию. Так, ну всё, удачи вам. Я пошёл. Ну вот, блин. А на Project нету. На на в нету доступа. ссылку, но на Так, где он, блин? Вот он. Так, а это не это документация же, да? Нет, это документация. Я я все три кладу. угу. Не, на доке есть. Я имею в виду вот нет доступа. Сейчас секунду. Так, если на Project нету, я сейчас сделают доступ. Угу. Так, сейчас у меня опять свалился собака. Так, да, он как-то странно, он эпики записал в оригинальные телетоновские проекты, а всё остальное как раз вот в это в Корк. Интересно. Ну, пятая эпика есть в телетоновском сейчас. Ой, в этом в Орке. А, сейчас я по Ой. М. Так, а, да, слушай, действительно, пятый эпиктамы там присутствуют, но при этом он в форке он гораздо более детализированный. То есть такое ощущение, что его просто разорвало в какой-то момент. Он часть туда записал, часть сюда записал. просто я заметил, что он записывал не туда, и я сказал ему, куда записывать. Походу ему надо будет дать т�� старые пять ссылок, чтобы он копернул, сообразил в о чём. Угу. И удалил. Так, Core infrastructure. [музыка] Так, да, всё хорошо. Я вот читаю эпики. Ну да, нормально написал. Угу. Ну, потому что, понимаешь, на всём этом, блин, он обучался, блин, он он не обучался на на том, как работать, допустим, через, я не знаю, там, через вот, но он прекрасно обучался о том, как работать через Project, как через руть, через всю эту фигню, да, Таски в гихабе он действительно хорошо пишет. То есть иногда даже вот у курсора бывает стороннюю задачу надо оформить. Ты просто прямо из курсора говоришь: "Типa мне задачу в Витхабе". Он там через GitHthub MCP подключается и прямо создаёт красиво это всё. Это да.

[03:50:00] Да. А, кстати, а здесь здесь у тебя тоже GitHub MCP используют для того, чтобы к GitHub подключаться или какой-то есть другой интерфейс для колодкода? А, а, в смысле консольный прямо. А, о'кей. Ну да, прикольно. только у тебя есть баш, у тебя есть всё. Ну да, само собой. У меня он однажды так в кубернесе эти, как их, поды отлаживал. Вот я офигел. отлажива. Ну да. сам нажимаю, смотрю каждую команду, потому что стрёмно. Вот. А, ну вьюи только как бы иногда разрешаю авто запускать. Там уже можно настроить какие типа, ну, как вот со звёздочкой тоже чтоться. Как со звёздочкой settings jon можно указать, ну, типа маску там, например, куб ктвёздочка, всё, что в view можно делать, а вот на предыдущее нет. Часто это лучше работает, кстати. Ну вот у меня сейчас проблема, кстати, с Кубернетусом заключается в том, что образы там устаревают на эластик, например. И я вот разбираюсь, то ли по ресурсам не хватает, то ли образ, то ли это дебажить. И вот он начинает: "Я всё починил, я всё сделал там как бы, ну не знаю, вот не получается так, чтобы отдать тебе дело. Всё время вот в developчах приходится фи-фи. Ну как бы он не туда бывает идёт overнерит. Угу. Ну да, это есть такое тоже наблюдение, то что в DВОС задачах пока что это девопсы проживут чуть дольше. одной стороны он одну вещь скажу. Значит, на самом деле из из моей практики, если вы не хотите, чтобы о overженирин, да, был, вот, то, значит, ээ просто пропишите, чтобы он использовал Solid, чтобы он использовал KIS, чтобы он использовал DRI, вот и Clean CД. Вот. И это прекрасно применимо, потому что там ко всему, вплоть до написания поэзии. Угу. Надо попробовать. Ну там не оверненет, он как бы как сказать, ну не сейчас, чтобы понятно было соль. Ну там не додумался там нормально обвешать логами там это, а проверить определить проблему, ну до атомов. Либо так бинарно, либо так там, значит, либо А вот он make observability и всё. Надо этот не забывать всегда лёгкие просто запиши в это самое в клод MD и всё. То есть ты ему ты ему просто скажи набор правил, понимаешь, вот чтобы он создал себе набор правил, там observability kiss этот solid там всю всю эту буду. Вот. Угу. все сам. Ну вот, давайте пока пауза расскажу тоже про случаи. Тут у меня была недавно задача, такую хитрую конфигурацию надо было построить. М два инстанса, точнее, три инстанса MySQL матер и д��а слайва с репликацией между ними. для приложений выставляется такая штука, как Proxy SQL. Прокси - это такая, ну, по сути, прокси для базданных, которая тебе позволяет онлайн включать,выключать дополнительные серваки, которые за ней находятся. Ну, в случае там, если у тебя трафик, нужно перенаправить с одного слайва на другой, там добавить слайв в конфигурацию, удалить его. То есть такая хорошая довольно дебракся, она онлайн позволяет все эти вещи делать. Вот. �� мне нужно было собрать тестовую конфигурацию, а для того, чтобы потестить, как это всё будет работать. Аа особенно не хотелось это всё руками делать, потому что задача-то выглядит довольно банально и там решается просто чтением аккуратным документации соответствующих а инструментов. Вот просто дал клауд десктопу с подключенным desktop командер mcp оно прямо справилось. То есть он сам аа скачал нужные докерконтейнеры, сам написал конфигурации для этих doкер

[03:55:00] контейнеро��, сам а-а проверил репликацию между вот этими нодами. То есть он поднимал сам контейнер и смотрел, работает репликация, буквально писал а какие-то аа создавал какие-то записи в базе в одной базе данных, проверял, не появились ли они в базе данных другого инстанса. Вот. Потом точно также решал проблемы а-а как tolerance этой системы. Буквально включал выключал отдельные инстансы MySQL, которые находится за проxl и смотрел, насколько это всё работает, на��колько система продолжает работать. Написал для этого всего конфиги. Вот, и выдал мне в конечном итоге окончательное решение. Ну, понятно, что его потом пришлось проверять. А-а, но суть в том, что для того, чтобы просто поднять всю вот эту связку на локальной машине, для того, чтобы я мог своё приложение уже поверхнеё потестить, а я считаю, он вообще отлично справился. То есть и это буквально ваншотом произошло. То есть это вот буквально я дал ему задачу, подробно расписал, что мне надо. Вот оставил его. Он там где-то минут 40, наверное, возился со всеми этими тестами, с поднятием докер контейнеров. Вот. Но в итоге вот получилось такое решение офигенно. То есть даже девопс задач, несмотря на то, что, как я считаю, девопсы проживут ещё пока дольше, чем программисты в свете автоматизации, а тем не менее вот какие-то вот такие вот простые вещи он уже прямо хорошо делает. Мне понравилось. Так.